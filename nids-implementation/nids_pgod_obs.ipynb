{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from pygod.detector import DOMINANT, OCGNN, GUIDE, GAE, GAAN, AnomalyDAE, CONAD\n",
    "from pygod.metric import eval_f1, eval_precision_at_k, eval_recall_at_k\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "import pickle\n",
    "import time\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch_geometric.nn as pyg_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     990 MB |    8065 MB |    6546 GB |    6545 GB |\n",
      "|       from large pool |     987 MB |    8042 MB |    6531 GB |    6531 GB |\n",
      "|       from small pool |       2 MB |      30 MB |      14 GB |      14 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     990 MB |    8065 MB |    6546 GB |    6545 GB |\n",
      "|       from large pool |     987 MB |    8042 MB |    6531 GB |    6531 GB |\n",
      "|       from small pool |       2 MB |      30 MB |      14 GB |      14 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    8968 MB |    8968 MB |    8968 MB |       0 B  |\n",
      "|       from large pool |    8936 MB |    8936 MB |    8936 MB |       0 B  |\n",
      "|       from small pool |      32 MB |      32 MB |      32 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   57133 KB |    1219 MB |    1232 GB |    1232 GB |\n",
      "|       from large pool |   37479 KB |    1217 MB |    1215 GB |    1215 GB |\n",
      "|       from small pool |   19653 KB |      20 MB |      16 GB |      16 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     110    |    2318    |  376276    |  376166    |\n",
      "|       from large pool |      16    |     413    |  201680    |  201664    |\n",
      "|       from small pool |      94    |    1905    |  174596    |  174502    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     110    |    2318    |  376276    |  376166    |\n",
      "|       from large pool |      16    |     413    |  201680    |  201664    |\n",
      "|       from small pool |      94    |    1905    |  174596    |  174502    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     104    |     104    |     104    |       0    |\n",
      "|       from large pool |      88    |      88    |      88    |       0    |\n",
      "|       from small pool |      16    |      16    |      16    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      46    |      78    |  221936    |  221890    |\n",
      "|       from large pool |       9    |      38    |  165979    |  165970    |\n",
      "|       from small pool |      37    |      48    |   55957    |   55920    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_labeled_path = \"C:\\\\Users\\\\asus\\\\Documents\\\\nids-pcap-dataset\\\\unsw_parquet_used_dataset\\\\unsw_labeled.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw = pd.read_parquet(unsw_labeled_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, test_size=0.3):\n",
    "    train, test = train_test_split(df, test_size=test_size)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_modeling_1(df):\n",
    "    graph = nx.Graph()\n",
    "    node_features = []\n",
    "    labels = []\n",
    "\n",
    "    for source_port_info in df[\"source_port_info\"].unique():\n",
    "        graph.add_node(source_port_info)\n",
    "        info_message = df[df[\"source_port_info\"] == source_port_info][\"info_message\"].iloc[0]\n",
    "        label = df[df[\"source_port_info\"] == source_port_info][\"is_malware\"].iloc[0]\n",
    "        node_features.append([float(len(info_message))])\n",
    "        labels.append(label)\n",
    "        \n",
    "    for (source_ip), group in df.groupby([\"source_ip\"]):\n",
    "        for i in range(len(group) - 1):\n",
    "            from_node = group.iloc[i][\"source_port_info\"]\n",
    "            to_node = group.iloc[i+1][\"source_port_info\"]\n",
    "            if graph.has_edge(from_node, to_node):\n",
    "                graph[from_node][to_node][\"weight\"] += 1\n",
    "            else:\n",
    "                graph.add_edge(from_node, to_node, weight=1)\n",
    "    return graph, node_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_test(unsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    77151\n",
       "1    10475\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    33123\n",
       "1     4431\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph, train_node_features, label_train = graph_modeling_1(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph, test_node_features, label_test = graph_modeling_1(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71374"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_graph, open('model_graph/train_graph_f.pkl', 'wb'))\n",
    "pickle.dump(train_node_features, open('model_graph/train_node_features_f.pkl', 'wb'))\n",
    "pickle.dump(label_train, open('model_graph/label_train_f.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_graph, open('model_graph/test_graph_f.pkl', 'wb'))\n",
    "pickle.dump(test_node_features, open('model_graph/test_node_features_f.pkl', 'wb'))\n",
    "pickle.dump(label_test, open('model_graph/label_test_f.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = pickle.load(open('model_graph/train_graph.pkl', 'rb'))\n",
    "label_train = pickle.load(open('model_graph/label_train.pkl', 'rb'))\n",
    "train_node_features = pickle.load(open('model_graph/train_node_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = pickle.load(open('model_graph/test_graph.pkl', 'rb'))\n",
    "label_test = pickle.load(open('model_graph/label_test.pkl', 'rb'))\n",
    "test_node_features = pickle.load(open('model_graph/test_node_features.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOMINANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dominant_model(train_graph, train_node_features, \n",
    "                        label_train, test_graph, test_node_features):\n",
    "    \n",
    "    pyG_train = from_networkx(train_graph)\n",
    "    pyG_train = pyG_train\n",
    "    pyG_train.x = train_node_features\n",
    "\n",
    "    pyG_test = from_networkx(test_graph)\n",
    "    pyG_test = pyG_test\n",
    "    pyG_test.x = test_node_features\n",
    "\n",
    "    dominant_model = DOMINANT(gpu=0, weight=0.1, num_layers=8, hid_dim=64, backbone= pyg_nn.EdgeCNN, contamination=0.37, lr=0.001, verbose=3, epoch=100)  \n",
    "    dominant_compile = dominant_model.fit(pyG_train)\n",
    "    return dominant_compile, pyG_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dominant(label_test, dominant_compile, pyG_test):\n",
    "    \n",
    "    dominant_ip_pred_res, dominant_ip_score_res = dominant_compile.predict(data=pyG_test, label = label_test, return_pred=True, return_score=True, prob_method='linear')\n",
    "    \n",
    "    unique_values, counts = torch.unique(dominant_ip_pred_res, return_counts=True)\n",
    "    print(unique_values, counts)\n",
    "\n",
    "    predictions = dominant_ip_pred_res.numpy()\n",
    "    labels = label_test.numpy()\n",
    "    TP = np.sum((labels == 1) & (predictions == 1))\n",
    "    FN = np.sum((labels == 1) & (predictions == 0))\n",
    "    FP = np.sum((labels == 0) & (predictions == 1))\n",
    "    TN = np.sum((labels == 0) & (predictions == 0))\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(labels, predictions)\n",
    "\n",
    "    f1_pygod = eval_f1(label_test, dominant_ip_pred_res)\n",
    "    precision_pygod = eval_precision_at_k(label_test, dominant_ip_score_res)\n",
    "    recall_pygod = eval_recall_at_k(label_test, dominant_ip_score_res)\n",
    "    print(\"F1 score: \", f1_score)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(confusion_matrix)\n",
    "    return precision_pygod, recall_pygod, f1_pygod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 51.0959 |  | Time 3.66\n",
      "Epoch 0001: Loss 47.2797 |  | Time 14.61\n",
      "Epoch 0002: Loss 43.1999 |  | Time 14.71\n",
      "Epoch 0003: Loss 39.2517 |  | Time 14.66\n",
      "Epoch 0004: Loss 35.7830 |  | Time 14.71\n",
      "Epoch 0005: Loss 32.6781 |  | Time 14.61\n",
      "Epoch 0006: Loss 29.7531 |  | Time 14.59\n",
      "Epoch 0007: Loss 27.3400 |  | Time 14.70\n",
      "Epoch 0008: Loss 25.1656 |  | Time 14.70\n",
      "Epoch 0009: Loss 23.2403 |  | Time 14.59\n",
      "Epoch 0010: Loss 21.4210 |  | Time 14.60\n",
      "Epoch 0011: Loss 19.8593 |  | Time 14.68\n",
      "Epoch 0012: Loss 18.4028 |  | Time 14.81\n",
      "Epoch 0013: Loss 17.0949 |  | Time 14.74\n",
      "Epoch 0014: Loss 15.8632 |  | Time 14.86\n",
      "Epoch 0015: Loss 14.7636 |  | Time 14.66\n",
      "Epoch 0016: Loss 13.8048 |  | Time 14.78\n",
      "Epoch 0017: Loss 12.9547 |  | Time 14.80\n",
      "Epoch 0018: Loss 12.2212 |  | Time 14.81\n",
      "Epoch 0019: Loss 11.5913 |  | Time 14.82\n",
      "Epoch 0020: Loss 11.0514 |  | Time 14.76\n",
      "Epoch 0021: Loss 10.5942 |  | Time 14.80\n",
      "Epoch 0022: Loss 10.2035 |  | Time 14.87\n",
      "Epoch 0023: Loss 9.8593 |  | Time 14.79\n",
      "Epoch 0024: Loss 9.5454 |  | Time 14.63\n",
      "Epoch 0025: Loss 9.2603 |  | Time 14.87\n",
      "Epoch 0026: Loss 9.0055 |  | Time 14.88\n",
      "Epoch 0027: Loss 8.7786 |  | Time 14.71\n",
      "Epoch 0028: Loss 8.5996 |  | Time 14.88\n",
      "Epoch 0029: Loss 8.4807 |  | Time 15.20\n",
      "Epoch 0030: Loss 8.4076 |  | Time 14.87\n",
      "Epoch 0031: Loss 8.3610 |  | Time 14.91\n",
      "Epoch 0032: Loss 8.3064 |  | Time 14.79\n",
      "Epoch 0033: Loss 8.2310 |  | Time 14.84\n",
      "Epoch 0034: Loss 8.1519 |  | Time 14.79\n",
      "Epoch 0035: Loss 8.0873 |  | Time 14.80\n",
      "Epoch 0036: Loss 8.0311 |  | Time 14.77\n",
      "Epoch 0037: Loss 7.9679 |  | Time 14.82\n",
      "Epoch 0038: Loss 7.8782 |  | Time 14.82\n",
      "Epoch 0039: Loss 7.7870 |  | Time 14.78\n",
      "Epoch 0040: Loss 7.6678 |  | Time 14.85\n",
      "Epoch 0041: Loss 7.4987 |  | Time 14.85\n",
      "Epoch 0042: Loss 7.3595 |  | Time 14.89\n",
      "Epoch 0043: Loss 7.2180 |  | Time 14.74\n",
      "Epoch 0044: Loss 7.0530 |  | Time 14.77\n",
      "Epoch 0045: Loss 6.8971 |  | Time 14.73\n",
      "Epoch 0046: Loss 6.8780 |  | Time 14.80\n",
      "Epoch 0047: Loss 6.8903 |  | Time 15.00\n",
      "Epoch 0048: Loss 6.7560 |  | Time 14.71\n",
      "Epoch 0049: Loss 6.7482 |  | Time 14.81\n",
      "Epoch 0050: Loss 6.6804 |  | Time 14.78\n",
      "Epoch 0051: Loss 6.6846 |  | Time 14.73\n",
      "Epoch 0052: Loss 6.6436 |  | Time 14.79\n",
      "Epoch 0053: Loss 6.5870 |  | Time 14.92\n",
      "Epoch 0054: Loss 6.5407 |  | Time 14.77\n",
      "Epoch 0055: Loss 6.4438 |  | Time 14.78\n",
      "Epoch 0056: Loss 6.3731 |  | Time 14.80\n",
      "Epoch 0057: Loss 6.2340 |  | Time 14.78\n",
      "Epoch 0058: Loss 6.0175 |  | Time 14.81\n",
      "Epoch 0059: Loss 5.6640 |  | Time 14.83\n",
      "Epoch 0060: Loss 4.9839 |  | Time 14.76\n",
      "Epoch 0061: Loss 4.0519 |  | Time 14.78\n",
      "Epoch 0062: Loss 4.5296 |  | Time 14.82\n",
      "Epoch 0063: Loss 3.9823 |  | Time 14.76\n",
      "Epoch 0064: Loss 4.1304 |  | Time 14.73\n",
      "Epoch 0065: Loss 3.2021 |  | Time 14.80\n",
      "Epoch 0066: Loss 4.1126 |  | Time 14.82\n",
      "Epoch 0067: Loss 3.6766 |  | Time 14.71\n",
      "Epoch 0068: Loss 3.4836 |  | Time 14.68\n",
      "Epoch 0069: Loss 3.6105 |  | Time 14.71\n",
      "Epoch 0070: Loss 2.8052 |  | Time 14.62\n",
      "Epoch 0071: Loss 3.1367 |  | Time 14.75\n",
      "Epoch 0072: Loss 2.6651 |  | Time 14.78\n",
      "Epoch 0073: Loss 2.6105 |  | Time 14.82\n",
      "Epoch 0074: Loss 2.8677 |  | Time 14.80\n",
      "Epoch 0075: Loss 2.5070 |  | Time 14.77\n",
      "Epoch 0076: Loss 2.4621 |  | Time 14.76\n",
      "Epoch 0077: Loss 2.6462 |  | Time 14.81\n",
      "Epoch 0078: Loss 2.5306 |  | Time 14.71\n",
      "Epoch 0079: Loss 2.3070 |  | Time 14.81\n",
      "Epoch 0080: Loss 2.7860 |  | Time 14.62\n",
      "Epoch 0081: Loss 2.3696 |  | Time 14.86\n",
      "Epoch 0082: Loss 2.9752 |  | Time 14.76\n",
      "Epoch 0083: Loss 2.8423 |  | Time 14.75\n",
      "Epoch 0084: Loss 2.3585 |  | Time 14.73\n",
      "Epoch 0085: Loss 2.2556 |  | Time 14.68\n",
      "Epoch 0086: Loss 2.5872 |  | Time 14.78\n",
      "Epoch 0087: Loss 2.3522 |  | Time 14.77\n",
      "Epoch 0088: Loss 2.8171 |  | Time 14.65\n",
      "Epoch 0089: Loss 2.5757 |  | Time 14.76\n",
      "Epoch 0090: Loss 2.4584 |  | Time 15.13\n",
      "Epoch 0091: Loss 2.5545 |  | Time 14.78\n",
      "Epoch 0092: Loss 2.1294 |  | Time 14.91\n",
      "Epoch 0093: Loss 2.8430 |  | Time 14.83\n",
      "Epoch 0094: Loss 2.4876 |  | Time 14.76\n",
      "Epoch 0095: Loss 2.3686 |  | Time 14.70\n",
      "Epoch 0096: Loss 2.4796 |  | Time 14.74\n",
      "Epoch 0097: Loss 2.1510 |  | Time 14.76\n",
      "Epoch 0098: Loss 2.1968 |  | Time 14.75\n",
      "Epoch 0099: Loss 2.1745 |  | Time 14.73\n",
      "Test: Loss 0.0002 | AUC 0.8013 | Recall 0.7065 | Precision 0.7065 | AP 0.8062 | F1 0.7065 | Time 13.02\n",
      "tensor([0, 1]) tensor([5659, 3866])\n",
      "F1 score:  0.7008086253369271\n",
      "Precision:  0.7397827211588205\n",
      "Recall:  0.6657355679702048\n",
      "[[4223 1006]\n",
      " [1436 2860]]\n"
     ]
    }
   ],
   "source": [
    "dominant_model, graph_test = make_dominant_model(train_graph, train_node_features, label_train, test_graph, test_node_features)\n",
    "precision_score, recall_score, f1_score_for = predict_dominant(label_test, dominant_model, graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ini precision:  tensor(0.7065)\n",
      "ini recall:  tensor(0.7065)\n",
      "ini f1_score_unv:  0.7008086253369271\n"
     ]
    }
   ],
   "source": [
    "# print(\"ini f1: \", f1)\n",
    "print(\"ini precision: \", precision_score)\n",
    "print(\"ini recall: \", recall_score)\n",
    "print(\"ini f1_score_unv: \", f1_score_for)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ocgnn(label_test, ocgnn_compile, pyG_test):\n",
    "    ocgnn_ip_pred_res, ocgnn_ip_score_res = ocgnn_compile.predict(data=pyG_test, label = label_test,return_pred=True, return_score=True, prob_method='linear')\n",
    "    \n",
    "    unique_values, counts = torch.unique(ocgnn_ip_pred_res, return_counts=True)\n",
    "    print(unique_values, counts)\n",
    "\n",
    "    predictions = ocgnn_ip_pred_res.numpy()\n",
    "    labels = label_test.numpy()\n",
    "    TP = np.sum((labels == 1) & (predictions == 1))\n",
    "    FN = np.sum((labels == 1) & (predictions == 0))\n",
    "    FP = np.sum((labels == 0) & (predictions == 1))\n",
    "    TN = np.sum((labels == 0) & (predictions == 0))\n",
    "\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(labels, predictions)\n",
    "\n",
    "    precision_pygod = eval_precision_at_k(label_test, ocgnn_ip_score_res)\n",
    "    recall_pygod = eval_recall_at_k(label_test, ocgnn_ip_score_res)\n",
    "    f1_pygod = eval_f1(label_test, ocgnn_ip_pred_res)\n",
    "    \n",
    "    print(\"F1 score: \", f1_score)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(confusion_matrix)\n",
    "    return precision_pygod, recall_pygod, f1_pygod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ocgnn_model(train_graph, train_node_features, \n",
    "                        label_train, test_graph, test_node_features,\n",
    "                        label_test):\n",
    "    \n",
    "    train_node_features = torch.tensor(train_node_features)\n",
    "    label_train = torch.tensor(label_train)\n",
    "    test_node_features = torch.tensor(test_node_features)\n",
    "\n",
    "    pyG_train = from_networkx(train_graph)\n",
    "    pyG_train = pyG_train.cpu()\n",
    "    pyG_train.x = train_node_features.cpu()\n",
    "    label_train = label_train.cpu()\n",
    "\n",
    "    pyG_test = from_networkx(test_graph)\n",
    "    pyG_test = pyG_test\n",
    "    pyG_test.x = test_node_features\n",
    "\n",
    "    ocgnn_model = OCGNN(hid_dim=14, num_layers=16, weight_decay=1, \n",
    "                    contamination=0.37, lr=0.001, epoch=100, gpu=-1, verbose=3)\n",
    "    ocgnn_compile = ocgnn_model.fit(pyG_train)\n",
    "    return ocgnn_compile, pyG_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_ocgnn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir\\network-intrusion-detection\\nids-implementation\\nids_pgod_obs.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ocgnn_model, graph_test \u001b[39m=\u001b[39m make_ocgnn_model(train_graph, train_node_features, label_train, test_graph, test_node_features, label_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m make_model_runtime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m precision_score, recall_score, f1_score_for \u001b[39m=\u001b[39m predict_ocgnn(label_test, ocgnn_model, graph_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_ocgnn_model' is not defined"
     ]
    }
   ],
   "source": [
    "ocgnn_model, graph_test = make_ocgnn_model(train_graph, train_node_features, label_train, test_graph, test_node_features, label_test)\n",
    "make_model_runtime = time.time()\n",
    "precision_score, recall_score, f1_score_for = predict_ocgnn(label_test, ocgnn_model, graph_test)\n",
    "print(\"ini f1: \", f1_score_for)\n",
    "print(\"ini precision: \", precision_score)\n",
    "print(\"ini recall: \", recall_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_ocgnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir\\network-intrusion-detection\\nids-implementation\\nids_pgod_obs.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(f1_ocgnn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(precision_ocgnn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/nids-implementation/nids_pgod_obs.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(recall_ocgnn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1_ocgnn' is not defined"
     ]
    }
   ],
   "source": [
    "print(f1_ocgnn)\n",
    "print(precision_ocgnn)\n",
    "print(recall_ocgnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.998138189315796, 34.89245128631592, 37.14145493507385]\n",
      "[1.1997323036193848, 1.2506287097930908, 0.970118522644043]\n"
     ]
    }
   ],
   "source": [
    "print(train_durration_ocgnn)\n",
    "print(predict_durration_ocgnn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gae_model(train_graph, train_node_features, \n",
    "                        label_train, test_graph, test_node_features,\n",
    "                        label_test):\n",
    "    \n",
    "    pyG_train = from_networkx(train_graph)\n",
    "    pyG_train = pyG_train\n",
    "    pyG_train.x = train_node_features\n",
    "    label_train = label_train\n",
    "\n",
    "    pyG_test = from_networkx(test_graph)\n",
    "    pyG_test = pyG_test\n",
    "    pyG_test.x = test_node_features\n",
    "\n",
    "    gae_model = GAE(hid_dim=12, num_layers=12, weight_decay=3,\n",
    "                contamination=0.37, lr=0.001, epoch=100, gpu=-1,\n",
    "                verbose=3, recon_s=True, sigmoid_s=True)\n",
    "    \n",
    "    gae_compile = gae_model.fit(pyG_train, label_train)\n",
    "    return gae_compile, pyG_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gae(label_test, gae_compile, pyG_test):\n",
    "    gae_ip_pred_res, gae_ip_score_res = gae_compile.predict(data=pyG_test, label = label_test,return_pred=True, return_score=True, prob_method='linear')\n",
    "    f1_score_pygod = eval_f1(label_test, gae_ip_pred_res)\n",
    "    precision = eval_precision_at_k(label_test, gae_ip_score_res)\n",
    "    recall = eval_recall_at_k(label_test, gae_ip_score_res)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    unique_values, counts = torch.unique(gae_ip_pred_res, return_counts=True)\n",
    "    print(unique_values, counts)\n",
    "    print(\"F1 score: \", f1_score)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 score pygod: \", f1_score_pygod)\n",
    "    return f1_score_pygod, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 0.4872 | AUC 0.9597 | Recall 0.8432 | Precision 0.8432 | AP 0.9354 | F1 0.8432 | Time 3.81\n",
      "Epoch 0001: Loss 0.4623 | AUC 0.9597 | Recall 0.8432 | Precision 0.8432 | AP 0.9355 | F1 0.8432 | Time 3.86\n",
      "Epoch 0002: Loss 0.4387 | AUC 0.9598 | Recall 0.8433 | Precision 0.8433 | AP 0.9355 | F1 0.8433 | Time 3.92\n",
      "Epoch 0003: Loss 0.4167 | AUC 0.9598 | Recall 0.8433 | Precision 0.8433 | AP 0.9356 | F1 0.8433 | Time 3.93\n",
      "Epoch 0004: Loss 0.3962 | AUC 0.9598 | Recall 0.8432 | Precision 0.8432 | AP 0.9356 | F1 0.8432 | Time 3.90\n",
      "Epoch 0005: Loss 0.3773 | AUC 0.9599 | Recall 0.8432 | Precision 0.8432 | AP 0.9357 | F1 0.8432 | Time 4.00\n",
      "Epoch 0006: Loss 0.3601 | AUC 0.9599 | Recall 0.8433 | Precision 0.8433 | AP 0.9357 | F1 0.8433 | Time 4.09\n",
      "Epoch 0007: Loss 0.3447 | AUC 0.9600 | Recall 0.8433 | Precision 0.8433 | AP 0.9358 | F1 0.8433 | Time 4.00\n",
      "Epoch 0008: Loss 0.3313 | AUC 0.9600 | Recall 0.8437 | Precision 0.8437 | AP 0.9359 | F1 0.8437 | Time 3.92\n",
      "Epoch 0009: Loss 0.3195 | AUC 0.9600 | Recall 0.8437 | Precision 0.8437 | AP 0.9359 | F1 0.8437 | Time 3.94\n",
      "Epoch 0010: Loss 0.3094 | AUC 0.9601 | Recall 0.8439 | Precision 0.8439 | AP 0.9360 | F1 0.8439 | Time 3.99\n",
      "Epoch 0011: Loss 0.3007 | AUC 0.9601 | Recall 0.8439 | Precision 0.8439 | AP 0.9361 | F1 0.8439 | Time 4.03\n",
      "Epoch 0012: Loss 0.2933 | AUC 0.9602 | Recall 0.8441 | Precision 0.8441 | AP 0.9361 | F1 0.8441 | Time 4.05\n",
      "Epoch 0013: Loss 0.2869 | AUC 0.9602 | Recall 0.8443 | Precision 0.8443 | AP 0.9362 | F1 0.8443 | Time 4.07\n",
      "Epoch 0014: Loss 0.2815 | AUC 0.9602 | Recall 0.8443 | Precision 0.8443 | AP 0.9362 | F1 0.8443 | Time 4.04\n",
      "Epoch 0015: Loss 0.2769 | AUC 0.9603 | Recall 0.8445 | Precision 0.8445 | AP 0.9363 | F1 0.8445 | Time 4.06\n",
      "Epoch 0016: Loss 0.2731 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.05\n",
      "Epoch 0017: Loss 0.2699 | AUC 0.9603 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.01\n",
      "Epoch 0018: Loss 0.2674 | AUC 0.9603 | Recall 0.8450 | Precision 0.8450 | AP 0.9363 | F1 0.8450 | Time 4.14\n",
      "Epoch 0019: Loss 0.2653 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.05\n",
      "Epoch 0020: Loss 0.2636 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.08\n",
      "Epoch 0021: Loss 0.2621 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.11\n",
      "Epoch 0022: Loss 0.2610 | AUC 0.9601 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.08\n",
      "Epoch 0023: Loss 0.2600 | AUC 0.9601 | Recall 0.8448 | Precision 0.8448 | AP 0.9362 | F1 0.8448 | Time 4.10\n",
      "Epoch 0024: Loss 0.2592 | AUC 0.9600 | Recall 0.8448 | Precision 0.8448 | AP 0.9362 | F1 0.8448 | Time 4.37\n",
      "Epoch 0025: Loss 0.2585 | AUC 0.9600 | Recall 0.8450 | Precision 0.8450 | AP 0.9362 | F1 0.8450 | Time 4.60\n",
      "Epoch 0026: Loss 0.2579 | AUC 0.9600 | Recall 0.8450 | Precision 0.8450 | AP 0.9362 | F1 0.8450 | Time 4.37\n",
      "Epoch 0027: Loss 0.2573 | AUC 0.9600 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.13\n",
      "Epoch 0028: Loss 0.2568 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.24\n",
      "Epoch 0029: Loss 0.2564 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.22\n",
      "Epoch 0030: Loss 0.2560 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.43\n",
      "Epoch 0031: Loss 0.2557 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.08\n",
      "Epoch 0032: Loss 0.2554 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.31\n",
      "Epoch 0033: Loss 0.2551 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.23\n",
      "Epoch 0034: Loss 0.2549 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.12\n",
      "Epoch 0035: Loss 0.2547 | AUC 0.9598 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.25\n",
      "Epoch 0036: Loss 0.2545 | AUC 0.9598 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.07\n",
      "Epoch 0037: Loss 0.2543 | AUC 0.9598 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.10\n",
      "Epoch 0038: Loss 0.2541 | AUC 0.9598 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 3.98\n",
      "Epoch 0039: Loss 0.2539 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.10\n",
      "Epoch 0040: Loss 0.2538 | AUC 0.9599 | Recall 0.8450 | Precision 0.8450 | AP 0.9361 | F1 0.8450 | Time 4.14\n",
      "Epoch 0041: Loss 0.2537 | AUC 0.9599 | Recall 0.8450 | Precision 0.8450 | AP 0.9361 | F1 0.8450 | Time 4.16\n",
      "Epoch 0042: Loss 0.2535 | AUC 0.9599 | Recall 0.8450 | Precision 0.8450 | AP 0.9361 | F1 0.8450 | Time 4.09\n",
      "Epoch 0043: Loss 0.2534 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9361 | F1 0.8452 | Time 4.15\n",
      "Epoch 0044: Loss 0.2533 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.06\n",
      "Epoch 0045: Loss 0.2532 | AUC 0.9599 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.17\n",
      "Epoch 0046: Loss 0.2531 | AUC 0.9600 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.13\n",
      "Epoch 0047: Loss 0.2530 | AUC 0.9600 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.09\n",
      "Epoch 0048: Loss 0.2529 | AUC 0.9600 | Recall 0.8452 | Precision 0.8452 | AP 0.9362 | F1 0.8452 | Time 4.15\n",
      "Epoch 0049: Loss 0.2528 | AUC 0.9600 | Recall 0.8450 | Precision 0.8450 | AP 0.9362 | F1 0.8450 | Time 4.10\n",
      "Epoch 0050: Loss 0.2527 | AUC 0.9601 | Recall 0.8450 | Precision 0.8450 | AP 0.9363 | F1 0.8450 | Time 4.13\n",
      "Epoch 0051: Loss 0.2526 | AUC 0.9601 | Recall 0.8450 | Precision 0.8450 | AP 0.9363 | F1 0.8450 | Time 4.18\n",
      "Epoch 0052: Loss 0.2525 | AUC 0.9601 | Recall 0.8450 | Precision 0.8450 | AP 0.9363 | F1 0.8450 | Time 4.11\n",
      "Epoch 0053: Loss 0.2524 | AUC 0.9601 | Recall 0.8450 | Precision 0.8450 | AP 0.9363 | F1 0.8450 | Time 4.17\n",
      "Epoch 0054: Loss 0.2524 | AUC 0.9601 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.09\n",
      "Epoch 0055: Loss 0.2523 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.10\n",
      "Epoch 0056: Loss 0.2522 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.16\n",
      "Epoch 0057: Loss 0.2521 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.16\n",
      "Epoch 0058: Loss 0.2520 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.39\n",
      "Epoch 0059: Loss 0.2520 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.11\n",
      "Epoch 0060: Loss 0.2519 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.09\n",
      "Epoch 0061: Loss 0.2518 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.11\n",
      "Epoch 0062: Loss 0.2517 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.14\n",
      "Epoch 0063: Loss 0.2517 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.08\n",
      "Epoch 0064: Loss 0.2516 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.09\n",
      "Epoch 0065: Loss 0.2515 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.21\n",
      "Epoch 0066: Loss 0.2515 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.13\n",
      "Epoch 0067: Loss 0.2514 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.12\n",
      "Epoch 0068: Loss 0.2513 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.06\n",
      "Epoch 0069: Loss 0.2513 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.09\n",
      "Epoch 0070: Loss 0.2512 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.18\n",
      "Epoch 0071: Loss 0.2511 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.07\n",
      "Epoch 0072: Loss 0.2511 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.15\n",
      "Epoch 0073: Loss 0.2510 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.14\n",
      "Epoch 0074: Loss 0.2510 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.17\n",
      "Epoch 0075: Loss 0.2509 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.07\n",
      "Epoch 0076: Loss 0.2509 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.00\n",
      "Epoch 0077: Loss 0.2508 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.13\n",
      "Epoch 0078: Loss 0.2508 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.10\n",
      "Epoch 0079: Loss 0.2507 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.10\n",
      "Epoch 0080: Loss 0.2507 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.08\n",
      "Epoch 0081: Loss 0.2506 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.05\n",
      "Epoch 0082: Loss 0.2506 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8447 | Time 4.10\n",
      "Epoch 0083: Loss 0.2506 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.05\n",
      "Epoch 0084: Loss 0.2505 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8447 | Time 4.10\n",
      "Epoch 0085: Loss 0.2505 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.12\n",
      "Epoch 0086: Loss 0.2505 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.08\n",
      "Epoch 0087: Loss 0.2504 | AUC 0.9603 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8447 | Time 4.12\n",
      "Epoch 0088: Loss 0.2504 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.08\n",
      "Epoch 0089: Loss 0.2504 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.17\n",
      "Epoch 0090: Loss 0.2504 | AUC 0.9603 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.08\n",
      "Epoch 0091: Loss 0.2503 | AUC 0.9603 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.33\n",
      "Epoch 0092: Loss 0.2503 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.26\n",
      "Epoch 0093: Loss 0.2503 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.18\n",
      "Epoch 0094: Loss 0.2503 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8448 | Time 4.16\n",
      "Epoch 0095: Loss 0.2503 | AUC 0.9602 | Recall 0.8448 | Precision 0.8448 | AP 0.9363 | F1 0.8447 | Time 4.13\n",
      "Epoch 0096: Loss 0.2502 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.18\n",
      "Epoch 0097: Loss 0.2502 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.14\n",
      "Epoch 0098: Loss 0.2502 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9363 | F1 0.8446 | Time 4.05\n",
      "Epoch 0099: Loss 0.2502 | AUC 0.9602 | Recall 0.8446 | Precision 0.8446 | AP 0.9362 | F1 0.8446 | Time 4.25\n",
      "Test: Loss 0.0000 | AUC 0.9583 | Recall 0.8729 | Precision 0.8729 | AP 0.9500 | F1 0.8729 | Time 0.90\n",
      "tensor([0, 1]) tensor([4697, 4828])\n",
      "F1 score:  tensor(0.8729)\n",
      "Precision:  tensor(0.8729)\n",
      "Recall:  tensor(0.8729)\n",
      "F1 score pygod:  0.8599298553266111\n"
     ]
    }
   ],
   "source": [
    "gae_model, graph_test = make_gae_model(train_graph, train_node_features, label_train, test_graph, test_node_features, label_test)\n",
    "f1_score_pygod, precision_score, recall_score, f1_score = predict_gae(label_test, gae_model, graph_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
