{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from pygod.detector import ANOMALOUS, SCAN, Radar, DOMINANT, OCGNN, GUIDE\n",
    "from pygod.metric import eval_average_precision, eval_roc_auc, eval_f1, eval_precision_at_k, eval_recall_at_k\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_train = pickle.load(open('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/nD_graph_train.pickle', 'rb'))\n",
    "node_features_train = torch.load('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/node_features_train.pt')\n",
    "labels_train = torch.load('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/labels_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4307.],\n",
       "        [4307.],\n",
       "        [4307.],\n",
       "        ...,\n",
       "        [4307.],\n",
       "        [4307.],\n",
       "        [4307.]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_test = pickle.load(open('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/nD_graph_test.pickle', 'rb'))\n",
    "node_features_test = torch.load('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/node_features_test.pt')\n",
    "labels_test = torch.load('C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb/graph_modeling/te/labels_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyG_train = from_networkx(nD_graph_train)\n",
    "pyG_train = pyG_train.cuda()\n",
    "pyG_train.x = node_features_train\n",
    "\n",
    "pyG_test = from_networkx(nD_graph_test)\n",
    "pyG_test.x = node_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2227,  222], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test = pd.read_parquet(\"C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb\\\\test.parquet\")\n",
    "label = test['is_malware'].to_numpy()\n",
    "# Switch the values 0 and 1 in the label variable\n",
    "# label = np.where(label == 0, 1, np.where(label == 1, 0, label))\n",
    "value_counts = np.unique(label, return_counts=True)\n",
    "# Convert label to a tensor torch\n",
    "label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "#convert label to tensor torch\n",
    "# label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int32' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-2.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-2.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39masus\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDocuments\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtugas-akhir-latest-update\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mdata-prep-related\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mgraph_modeling\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mfix-ipnyb\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtrain.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-2.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m label_train \u001b[39m=\u001b[39m train[\u001b[39m'\u001b[39;49m\u001b[39mis_malware\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto_numpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-2.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Switch the values 0 and 1 in the label variable\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-2.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# label = np.where(label == 0, 1, np.where(label == 1, 0, label))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-2.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m value_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(label_train, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int32' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"C:\\\\Users\\\\asus\\\\Documents\\\\tugas-akhir-latest-update\\\\data-prep-related\\\\graph_modeling\\\\fix-ipnyb\\\\train.parquet\")\n",
    "label_train = train['is_malware'].iloc[0].to_numpy()\n",
    "# Switch the values 0 and 1 in the label variable\n",
    "# label = np.where(label == 0, 1, np.where(label == 1, 0, label))\n",
    "value_counts = np.unique(label_train, return_counts=True)\n",
    "# Convert label to a tensor torch\n",
    "label_tensor_train = torch.tensor(label, dtype=torch.float)\n",
    "#convert label to tensor torch\n",
    "# label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "value_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOMALOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOMINANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_model = DOMINANT(gpu=0, weight=0.02, num_layers=128, hid_dim=64, contamination=0.1, lr=0.001, verbose=3, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 87.5195 |  | Time 0.66\n",
      "Epoch 0001: Loss 87.5194 |  | Time 0.59\n",
      "Epoch 0002: Loss 87.5191 |  | Time 0.64\n",
      "Epoch 0003: Loss 87.5185 |  | Time 0.56\n",
      "Epoch 0004: Loss 87.5208 |  | Time 0.55\n",
      "Epoch 0005: Loss 87.5179 |  | Time 0.78\n",
      "Epoch 0006: Loss 87.5177 |  | Time 1.01\n",
      "Epoch 0007: Loss 87.5172 |  | Time 0.65\n",
      "Epoch 0008: Loss 87.5165 |  | Time 0.65\n",
      "Epoch 0009: Loss 87.5156 |  | Time 0.57\n",
      "Epoch 0010: Loss 87.5144 |  | Time 0.49\n",
      "Epoch 0011: Loss 87.5131 |  | Time 0.51\n",
      "Epoch 0012: Loss 87.5113 |  | Time 0.51\n",
      "Epoch 0013: Loss 87.5088 |  | Time 0.53\n",
      "Epoch 0014: Loss 87.5053 |  | Time 0.53\n",
      "Epoch 0015: Loss 87.5004 |  | Time 0.54\n",
      "Epoch 0016: Loss 87.4933 |  | Time 0.50\n",
      "Epoch 0017: Loss 87.4827 |  | Time 0.50\n",
      "Epoch 0018: Loss 87.4665 |  | Time 0.56\n",
      "Epoch 0019: Loss 87.4410 |  | Time 0.73\n",
      "Epoch 0020: Loss 87.4002 |  | Time 0.68\n",
      "Epoch 0021: Loss 87.3333 |  | Time 0.66\n",
      "Epoch 0022: Loss 87.2205 |  | Time 0.49\n",
      "Epoch 0023: Loss 87.0261 |  | Time 0.51\n",
      "Epoch 0024: Loss 86.6822 |  | Time 0.49\n",
      "Epoch 0025: Loss 86.0597 |  | Time 0.49\n",
      "Epoch 0026: Loss 84.8976 |  | Time 0.49\n",
      "Epoch 0027: Loss 82.6614 |  | Time 0.48\n",
      "Epoch 0028: Loss 78.2272 |  | Time 0.49\n",
      "Epoch 0029: Loss 69.0979 |  | Time 0.48\n",
      "Epoch 0030: Loss 49.6404 |  | Time 0.49\n",
      "Epoch 0031: Loss 6.4072 |  | Time 0.50\n",
      "Epoch 0032: Loss 97.3107 |  | Time 0.50\n",
      "Epoch 0033: Loss 65.6859 |  | Time 0.49\n",
      "Epoch 0034: Loss 11.2679 |  | Time 0.51\n",
      "Epoch 0035: Loss 31.4167 |  | Time 0.50\n",
      "Epoch 0036: Loss 48.2139 |  | Time 0.57\n",
      "Epoch 0037: Loss 56.6289 |  | Time 0.51\n",
      "Epoch 0038: Loss 61.1805 |  | Time 0.52\n",
      "Epoch 0039: Loss 63.6238 |  | Time 0.49\n",
      "Epoch 0040: Loss 64.7361 |  | Time 0.49\n",
      "Epoch 0041: Loss 64.8698 |  | Time 0.49\n",
      "Epoch 0042: Loss 64.1631 |  | Time 0.49\n",
      "Epoch 0043: Loss 62.6197 |  | Time 0.49\n",
      "Epoch 0044: Loss 60.1110 |  | Time 0.50\n",
      "Epoch 0045: Loss 56.3577 |  | Time 0.51\n",
      "Epoch 0046: Loss 50.8420 |  | Time 0.49\n",
      "Epoch 0047: Loss 42.6315 |  | Time 0.48\n",
      "Epoch 0048: Loss 29.9671 |  | Time 0.50\n",
      "Epoch 0049: Loss 9.2625 |  | Time 0.52\n",
      "Epoch 0050: Loss 30.1798 |  | Time 0.49\n",
      "Epoch 0051: Loss 50.8232 |  | Time 0.50\n",
      "Epoch 0052: Loss 45.5288 |  | Time 0.51\n",
      "Epoch 0053: Loss 22.3907 |  | Time 0.49\n",
      "Epoch 0054: Loss 7.9115 |  | Time 0.54\n",
      "Epoch 0055: Loss 20.3072 |  | Time 0.52\n",
      "Epoch 0056: Loss 25.0657 |  | Time 0.52\n",
      "Epoch 0057: Loss 24.7217 |  | Time 0.51\n",
      "Epoch 0058: Loss 19.7809 |  | Time 0.49\n",
      "Epoch 0059: Loss 9.3135 |  | Time 0.49\n",
      "Epoch 0060: Loss 12.3809 |  | Time 0.51\n",
      "Epoch 0061: Loss 20.9819 |  | Time 0.50\n",
      "Epoch 0062: Loss 16.9972 |  | Time 0.52\n",
      "Epoch 0063: Loss 4.0837 |  | Time 0.50\n",
      "Epoch 0064: Loss 16.0852 |  | Time 0.49\n",
      "Epoch 0065: Loss 23.9549 |  | Time 0.51\n",
      "Epoch 0066: Loss 26.4064 |  | Time 0.53\n",
      "Epoch 0067: Loss 24.7336 |  | Time 0.52\n",
      "Epoch 0068: Loss 18.9700 |  | Time 0.52\n",
      "Epoch 0069: Loss 8.0205 |  | Time 0.49\n",
      "Epoch 0070: Loss 13.7356 |  | Time 0.52\n",
      "Epoch 0071: Loss 23.2892 |  | Time 0.53\n",
      "Epoch 0072: Loss 20.7085 |  | Time 0.49\n",
      "Epoch 0073: Loss 8.6309 |  | Time 0.56\n",
      "Epoch 0074: Loss 11.0681 |  | Time 0.57\n",
      "Epoch 0075: Loss 18.6001 |  | Time 0.52\n",
      "Epoch 0076: Loss 20.5001 |  | Time 0.50\n",
      "Epoch 0077: Loss 17.9160 |  | Time 0.50\n",
      "Epoch 0078: Loss 10.6534 |  | Time 0.49\n",
      "Epoch 0079: Loss 5.8731 |  | Time 0.51\n",
      "Epoch 0080: Loss 11.5045 |  | Time 0.51\n",
      "Epoch 0081: Loss 8.5998 |  | Time 0.58\n",
      "Epoch 0082: Loss 4.2547 |  | Time 0.57\n",
      "Epoch 0083: Loss 6.2750 |  | Time 0.58\n",
      "Epoch 0084: Loss 2.1759 |  | Time 0.52\n",
      "Epoch 0085: Loss 10.7998 |  | Time 0.51\n",
      "Epoch 0086: Loss 12.0196 |  | Time 0.50\n",
      "Epoch 0087: Loss 5.3935 |  | Time 0.51\n",
      "Epoch 0088: Loss 9.6914 |  | Time 0.51\n",
      "Epoch 0089: Loss 14.1804 |  | Time 0.52\n",
      "Epoch 0090: Loss 13.3444 |  | Time 0.51\n",
      "Epoch 0091: Loss 7.5263 |  | Time 0.51\n",
      "Epoch 0092: Loss 7.3874 |  | Time 0.50\n",
      "Epoch 0093: Loss 11.5371 |  | Time 0.50\n",
      "Epoch 0094: Loss 7.6794 |  | Time 0.55\n",
      "Epoch 0095: Loss 5.4550 |  | Time 0.51\n",
      "Epoch 0096: Loss 8.0941 |  | Time 0.53\n",
      "Epoch 0097: Loss 4.9054 |  | Time 0.55\n",
      "Epoch 0098: Loss 7.3962 |  | Time 0.54\n",
      "Epoch 0099: Loss 9.0220 |  | Time 0.52\n"
     ]
    }
   ],
   "source": [
    "dominant_compile = dominant_model.fit(pyG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0164 | AUC 0.4785 | Recall 0.0631 | Precision 0.0631 | AP 0.0831 | F1 0.0559 | Time 0.60\n",
      "tensor([1]) tensor([2449])\n"
     ]
    }
   ],
   "source": [
    "dominant_ip_pred_res, dominant_ip_score_res, dominant_ip_prob_res, dominant_ip_conf_res = dominant_compile.predict(data=pyG_test, label=label_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(dominant_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocgnn_model = OCGNN(hid_dim=64, num_layers=64, weight_decay=0.02, \n",
    "                    contamination=0.1, lr=0.001, epoch=100, gpu=-1, batch_size=0, num_neigh=-1, \n",
    "                    beta=0.5, warmup=2, eps=0.001, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 0.0000 |  | Time 1.05\n",
      "Epoch 0001: Loss 0.0006 |  | Time 0.99\n",
      "Epoch 0002: Loss 0.0003 |  | Time 0.94\n",
      "Epoch 0003: Loss 0.0005 |  | Time 0.98\n",
      "Epoch 0004: Loss 0.0003 |  | Time 0.96\n",
      "Epoch 0005: Loss 0.0003 |  | Time 0.97\n",
      "Epoch 0006: Loss 0.0003 |  | Time 1.02\n",
      "Epoch 0007: Loss 0.0003 |  | Time 1.11\n",
      "Epoch 0008: Loss 0.0003 |  | Time 1.03\n",
      "Epoch 0009: Loss 0.0003 |  | Time 0.99\n",
      "Epoch 0010: Loss 0.0003 |  | Time 2.62\n",
      "Epoch 0011: Loss 0.0003 |  | Time 2.49\n",
      "Epoch 0012: Loss 0.0003 |  | Time 2.68\n",
      "Epoch 0013: Loss 0.0003 |  | Time 1.98\n",
      "Epoch 0014: Loss 0.0003 |  | Time 1.80\n",
      "Epoch 0015: Loss 0.0003 |  | Time 2.06\n",
      "Epoch 0016: Loss 0.0003 |  | Time 1.28\n",
      "Epoch 0017: Loss 0.0003 |  | Time 1.54\n",
      "Epoch 0018: Loss 0.0003 |  | Time 1.37\n",
      "Epoch 0019: Loss 0.0003 |  | Time 1.29\n",
      "Epoch 0020: Loss 0.0003 |  | Time 1.64\n",
      "Epoch 0021: Loss 0.0003 |  | Time 1.43\n",
      "Epoch 0022: Loss 0.0003 |  | Time 1.16\n",
      "Epoch 0023: Loss 0.0003 |  | Time 1.09\n",
      "Epoch 0024: Loss 0.0003 |  | Time 1.09\n",
      "Epoch 0025: Loss 0.0003 |  | Time 1.20\n",
      "Epoch 0026: Loss 0.0003 |  | Time 1.06\n",
      "Epoch 0027: Loss 0.0003 |  | Time 1.36\n",
      "Epoch 0028: Loss 0.0003 |  | Time 1.24\n",
      "Epoch 0029: Loss 0.0003 |  | Time 1.22\n",
      "Epoch 0030: Loss 0.0003 |  | Time 1.20\n",
      "Epoch 0031: Loss 0.0003 |  | Time 1.08\n",
      "Epoch 0032: Loss 0.0003 |  | Time 0.99\n",
      "Epoch 0033: Loss 0.0003 |  | Time 0.96\n",
      "Epoch 0034: Loss 0.0003 |  | Time 0.99\n",
      "Epoch 0035: Loss 0.0003 |  | Time 1.02\n",
      "Epoch 0036: Loss 0.0003 |  | Time 0.91\n",
      "Epoch 0037: Loss 0.0003 |  | Time 0.87\n",
      "Epoch 0038: Loss 0.0003 |  | Time 0.87\n",
      "Epoch 0039: Loss 0.0003 |  | Time 0.86\n",
      "Epoch 0040: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0041: Loss 0.0003 |  | Time 0.95\n",
      "Epoch 0042: Loss 0.0003 |  | Time 1.12\n",
      "Epoch 0043: Loss 0.0003 |  | Time 1.05\n",
      "Epoch 0044: Loss 0.0003 |  | Time 1.03\n",
      "Epoch 0045: Loss 0.0003 |  | Time 0.95\n",
      "Epoch 0046: Loss 0.0003 |  | Time 0.96\n",
      "Epoch 0047: Loss 0.0003 |  | Time 0.89\n",
      "Epoch 0048: Loss 0.0003 |  | Time 0.85\n",
      "Epoch 0049: Loss 0.0003 |  | Time 1.06\n",
      "Epoch 0050: Loss 0.0003 |  | Time 1.21\n",
      "Epoch 0051: Loss 0.0003 |  | Time 0.99\n",
      "Epoch 0052: Loss 0.0003 |  | Time 0.94\n",
      "Epoch 0053: Loss 0.0003 |  | Time 1.01\n",
      "Epoch 0054: Loss 0.0003 |  | Time 0.92\n",
      "Epoch 0055: Loss 0.0003 |  | Time 1.74\n",
      "Epoch 0056: Loss 0.0003 |  | Time 1.74\n",
      "Epoch 0057: Loss 0.0003 |  | Time 1.07\n",
      "Epoch 0058: Loss 0.0003 |  | Time 1.09\n",
      "Epoch 0059: Loss 0.0003 |  | Time 1.58\n",
      "Epoch 0060: Loss 0.0003 |  | Time 1.55\n",
      "Epoch 0061: Loss 0.0003 |  | Time 1.45\n",
      "Epoch 0062: Loss 0.0003 |  | Time 1.41\n",
      "Epoch 0063: Loss 0.0003 |  | Time 1.14\n",
      "Epoch 0064: Loss 0.0003 |  | Time 1.05\n",
      "Epoch 0065: Loss 0.0003 |  | Time 1.04\n",
      "Epoch 0066: Loss 0.0003 |  | Time 1.04\n",
      "Epoch 0067: Loss 0.0003 |  | Time 1.03\n",
      "Epoch 0068: Loss 0.0003 |  | Time 1.16\n",
      "Epoch 0069: Loss 0.0003 |  | Time 1.08\n",
      "Epoch 0070: Loss 0.0003 |  | Time 0.97\n",
      "Epoch 0071: Loss 0.0003 |  | Time 1.13\n",
      "Epoch 0072: Loss 0.0003 |  | Time 0.91\n",
      "Epoch 0073: Loss 0.0003 |  | Time 0.87\n",
      "Epoch 0074: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0075: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0076: Loss 0.0003 |  | Time 0.89\n",
      "Epoch 0077: Loss 0.0003 |  | Time 0.93\n",
      "Epoch 0078: Loss 0.0003 |  | Time 0.88\n",
      "Epoch 0079: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0080: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0081: Loss 0.0003 |  | Time 0.88\n",
      "Epoch 0082: Loss 0.0003 |  | Time 0.91\n",
      "Epoch 0083: Loss 0.0003 |  | Time 0.84\n",
      "Epoch 0084: Loss 0.0003 |  | Time 0.86\n",
      "Epoch 0085: Loss 0.0003 |  | Time 0.86\n",
      "Epoch 0086: Loss 0.0003 |  | Time 0.91\n",
      "Epoch 0087: Loss 0.0003 |  | Time 0.87\n",
      "Epoch 0088: Loss 0.0003 |  | Time 0.88\n",
      "Epoch 0089: Loss 0.0003 |  | Time 0.87\n",
      "Epoch 0090: Loss 0.0003 |  | Time 0.85\n",
      "Epoch 0091: Loss 0.0003 |  | Time 0.85\n",
      "Epoch 0092: Loss 0.0003 |  | Time 0.85\n",
      "Epoch 0093: Loss 0.0003 |  | Time 0.84\n",
      "Epoch 0094: Loss 0.0003 |  | Time 0.82\n",
      "Epoch 0095: Loss 0.0003 |  | Time 0.90\n",
      "Epoch 0096: Loss 0.0003 |  | Time 0.82\n",
      "Epoch 0097: Loss 0.0003 |  | Time 0.85\n",
      "Epoch 0098: Loss 0.0003 |  | Time 0.86\n",
      "Epoch 0099: Loss 0.0003 |  | Time 0.85\n"
     ]
    }
   ],
   "source": [
    "ocgnn_compile = ocgnn_model.fit(pyG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0000 | AUC 0.5056 | Recall 0.2568 | Precision 0.2568 | AP 0.0919 | F1 0.0460 | Time 0.33\n",
      "tensor([0]) tensor([2449])\n"
     ]
    }
   ],
   "source": [
    "ocgnn_ip_pred_res, ocgnn_ip_score_res, ocgnn_ip_prob_res, ocgnn_ip_conf_res = ocgnn_compile.predict(data=pyG_test, label=label_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(ocgnn_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_model = GUIDE(num_layers=4, hid_a=64, hid_s=64, weight_decay=0.02, alpha=1, \n",
    "                    contamination=0.1, lr=0.001, epoch=100, gpu=-1, batch_size=0, num_neigh=-1, \n",
    "                    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 4817.6006 |  | Time 0.15\n",
      "Epoch 0001: Loss 4594.2217 |  | Time 0.14\n",
      "Epoch 0002: Loss 4389.7432 |  | Time 0.15\n",
      "Epoch 0003: Loss 4209.9419 |  | Time 0.13\n",
      "Epoch 0004: Loss 4037.5686 |  | Time 0.15\n",
      "Epoch 0005: Loss 3860.9883 |  | Time 0.14\n",
      "Epoch 0006: Loss 3683.4875 |  | Time 0.14\n",
      "Epoch 0007: Loss 3503.2329 |  | Time 0.15\n",
      "Epoch 0008: Loss 3317.2200 |  | Time 0.15\n",
      "Epoch 0009: Loss 3142.2161 |  | Time 0.14\n",
      "Epoch 0010: Loss 2984.1731 |  | Time 0.15\n",
      "Epoch 0011: Loss 2816.3494 |  | Time 0.13\n",
      "Epoch 0012: Loss 2642.0928 |  | Time 0.14\n",
      "Epoch 0013: Loss 2458.7939 |  | Time 0.12\n",
      "Epoch 0014: Loss 2272.1636 |  | Time 0.13\n",
      "Epoch 0015: Loss 2075.0476 |  | Time 0.11\n",
      "Epoch 0016: Loss 1867.0857 |  | Time 0.14\n",
      "Epoch 0017: Loss 1648.5952 |  | Time 0.14\n",
      "Epoch 0018: Loss 1439.9185 |  | Time 0.13\n",
      "Epoch 0019: Loss 1224.2949 |  | Time 0.12\n",
      "Epoch 0020: Loss 995.1100 |  | Time 0.13\n",
      "Epoch 0021: Loss 746.9553 |  | Time 0.12\n",
      "Epoch 0022: Loss 483.6100 |  | Time 0.12\n",
      "Epoch 0023: Loss 204.3717 |  | Time 0.12\n",
      "Epoch 0024: Loss 111.0763 |  | Time 0.14\n",
      "Epoch 0025: Loss 320.1948 |  | Time 0.13\n",
      "Epoch 0026: Loss 454.8388 |  | Time 0.13\n",
      "Epoch 0027: Loss 525.6268 |  | Time 0.13\n",
      "Epoch 0028: Loss 545.9500 |  | Time 0.12\n",
      "Epoch 0029: Loss 524.9965 |  | Time 0.13\n",
      "Epoch 0030: Loss 462.1198 |  | Time 0.11\n",
      "Epoch 0031: Loss 366.6575 |  | Time 0.14\n",
      "Epoch 0032: Loss 244.8640 |  | Time 0.17\n",
      "Epoch 0033: Loss 102.0543 |  | Time 0.15\n",
      "Epoch 0034: Loss 75.0549 |  | Time 0.13\n",
      "Epoch 0035: Loss 163.2630 |  | Time 0.12\n",
      "Epoch 0036: Loss 209.6178 |  | Time 0.14\n",
      "Epoch 0037: Loss 218.4373 |  | Time 0.12\n",
      "Epoch 0038: Loss 194.6743 |  | Time 0.12\n",
      "Epoch 0039: Loss 141.7237 |  | Time 0.13\n",
      "Epoch 0040: Loss 65.2773 |  | Time 0.14\n",
      "Epoch 0041: Loss 65.2254 |  | Time 0.13\n",
      "Epoch 0042: Loss 124.2258 |  | Time 0.13\n",
      "Epoch 0043: Loss 143.3448 |  | Time 0.13\n",
      "Epoch 0044: Loss 127.0589 |  | Time 0.12\n",
      "Epoch 0045: Loss 79.8648 |  | Time 0.12\n",
      "Epoch 0046: Loss 24.3066 |  | Time 0.15\n",
      "Epoch 0047: Loss 59.0666 |  | Time 0.14\n",
      "Epoch 0048: Loss 63.5407 |  | Time 0.14\n",
      "Epoch 0049: Loss 40.2357 |  | Time 0.14\n",
      "Epoch 0050: Loss 40.1596 |  | Time 0.13\n",
      "Epoch 0051: Loss 55.1782 |  | Time 0.12\n",
      "Epoch 0052: Loss 37.7304 |  | Time 0.15\n",
      "Epoch 0053: Loss 37.7126 |  | Time 0.16\n",
      "Epoch 0054: Loss 49.9791 |  | Time 0.13\n",
      "Epoch 0055: Loss 35.0707 |  | Time 0.13\n",
      "Epoch 0056: Loss 36.9221 |  | Time 0.14\n",
      "Epoch 0057: Loss 44.8306 |  | Time 0.13\n",
      "Epoch 0058: Loss 21.7858 |  | Time 0.15\n",
      "Epoch 0059: Loss 56.5055 |  | Time 0.14\n",
      "Epoch 0060: Loss 73.2424 |  | Time 0.11\n",
      "Epoch 0061: Loss 61.6869 |  | Time 0.12\n",
      "Epoch 0062: Loss 26.1562 |  | Time 0.14\n",
      "Epoch 0063: Loss 66.3252 |  | Time 0.13\n",
      "Epoch 0064: Loss 92.3716 |  | Time 0.14\n",
      "Epoch 0065: Loss 85.7005 |  | Time 0.13\n",
      "Epoch 0066: Loss 49.9714 |  | Time 0.13\n",
      "Epoch 0067: Loss 40.4441 |  | Time 0.12\n",
      "Epoch 0068: Loss 66.3928 |  | Time 0.12\n",
      "Epoch 0069: Loss 63.9072 |  | Time 0.12\n",
      "Epoch 0070: Loss 36.0784 |  | Time 0.13\n",
      "Epoch 0071: Loss 47.4539 |  | Time 0.13\n",
      "Epoch 0072: Loss 66.8957 |  | Time 0.13\n",
      "Epoch 0073: Loss 55.0130 |  | Time 0.14\n",
      "Epoch 0074: Loss 16.0910 |  | Time 0.14\n",
      "Epoch 0075: Loss 24.7627 |  | Time 0.12\n",
      "Epoch 0076: Loss 22.9975 |  | Time 0.22\n",
      "Epoch 0077: Loss 21.0559 |  | Time 0.13\n",
      "Epoch 0078: Loss 23.7954 |  | Time 0.13\n",
      "Epoch 0079: Loss 22.9675 |  | Time 0.13\n",
      "Epoch 0080: Loss 18.9854 |  | Time 0.14\n",
      "Epoch 0081: Loss 29.5075 |  | Time 0.14\n",
      "Epoch 0082: Loss 20.4123 |  | Time 0.12\n",
      "Epoch 0083: Loss 45.3745 |  | Time 0.13\n",
      "Epoch 0084: Loss 47.9381 |  | Time 0.15\n",
      "Epoch 0085: Loss 21.4217 |  | Time 0.12\n",
      "Epoch 0086: Loss 58.6027 |  | Time 0.14\n",
      "Epoch 0087: Loss 78.1571 |  | Time 0.15\n",
      "Epoch 0088: Loss 70.0811 |  | Time 0.14\n",
      "Epoch 0089: Loss 37.7417 |  | Time 0.13\n",
      "Epoch 0090: Loss 49.3700 |  | Time 0.13\n",
      "Epoch 0091: Loss 72.7675 |  | Time 0.12\n",
      "Epoch 0092: Loss 64.9497 |  | Time 0.12\n",
      "Epoch 0093: Loss 29.2357 |  | Time 0.12\n",
      "Epoch 0094: Loss 58.7929 |  | Time 0.12\n",
      "Epoch 0095: Loss 85.3883 |  | Time 0.14\n",
      "Epoch 0096: Loss 83.8652 |  | Time 0.14\n",
      "Epoch 0097: Loss 57.1191 |  | Time 0.12\n",
      "Epoch 0098: Loss 22.3140 |  | Time 0.18\n",
      "Epoch 0099: Loss 40.4866 |  | Time 0.12\n"
     ]
    }
   ],
   "source": [
    "guide_compile = guide_model.fit(pyG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0093 | AUC 0.4772 | Recall 0.0541 | Precision 0.0541 | AP 0.0879 | F1 0.0562 | Time 0.02\n"
     ]
    }
   ],
   "source": [
    "guide_ip_pred_res, guide_ip_score_res, guide_ip_prob_res, guide_ip_conf_res = guide_compile.predict(data=pyG_test, label=label_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
