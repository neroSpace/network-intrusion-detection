{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import parquet file\n",
    "unsw_w_st = pd.read_parquet(\"C:\\\\Users\\\\asus\\\\Documents\\\\nids-pcap-dataset\\\\unsw_parquet_used_dataset\\\\labeled_wo_start_time_w_dup[port].parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 125325 entries, 1 to 490022\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   source_ip         125325 non-null  object  \n",
      " 1   destination_ip    125325 non-null  object  \n",
      " 2   source_port       125325 non-null  object  \n",
      " 3   destination_port  125325 non-null  object  \n",
      " 4   info_message      125325 non-null  object  \n",
      " 5   attack_category   15801 non-null   category\n",
      " 6   is_malware        125325 non-null  int64   \n",
      " 7   source_ip_info    125325 non-null  object  \n",
      " 8   source_port_info  125325 non-null  object  \n",
      " 9   dest_ip_info      125325 non-null  object  \n",
      " 10  dest_port_info    125325 non-null  object  \n",
      " 11  count_benign      125325 non-null  int64   \n",
      " 12  count_malware     125325 non-null  int64   \n",
      "dtypes: category(1), int64(3), object(9)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "unsw_w_st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_w_st['source_port'] = unsw_w_st.source_port.astype('int32')\n",
    "unsw_w_st['destination_port']= unsw_w_st.destination_port.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "unsw_w_st['sip_ohe'] = label_encoder.fit_transform(unsw_w_st.source_ip.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_w_st['lensip'] = unsw_w_st.info_message.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sip_ohe\n",
       "2    3652\n",
       "0    3710\n",
       "1    3764\n",
       "3    3925\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsw_w_st.loc[unsw_w_st['is_malware'] == 1, 'sip_ohe'].value_counts().sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nD_unsw_w_st = unsw_w_st.drop_duplicates(subset=['source_port_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(unsw_w_st, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    77148\n",
       "1    10579\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    61715\n",
       "1     9774\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_train_df = train_df.drop_duplicates(subset=['source_port_info'])\n",
    "nD_train_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = nD_train_df.is_malware.value_counts()\n",
    "if value_counts[0] > 9774 and value_counts[1] > 1000:\n",
    "    df_to_lower_benign = nD_train_df[nD_train_df['is_malware'] == 0].sample(n=9774, random_state=0)\n",
    "    df_to_lower_malicious = nD_train_df[nD_train_df['is_malware'] == 1].sample(n=1000, random_state=0)\n",
    "    nD_train_df = pd.concat([df_to_lower_benign, df_to_lower_malicious])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([9774, 1000], dtype=int64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = nD_train_df['is_malware'].to_numpy()\n",
    "label_train_tensor = torch.tensor(label_train, dtype=torch.float)\n",
    "value_counts = np.unique(label_train, return_counts=True)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10774"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nD_train_df.source_port_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    33126\n",
       "1     4472\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    29902\n",
       "1     4260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_test_df = test_df.drop_duplicates(subset=['source_port_info'])\n",
    "nD_test_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = nD_test_df.is_malware.value_counts()\n",
    "if value_counts[0] > 4260:\n",
    "    df_to_lower_benign = nD_test_df[nD_test_df['is_malware'] == 0].sample(n=4260, random_state=0)\n",
    "    nD_test_df = pd.concat([df_to_lower_benign, nD_test_df[nD_test_df['is_malware'] == 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([4260, 4260], dtype=int64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test = nD_test_df['is_malware'].to_numpy()\n",
    "value_counts = np.unique(label_test, return_counts=True)\n",
    "label_test_tensor = torch.tensor(label_test, dtype=torch.float)\n",
    "value_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_train = nx.Graph()\n",
    "node_features = []\n",
    "attr = []\n",
    "labels = []\n",
    "\n",
    "for source_port_info in nD_train_df[\"source_port_info\"].unique():\n",
    "    nD_graph_train.add_node(source_port_info)\n",
    "    source_ip = nD_train_df[nD_train_df[\"source_port_info\"] == source_port_info][\"sip_ohe\"].iloc[0]\n",
    "    info_message = nD_train_df[nD_train_df[\"source_port_info\"] == source_port_info][\"info_message\"].iloc[0]\n",
    "    node_features.append([float(len(info_message))])\n",
    "    \n",
    "for (source_ip), group in nD_train_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"source_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"source_port_info\"]\n",
    "        if nD_graph_train.has_edge(from_node, to_node):\n",
    "            nD_graph_train[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_train.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor = torch.tensor(node_features)\n",
    "node_features_tensor = node_features_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.],\n",
       "        [28.],\n",
       "        [28.],\n",
       "        ...,\n",
       "        [51.],\n",
       "        [27.],\n",
       "        [52.]], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = list(nx.isolates(nD_graph_train))\n",
    "\n",
    "print(\"Isolated nodes:\", len(isolated_nodes), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 10774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print num of nodes\n",
    "print(\"Number of nodes:\", nD_graph_train.number_of_nodes(), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_test = nx.Graph()\n",
    "node_features_test = []\n",
    "attr = []\n",
    "labels = []\n",
    "\n",
    "for source_port_info in nD_test_df[\"source_port_info\"].unique():\n",
    "    nD_graph_test.add_node(source_port_info)\n",
    "    # source_ip = nD_test_df[nD_test_df[\"source_port_info\"] == source_port_info][\"sip_ohe\"].iloc[0]\n",
    "    info_message = nD_test_df[nD_test_df[\"source_port_info\"] == source_port_info][\"info_message\"].iloc[0]\n",
    "    node_features_test.append([float(len(info_message))])\n",
    "    \n",
    "for (source_ip), group in nD_test_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"source_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"source_port_info\"]\n",
    "        if nD_graph_test.has_edge(from_node, to_node):\n",
    "            nD_graph_test[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_test.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor_test = torch.tensor(node_features_test)\n",
    "node_features_tensor_test = node_features_tensor_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  28.],\n",
       "        [  28.],\n",
       "        [  28.],\n",
       "        ...,\n",
       "        [  20.],\n",
       "        [1047.],\n",
       "        [  67.]], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8520 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print num of nodes\n",
    "print(\"Number of nodes:\", nD_graph_test.number_of_nodes(), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyGOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from pygod.detector import ANOMALOUS, SCAN, Radar, DOMINANT, OCGNN, GUIDE\n",
    "from pygod.metric import eval_average_precision, eval_roc_auc, eval_f1, eval_precision_at_k, eval_recall_at_k\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyG_train = from_networkx(nD_graph_train)\n",
    "pyG_train = pyG_train.cuda()\n",
    "pyG_train.x = node_features_tensor\n",
    "\n",
    "pyG_test = from_networkx(nD_graph_test)\n",
    "pyG_test.x = node_features_tensor_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOMINANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_model = DOMINANT(gpu=0, weight=0.02, num_layers=4, hid_dim=16, contamination=0.01, lr=0.001, verbose=2, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 2061.8242 | AUC 0.0000 | Time 0.42\n",
      "Epoch 0001: Loss nan | "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-3.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-3.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dominant_compile \u001b[39m=\u001b[39m dominant_model\u001b[39m.\u001b[39;49mfit(pyG_test, label_test_tensor)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:485\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgan:\n\u001b[0;32m    484\u001b[0m         loss_value \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loss_g \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], loss_value)\n\u001b[1;32m--> 485\u001b[0m     logger(epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[0;32m    486\u001b[0m            loss\u001b[39m=\u001b[39;49mloss_value,\n\u001b[0;32m    487\u001b[0m            score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_score_,\n\u001b[0;32m    488\u001b[0m            target\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m    489\u001b[0m            time\u001b[39m=\u001b[39;49mtime\u001b[39m.\u001b[39;49mtime() \u001b[39m-\u001b[39;49m start_time,\n\u001b[0;32m    490\u001b[0m            verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    491\u001b[0m            train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    493\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_decision_score()\n\u001b[0;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\utils\\utility.py:236\u001b[0m, in \u001b[0;36mlogger\u001b[1;34m(epoch, loss, score, target, time, verbose, train, deep)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m         auc \u001b[39m=\u001b[39m eval_roc_auc(target, score)\n\u001b[0;32m    237\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAUC \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(auc), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\metric\\metric.py:33\u001b[0m, in \u001b[0;36meval_roc_auc\u001b[1;34m(label, score)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_roc_auc\u001b[39m(label, score):\n\u001b[0;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    ROC-AUC score for binary classification.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m        Average ROC-AUC score across different labels.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     roc_auc \u001b[39m=\u001b[39m roc_auc_score(y_true\u001b[39m=\u001b[39;49mlabel, y_score\u001b[39m=\u001b[39;49mscore)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m roc_auc\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:551\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    549\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    550\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 551\u001b[0m y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (\n\u001b[0;32m    554\u001b[0m     y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    555\u001b[0m ):\n\u001b[0;32m    556\u001b[0m     \u001b[39m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[0;32m    557\u001b[0m     \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m max_fpr \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "dominant_compile = dominant_model.fit(pyG_test, label_test_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocgnn_model = OCGNN(hid_dim=64, num_layers=64, weight_decay=0.5, \n",
    "                    contamination=0.33, lr=0.001, epoch=100, batch_size=10000, gpu=-1, num_neigh=-1, \n",
    "                    beta=0.75, warmup=15, verbose=3, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 0.0000 | "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6339, 5486]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-3.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-3.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ocgnn_compile \u001b[39m=\u001b[39m ocgnn_model\u001b[39m.\u001b[39;49mfit(pyG_train, label_train_tensor)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:485\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgan:\n\u001b[0;32m    484\u001b[0m         loss_value \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loss_g \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], loss_value)\n\u001b[1;32m--> 485\u001b[0m     logger(epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[0;32m    486\u001b[0m            loss\u001b[39m=\u001b[39;49mloss_value,\n\u001b[0;32m    487\u001b[0m            score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_score_,\n\u001b[0;32m    488\u001b[0m            target\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m    489\u001b[0m            time\u001b[39m=\u001b[39;49mtime\u001b[39m.\u001b[39;49mtime() \u001b[39m-\u001b[39;49m start_time,\n\u001b[0;32m    490\u001b[0m            verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    491\u001b[0m            train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    493\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_decision_score()\n\u001b[0;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\utils\\utility.py:236\u001b[0m, in \u001b[0;36mlogger\u001b[1;34m(epoch, loss, score, target, time, verbose, train, deep)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m         auc \u001b[39m=\u001b[39m eval_roc_auc(target, score)\n\u001b[0;32m    237\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAUC \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(auc), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\metric\\metric.py:33\u001b[0m, in \u001b[0;36meval_roc_auc\u001b[1;34m(label, score)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_roc_auc\u001b[39m(label, score):\n\u001b[0;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    ROC-AUC score for binary classification.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m        Average ROC-AUC score across different labels.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     roc_auc \u001b[39m=\u001b[39m roc_auc_score(y_true\u001b[39m=\u001b[39;49mlabel, y_score\u001b[39m=\u001b[39;49mscore)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m roc_auc\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    570\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[0;32m    571\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[0;32m    574\u001b[0m         y_true,\n\u001b[0;32m    575\u001b[0m         y_score,\n\u001b[0;32m    576\u001b[0m         average,\n\u001b[0;32m    577\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[0;32m    582\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    586\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    342\u001b[0m     )\n\u001b[1;32m--> 344\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m    345\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    906\u001b[0m ):\n\u001b[0;32m    907\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \n\u001b[0;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m    749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m--> 751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    752\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m    753\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6339, 5486]"
     ]
    }
   ],
   "source": [
    "ocgnn_compile = ocgnn_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ocgnn_compile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-3.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-3.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ocgnn_ip_pred_res, ocgnn_ip_score_res, ocgnn_ip_prob_res, ocgnn_ip_conf_res \u001b[39m=\u001b[39m ocgnn_compile\u001b[39m.\u001b[39mpredict(data\u001b[39m=\u001b[39mpyG_test, label\u001b[39m=\u001b[39mlabel_test_tensor, return_pred\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_prob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prob_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, return_conf\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-3.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m unique_values, counts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munique(ocgnn_ip_pred_res, return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-3.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(unique_values, counts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ocgnn_compile' is not defined"
     ]
    }
   ],
   "source": [
    "ocgnn_ip_pred_res, ocgnn_ip_score_res, ocgnn_ip_prob_res, ocgnn_ip_conf_res = ocgnn_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(ocgnn_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
