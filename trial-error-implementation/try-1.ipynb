{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import parquet file\n",
    "unsw_w_st = pd.read_parquet(\"C:\\\\Users\\\\asus\\\\Documents\\\\nids-pcap-dataset\\\\unsw_parquet_used_dataset\\\\labeled_wo_start_time_w_dup[port].parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_ip</th>\n",
       "      <th>destination_ip</th>\n",
       "      <th>source_port</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>info_message</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>is_malware</th>\n",
       "      <th>source_ip_info</th>\n",
       "      <th>source_port_info</th>\n",
       "      <th>dest_ip_info</th>\n",
       "      <th>dest_port_info</th>\n",
       "      <th>count_benign</th>\n",
       "      <th>count_malware</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>4657</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>4657 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>149.171.126.18 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>80 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>32473</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /level/15/exec/-/buffers/assigned/dump HTT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>175.45.176.3 GET /level/15/exec/-/buffers/assi...</td>\n",
       "      <td>32473 GET /level/15/exec/-/buffers/assigned/du...</td>\n",
       "      <td>149.171.126.18 GET /level/15/exec/-/buffers/as...</td>\n",
       "      <td>80 GET /level/15/exec/-/buffers/assigned/dump ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>49194</td>\n",
       "      <td>80</td>\n",
       "      <td>GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.0 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>49194 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>149.171.126.17 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>80 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.14</td>\n",
       "      <td>51435</td>\n",
       "      <td>80</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET / HTTP/1.1</td>\n",
       "      <td>51435 GET / HTTP/1.1</td>\n",
       "      <td>149.171.126.14 GET / HTTP/1.1</td>\n",
       "      <td>80 GET / HTTP/1.1</td>\n",
       "      <td>46862</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>64694</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /scripts/cbag/ag.exe?page=FileDownload&amp;id=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET /scripts/cbag/ag.exe?page=Fil...</td>\n",
       "      <td>64694 GET /scripts/cbag/ag.exe?page=FileDownlo...</td>\n",
       "      <td>149.171.126.19 GET /scripts/cbag/ag.exe?page=F...</td>\n",
       "      <td>80 GET /scripts/cbag/ag.exe?page=FileDownload&amp;...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_ip  destination_ip source_port destination_port   \n",
       "index                                                              \n",
       "1      175.45.176.1  149.171.126.18        4657               80  \\\n",
       "2      175.45.176.3  149.171.126.18       32473               80   \n",
       "6      175.45.176.0  149.171.126.17       49194               80   \n",
       "9      175.45.176.1  149.171.126.14       51435               80   \n",
       "10     175.45.176.1  149.171.126.19       64694               80   \n",
       "\n",
       "                                            info_message attack_category   \n",
       "index                                                                      \n",
       "1                               GET /oKmwKoVbq HTTP/1.1              NaN  \\\n",
       "2      GET /level/15/exec/-/buffers/assigned/dump HTT...             NaN   \n",
       "6                               GET eLWfxXSPkc HTTP/1.1              NaN   \n",
       "9                                        GET / HTTP/1.1              NaN   \n",
       "10     GET /scripts/cbag/ag.exe?page=FileDownload&id=...             NaN   \n",
       "\n",
       "       is_malware                                     source_ip_info   \n",
       "index                                                                  \n",
       "1               0              175.45.176.1 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2               1  175.45.176.3 GET /level/15/exec/-/buffers/assi...   \n",
       "6               0              175.45.176.0 GET eLWfxXSPkc HTTP/1.1    \n",
       "9               0                       175.45.176.1 GET / HTTP/1.1    \n",
       "10              0  175.45.176.1 GET /scripts/cbag/ag.exe?page=Fil...   \n",
       "\n",
       "                                        source_port_info   \n",
       "index                                                      \n",
       "1                          4657 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2      32473 GET /level/15/exec/-/buffers/assigned/du...   \n",
       "6                         49194 GET eLWfxXSPkc HTTP/1.1    \n",
       "9                                  51435 GET / HTTP/1.1    \n",
       "10     64694 GET /scripts/cbag/ag.exe?page=FileDownlo...   \n",
       "\n",
       "                                            dest_ip_info   \n",
       "index                                                      \n",
       "1                149.171.126.18 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2      149.171.126.18 GET /level/15/exec/-/buffers/as...   \n",
       "6                149.171.126.17 GET eLWfxXSPkc HTTP/1.1    \n",
       "9                         149.171.126.14 GET / HTTP/1.1    \n",
       "10     149.171.126.19 GET /scripts/cbag/ag.exe?page=F...   \n",
       "\n",
       "                                          dest_port_info  count_benign   \n",
       "index                                                                    \n",
       "1                            80 GET /oKmwKoVbq HTTP/1.1              1  \\\n",
       "2      80 GET /level/15/exec/-/buffers/assigned/dump ...             1   \n",
       "6                            80 GET eLWfxXSPkc HTTP/1.1              1   \n",
       "9                                     80 GET / HTTP/1.1          46862   \n",
       "10     80 GET /scripts/cbag/ag.exe?page=FileDownload&...             1   \n",
       "\n",
       "       count_malware  \n",
       "index                 \n",
       "1                  0  \n",
       "2                  7  \n",
       "6                  0  \n",
       "9               1313  \n",
       "10                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsw_w_st.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 125325 entries, 1 to 490022\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   source_ip         125325 non-null  object  \n",
      " 1   destination_ip    125325 non-null  object  \n",
      " 2   source_port       125325 non-null  object  \n",
      " 3   destination_port  125325 non-null  object  \n",
      " 4   info_message      125325 non-null  object  \n",
      " 5   attack_category   15801 non-null   category\n",
      " 6   is_malware        125325 non-null  int64   \n",
      " 7   source_ip_info    125325 non-null  object  \n",
      " 8   source_port_info  125325 non-null  object  \n",
      " 9   dest_ip_info      125325 non-null  object  \n",
      " 10  dest_port_info    125325 non-null  object  \n",
      " 11  count_benign      125325 non-null  int64   \n",
      " 12  count_malware     125325 non-null  int64   \n",
      "dtypes: category(1), int64(3), object(9)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "unsw_w_st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_w_st['source_port'] = unsw_w_st.source_port.astype('int32')\n",
    "unsw_w_st['destination_port']= unsw_w_st.destination_port.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "unsw_w_st['sip_ohe'] = label_encoder.fit_transform(unsw_w_st.source_ip.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_w_st['lensip'] = unsw_w_st.info_message.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "destination_port\n",
       "80    110274\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsw_w_st.loc[unsw_w_st['is_malware'] == 0, 'destination_port'].value_counts().sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(unsw_w_st, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    77148\n",
       "1    10579\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87727 entries, 202866 to 255741\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   source_ip         87727 non-null  object  \n",
      " 1   destination_ip    87727 non-null  object  \n",
      " 2   source_port       87727 non-null  int32   \n",
      " 3   destination_port  87727 non-null  int32   \n",
      " 4   info_message      87727 non-null  object  \n",
      " 5   attack_category   11119 non-null  category\n",
      " 6   is_malware        87727 non-null  int64   \n",
      " 7   source_ip_info    87727 non-null  object  \n",
      " 8   source_port_info  87727 non-null  object  \n",
      " 9   dest_ip_info      87727 non-null  object  \n",
      " 10  dest_port_info    87727 non-null  object  \n",
      " 11  count_benign      87727 non-null  int64   \n",
      " 12  count_malware     87727 non-null  int64   \n",
      " 13  sip_ohe           87727 non-null  int32   \n",
      " 14  lensip            87727 non-null  int64   \n",
      "dtypes: category(1), int32(3), int64(4), object(7)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts = train_df.is_malware.value_counts()\n",
    "# if value_counts[1] > 102:\n",
    "#     df_to_lower = train_df[train_df['is_malware'] == 1].sample(n=104, random_state=13)\n",
    "#     train_df = pd.concat([train_df[train_df['is_malware'] == 0], df_to_lower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([77148, 10579], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nD_train_df = train_df.drop_duplicates(subset=['dest_port_info'])\n",
    "label_train = train_df['is_malware'].to_numpy()\n",
    "label_train_tensor = torch.tensor(label_train, dtype=torch.float)\n",
    "value_counts = np.unique(label_train, return_counts=True)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_train =  train_df.drop_duplicates(subset=['dest_port_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "1    5965\n",
       "0    1674\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_train.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37598 entries, 191480 to 459269\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   source_ip         37598 non-null  object  \n",
      " 1   destination_ip    37598 non-null  object  \n",
      " 2   source_port       37598 non-null  int32   \n",
      " 3   destination_port  37598 non-null  int32   \n",
      " 4   info_message      37598 non-null  object  \n",
      " 5   attack_category   4682 non-null   category\n",
      " 6   is_malware        37598 non-null  int64   \n",
      " 7   source_ip_info    37598 non-null  object  \n",
      " 8   source_port_info  37598 non-null  object  \n",
      " 9   dest_ip_info      37598 non-null  object  \n",
      " 10  dest_port_info    37598 non-null  object  \n",
      " 11  count_benign      37598 non-null  int64   \n",
      " 12  count_malware     37598 non-null  int64   \n",
      " 13  sip_ohe           37598 non-null  int32   \n",
      " 14  lensip            37598 non-null  int64   \n",
      "dtypes: category(1), int32(3), int64(4), object(7)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([33126,  4472], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nD_test_df = test_df.drop_duplicates(subset=['dest_port_info'])\n",
    "label_test = test_df['is_malware'].to_numpy()\n",
    "value_counts = np.unique(label_test, return_counts=True)\n",
    "label_test_tensor = torch.tensor(label_test, dtype=torch.float)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    33126\n",
       "1     4472\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "1    3056\n",
       "0     789\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_test_df = test_df.drop_duplicates(subset=['dest_port_info'])\n",
    "nD_test_df.is_malware.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_train = nx.Graph()\n",
    "node_features = []\n",
    "attr = []\n",
    "labels = []\n",
    "\n",
    "for dest_port_info in train_df[\"dest_port_info\"]:\n",
    "    nD_graph_train.add_node(dest_port_info)\n",
    "    info_message = train_df[train_df[\"dest_port_info\"] == dest_port_info][\"info_message\"].iloc[0]\n",
    "    node_features.append([float(len(info_message))])\n",
    "    \n",
    "for (source_ip), group in train_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"dest_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"dest_port_info\"]\n",
    "        if nD_graph_train.has_edge(from_node, to_node):\n",
    "            nD_graph_train[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_train.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor = torch.tensor(node_features)\n",
    "node_features_tensor = node_features_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.],\n",
       "        [ 28.],\n",
       "        [ 28.],\n",
       "        ...,\n",
       "        [168.],\n",
       "        [ 28.],\n",
       "        [ 28.]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 7639 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print num of nodes\n",
    "print(\"Number of nodes:\", nD_graph_train.number_of_nodes(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([77148, 10579], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = train_df['is_malware'].to_numpy()\n",
    "label_train_tensor = torch.tensor(label_train, dtype=torch.float)\n",
    "value_counts = np.unique(label_train, return_counts=True)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = list(nx.isolates(nD_graph_train))\n",
    "\n",
    "print(\"Isolated nodes:\", len(isolated_nodes), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_test = nx.Graph()\n",
    "node_features_test = []\n",
    "labels_test = []\n",
    "ground_truth = []\n",
    "\n",
    "for dest_port_info in test_df[\"dest_port_info\"].unique():\n",
    "    nD_graph_test.add_node(dest_port_info)\n",
    "    info_message = test_df[test_df[\"dest_port_info\"] == dest_port_info][\"info_message\"].iloc[0]\n",
    "    ground_truth = test_df[test_df[\"dest_port_info\"] == dest_port_info][\"is_malware\"].iloc[0]\n",
    "    # print(info_message)\n",
    "    node_features_test.append([float(len(info_message))])\n",
    "\n",
    "for (source_ip), group in test_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"dest_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"dest_port_info\"]\n",
    "        if nD_graph_test.has_edge(from_node, to_node):\n",
    "            nD_graph_test[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_test.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = ground_truth.to_numpy()\n",
    "# ground_truth = torch.tensor(ground_truth, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor_test = torch.tensor(node_features_test)\n",
    "node_features_tensor_test = node_features_tensor_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  12.],\n",
       "        [  15.],\n",
       "        [  28.],\n",
       "        ...,\n",
       "        [  39.],\n",
       "        [1047.],\n",
       "        [  67.]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = list(nx.isolates(nD_graph_test))\n",
    "\n",
    "print(\"Isolated nodes:\", len(isolated_nodes), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from pygod.detector import DOMINANT, OCGNN, GUIDE, GAE, GAAN, AnomalyDAE, CONAD\n",
    "from pygod.metric import eval_average_precision, eval_roc_auc, eval_f1, eval_precision_at_k, eval_recall_at_k\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "import pickle\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyG_train = from_networkx(nD_graph_train)\n",
    "pyG_train = pyG_train\n",
    "pyG_train.x = node_features_tensor\n",
    "\n",
    "# pyG_test = from_networkx(nD_graph_test)\n",
    "# pyG_test = pyG_test\n",
    "# pyG_test.x = node_features_tensor_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOMINANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_model = DOMINANT(gpu=0, weight=0.02, num_layers=144, hid_dim=64, contamination=0.12, lr=0.001, verbose=3, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 5.0731 | "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [87727, 7639]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-1.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-1.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dominant_compile \u001b[39m=\u001b[39m dominant_model\u001b[39m.\u001b[39;49mfit(pyG_train, label_train_tensor)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:485\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgan:\n\u001b[0;32m    484\u001b[0m         loss_value \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loss_g \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], loss_value)\n\u001b[1;32m--> 485\u001b[0m     logger(epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[0;32m    486\u001b[0m            loss\u001b[39m=\u001b[39;49mloss_value,\n\u001b[0;32m    487\u001b[0m            score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_score_,\n\u001b[0;32m    488\u001b[0m            target\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m    489\u001b[0m            time\u001b[39m=\u001b[39;49mtime\u001b[39m.\u001b[39;49mtime() \u001b[39m-\u001b[39;49m start_time,\n\u001b[0;32m    490\u001b[0m            verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    491\u001b[0m            train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    493\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_decision_score()\n\u001b[0;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\utils\\utility.py:236\u001b[0m, in \u001b[0;36mlogger\u001b[1;34m(epoch, loss, score, target, time, verbose, train, deep)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m         auc \u001b[39m=\u001b[39m eval_roc_auc(target, score)\n\u001b[0;32m    237\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAUC \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(auc), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\metric\\metric.py:33\u001b[0m, in \u001b[0;36meval_roc_auc\u001b[1;34m(label, score)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_roc_auc\u001b[39m(label, score):\n\u001b[0;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    ROC-AUC score for binary classification.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m        Average ROC-AUC score across different labels.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     roc_auc \u001b[39m=\u001b[39m roc_auc_score(y_true\u001b[39m=\u001b[39;49mlabel, y_score\u001b[39m=\u001b[39;49mscore)\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m roc_auc\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    570\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[0;32m    571\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[0;32m    574\u001b[0m         y_true,\n\u001b[0;32m    575\u001b[0m         y_score,\n\u001b[0;32m    576\u001b[0m         average,\n\u001b[0;32m    577\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[0;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[0;32m    582\u001b[0m         y_true,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    585\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    586\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m     78\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    342\u001b[0m     )\n\u001b[1;32m--> 344\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m    345\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    906\u001b[0m ):\n\u001b[0;32m    907\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \n\u001b[0;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[0;32m    749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m--> 751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    752\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m    753\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [87727, 7639]"
     ]
    }
   ],
   "source": [
    "dominant_compile = dominant_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0011 | AUC 0.6186 | Recall 0.8367 | Precision 0.8367 | AP 0.8377 | F1 0.8367 | Time 0.65\n",
      "tensor([0, 1]) tensor([3425,  420])\n"
     ]
    }
   ],
   "source": [
    "dominant_ip_pred_res, dominant_ip_score_res, dominant_ip_prob_res, dominant_ip_conf_res = dominant_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(dominant_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocgnn_model = OCGNN(hid_dim=64, num_layers=64, weight_decay=0.02, \n",
    "                    contamination=0.12, lr=0.001, epoch=100, gpu=-1, batch_size=0, num_neigh=-1, \n",
    "                    beta=0.5, warmup=2, eps=0.001, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 0.0000 | AUC 0.5783 | Recall 0.7992 | Precision 0.7992 | AP 0.8312 | F1 0.7992 | Time 2.20\n",
      "Epoch 0001: Loss 0.0003 | AUC 0.6027 | Recall 0.8052 | Precision 0.8052 | AP 0.8465 | F1 0.8051 | Time 2.03\n",
      "Epoch 0002: Loss 0.0002 | AUC 0.5915 | Recall 0.7951 | Precision 0.7951 | AP 0.8459 | F1 0.7951 | Time 1.98\n",
      "Epoch 0003: Loss 0.0001 | AUC 0.5497 | Recall 0.7821 | Precision 0.7821 | AP 0.8335 | F1 0.7821 | Time 2.02\n",
      "Epoch 0004: Loss 0.0001 | AUC 0.5164 | Recall 0.7816 | Precision 0.7816 | AP 0.8097 | F1 0.7816 | Time 1.98\n",
      "Epoch 0005: Loss 0.0001 | AUC 0.5130 | Recall 0.7807 | Precision 0.7807 | AP 0.8037 | F1 0.7807 | Time 1.96\n",
      "Epoch 0006: Loss 0.0001 | AUC 0.5073 | Recall 0.7837 | Precision 0.7837 | AP 0.7874 | F1 0.7837 | Time 1.98\n",
      "Epoch 0007: Loss 0.0001 | AUC 0.4945 | Recall 0.7826 | Precision 0.7826 | AP 0.7592 | F1 0.7826 | Time 2.00\n",
      "Epoch 0008: Loss 0.0001 | AUC 0.4816 | Recall 0.7854 | Precision 0.7854 | AP 0.7435 | F1 0.7854 | Time 1.99\n",
      "Epoch 0009: Loss 0.0001 | AUC 0.4667 | Recall 0.7809 | Precision 0.7809 | AP 0.7360 | F1 0.7809 | Time 2.00\n",
      "Epoch 0010: Loss 0.0001 | AUC 0.4639 | Recall 0.7812 | Precision 0.7812 | AP 0.7345 | F1 0.7812 | Time 2.02\n",
      "Epoch 0011: Loss 0.0001 | AUC 0.4596 | Recall 0.7822 | Precision 0.7822 | AP 0.7329 | F1 0.7822 | Time 1.97\n",
      "Epoch 0012: Loss 0.0001 | AUC 0.4550 | Recall 0.7817 | Precision 0.7817 | AP 0.7318 | F1 0.7817 | Time 2.03\n",
      "Epoch 0013: Loss 0.0001 | AUC 0.4521 | Recall 0.7806 | Precision 0.7806 | AP 0.7309 | F1 0.7806 | Time 2.00\n",
      "Epoch 0014: Loss 0.0001 | AUC 0.4500 | Recall 0.7802 | Precision 0.7802 | AP 0.7305 | F1 0.7802 | Time 2.01\n",
      "Epoch 0015: Loss 0.0001 | AUC 0.4526 | Recall 0.7749 | Precision 0.7749 | AP 0.7325 | F1 0.7749 | Time 1.98\n",
      "Epoch 0016: Loss 0.0001 | AUC 0.4543 | Recall 0.7720 | Precision 0.7720 | AP 0.7350 | F1 0.7720 | Time 1.99\n",
      "Epoch 0017: Loss 0.0001 | AUC 0.4553 | Recall 0.7764 | Precision 0.7764 | AP 0.7348 | F1 0.7764 | Time 2.06\n",
      "Epoch 0018: Loss 0.0001 | AUC 0.4539 | Recall 0.7760 | Precision 0.7760 | AP 0.7330 | F1 0.7760 | Time 2.05\n",
      "Epoch 0019: Loss 0.0001 | AUC 0.4571 | Recall 0.7774 | Precision 0.7774 | AP 0.7336 | F1 0.7774 | Time 2.05\n",
      "Epoch 0020: Loss 0.0001 | AUC 0.4626 | Recall 0.7780 | Precision 0.7780 | AP 0.7356 | F1 0.7780 | Time 2.05\n",
      "Epoch 0021: Loss 0.0001 | AUC 0.4556 | Recall 0.7747 | Precision 0.7747 | AP 0.7330 | F1 0.7747 | Time 2.05\n",
      "Epoch 0022: Loss 0.0001 | AUC 0.4508 | Recall 0.7755 | Precision 0.7755 | AP 0.7316 | F1 0.7755 | Time 2.01\n",
      "Epoch 0023: Loss 0.0001 | AUC 0.4506 | Recall 0.7754 | Precision 0.7754 | AP 0.7318 | F1 0.7754 | Time 2.04\n",
      "Epoch 0024: Loss 0.0001 | AUC 0.4512 | Recall 0.7765 | Precision 0.7765 | AP 0.7325 | F1 0.7765 | Time 1.99\n",
      "Epoch 0025: Loss 0.0001 | AUC 0.4499 | Recall 0.7740 | Precision 0.7740 | AP 0.7325 | F1 0.7740 | Time 2.13\n",
      "Epoch 0026: Loss 0.0001 | AUC 0.4519 | Recall 0.7744 | Precision 0.7744 | AP 0.7337 | F1 0.7744 | Time 1.99\n",
      "Epoch 0027: Loss 0.0001 | AUC 0.4468 | Recall 0.7732 | Precision 0.7732 | AP 0.7307 | F1 0.7732 | Time 2.00\n",
      "Epoch 0028: Loss 0.0001 | AUC 0.4692 | Recall 0.7759 | Precision 0.7759 | AP 0.7451 | F1 0.7759 | Time 2.02\n",
      "Epoch 0029: Loss 0.0001 | AUC 0.4683 | Recall 0.7745 | Precision 0.7745 | AP 0.7418 | F1 0.7745 | Time 2.01\n",
      "Epoch 0030: Loss 0.0001 | AUC 0.4606 | Recall 0.7740 | Precision 0.7740 | AP 0.7359 | F1 0.7740 | Time 2.01\n",
      "Epoch 0031: Loss 0.0001 | AUC 0.4609 | Recall 0.7735 | Precision 0.7735 | AP 0.7363 | F1 0.7735 | Time 1.96\n",
      "Epoch 0032: Loss 0.0001 | AUC 0.4797 | Recall 0.7770 | Precision 0.7770 | AP 0.7482 | F1 0.7770 | Time 2.05\n",
      "Epoch 0033: Loss 0.0001 | AUC 0.4979 | Recall 0.7772 | Precision 0.7772 | AP 0.7794 | F1 0.7772 | Time 2.01\n",
      "Epoch 0034: Loss 0.0001 | AUC 0.4759 | Recall 0.7760 | Precision 0.7760 | AP 0.7454 | F1 0.7760 | Time 1.98\n",
      "Epoch 0035: Loss 0.0001 | AUC 0.4767 | Recall 0.7807 | Precision 0.7807 | AP 0.7436 | F1 0.7807 | Time 2.00\n",
      "Epoch 0036: Loss 0.0001 | AUC 0.4810 | Recall 0.7817 | Precision 0.7817 | AP 0.7483 | F1 0.7817 | Time 2.01\n",
      "Epoch 0037: Loss 0.0001 | AUC 0.4824 | Recall 0.7797 | Precision 0.7797 | AP 0.7519 | F1 0.7797 | Time 2.00\n",
      "Epoch 0038: Loss 0.0001 | AUC 0.4866 | Recall 0.7794 | Precision 0.7794 | AP 0.7598 | F1 0.7793 | Time 2.06\n",
      "Epoch 0039: Loss 0.0001 | AUC 0.4856 | Recall 0.7780 | Precision 0.7780 | AP 0.7599 | F1 0.7779 | Time 2.04\n",
      "Epoch 0040: Loss 0.0001 | AUC 0.4846 | Recall 0.7777 | Precision 0.7777 | AP 0.7566 | F1 0.7777 | Time 2.01\n",
      "Epoch 0041: Loss 0.0001 | AUC 0.5011 | Recall 0.7789 | Precision 0.7789 | AP 0.7868 | F1 0.7789 | Time 2.16\n",
      "Epoch 0042: Loss 0.0001 | AUC 0.5017 | Recall 0.7789 | Precision 0.7789 | AP 0.7894 | F1 0.7788 | Time 1.99\n",
      "Epoch 0043: Loss 0.0001 | AUC 0.5018 | Recall 0.7782 | Precision 0.7782 | AP 0.7888 | F1 0.7782 | Time 2.03\n",
      "Epoch 0044: Loss 0.0001 | AUC 0.5128 | Recall 0.7790 | Precision 0.7790 | AP 0.8055 | F1 0.7790 | Time 2.03\n",
      "Epoch 0045: Loss 0.0001 | AUC 0.5164 | Recall 0.7802 | Precision 0.7802 | AP 0.8099 | F1 0.7802 | Time 2.08\n",
      "Epoch 0046: Loss 0.0001 | AUC 0.5021 | Recall 0.7780 | Precision 0.7780 | AP 0.7891 | F1 0.7780 | Time 2.01\n",
      "Epoch 0047: Loss 0.0001 | AUC 0.4972 | Recall 0.7780 | Precision 0.7780 | AP 0.7804 | F1 0.7780 | Time 2.01\n",
      "Epoch 0048: Loss 0.0001 | AUC 0.4979 | Recall 0.7806 | Precision 0.7806 | AP 0.7786 | F1 0.7806 | Time 2.08\n",
      "Epoch 0049: Loss 0.0001 | AUC 0.5103 | Recall 0.7772 | Precision 0.7772 | AP 0.8026 | F1 0.7771 | Time 2.09\n",
      "Epoch 0050: Loss 0.0001 | AUC 0.5117 | Recall 0.7780 | Precision 0.7780 | AP 0.8049 | F1 0.7780 | Time 2.06\n",
      "Epoch 0051: Loss 0.0001 | AUC 0.4925 | Recall 0.7789 | Precision 0.7789 | AP 0.7728 | F1 0.7789 | Time 2.01\n",
      "Epoch 0052: Loss 0.0001 | AUC 0.4901 | Recall 0.7794 | Precision 0.7794 | AP 0.7654 | F1 0.7794 | Time 2.51\n",
      "Epoch 0053: Loss 0.0001 | AUC 0.4997 | Recall 0.7806 | Precision 0.7806 | AP 0.7855 | F1 0.7803 | Time 2.31\n",
      "Epoch 0054: Loss 0.0001 | AUC 0.5144 | Recall 0.7795 | Precision 0.7795 | AP 0.8104 | F1 0.7795 | Time 2.29\n",
      "Epoch 0055: Loss 0.0001 | AUC 0.5043 | Recall 0.7795 | Precision 0.7795 | AP 0.7930 | F1 0.7795 | Time 5.31\n",
      "Epoch 0056: Loss 0.0001 | AUC 0.4973 | Recall 0.7812 | Precision 0.7812 | AP 0.7671 | F1 0.7811 | Time 2.72\n",
      "Epoch 0057: Loss 0.0001 | AUC 0.4969 | Recall 0.7821 | Precision 0.7821 | AP 0.7639 | F1 0.7820 | Time 2.32\n",
      "Epoch 0058: Loss 0.0001 | AUC 0.5034 | Recall 0.7782 | Precision 0.7782 | AP 0.7799 | F1 0.7782 | Time 2.28\n",
      "Epoch 0059: Loss 0.0001 | AUC 0.5364 | Recall 0.7812 | Precision 0.7812 | AP 0.8253 | F1 0.7812 | Time 2.37\n",
      "Epoch 0060: Loss 0.0001 | AUC 0.6014 | Recall 0.8030 | Precision 0.8030 | AP 0.8509 | F1 0.8030 | Time 2.19\n",
      "Epoch 0061: Loss 0.0001 | AUC 0.6052 | Recall 0.8042 | Precision 0.8042 | AP 0.8505 | F1 0.8042 | Time 2.01\n",
      "Epoch 0062: Loss 0.0001 | AUC 0.6044 | Recall 0.8037 | Precision 0.8037 | AP 0.8497 | F1 0.8036 | Time 2.03\n",
      "Epoch 0063: Loss 0.0001 | AUC 0.5989 | Recall 0.8020 | Precision 0.8020 | AP 0.8500 | F1 0.8020 | Time 2.05\n",
      "Epoch 0064: Loss 0.0001 | AUC 0.5646 | Recall 0.7858 | Precision 0.7858 | AP 0.8402 | F1 0.7858 | Time 2.01\n",
      "Epoch 0065: Loss 0.0001 | AUC 0.5996 | Recall 0.8057 | Precision 0.8057 | AP 0.8488 | F1 0.8057 | Time 2.01\n",
      "Epoch 0066: Loss 0.0001 | AUC 0.6003 | Recall 0.8094 | Precision 0.8094 | AP 0.8420 | F1 0.8094 | Time 2.06\n",
      "Epoch 0067: Loss 0.0001 | AUC 0.5807 | Recall 0.8075 | Precision 0.8075 | AP 0.8266 | F1 0.8075 | Time 2.15\n",
      "Epoch 0068: Loss 0.0001 | AUC 0.5849 | Recall 0.8089 | Precision 0.8089 | AP 0.8297 | F1 0.8088 | Time 2.17\n",
      "Epoch 0069: Loss 0.0001 | AUC 0.6012 | Recall 0.8097 | Precision 0.8097 | AP 0.8424 | F1 0.8096 | Time 2.07\n",
      "Epoch 0070: Loss 0.0001 | AUC 0.6044 | Recall 0.8072 | Precision 0.8072 | AP 0.8463 | F1 0.8071 | Time 2.07\n",
      "Epoch 0071: Loss 0.0001 | AUC 0.6034 | Recall 0.8049 | Precision 0.8049 | AP 0.8464 | F1 0.8049 | Time 2.02\n",
      "Epoch 0072: Loss 0.0001 | AUC 0.6041 | Recall 0.8050 | Precision 0.8050 | AP 0.8469 | F1 0.8048 | Time 2.00\n",
      "Epoch 0073: Loss 0.0001 | AUC 0.6037 | Recall 0.8050 | Precision 0.8050 | AP 0.8464 | F1 0.8048 | Time 2.02\n",
      "Epoch 0074: Loss 0.0001 | AUC 0.6045 | Recall 0.8070 | Precision 0.8070 | AP 0.8460 | F1 0.8070 | Time 1.97\n",
      "Epoch 0075: Loss 0.0001 | AUC 0.5916 | Recall 0.8075 | Precision 0.8075 | AP 0.8353 | F1 0.8075 | Time 2.11\n",
      "Epoch 0076: Loss 0.0001 | AUC 0.5119 | Recall 0.7790 | Precision 0.7790 | AP 0.7948 | F1 0.7789 | Time 2.13\n",
      "Epoch 0077: Loss 0.0001 | AUC 0.4040 | Recall 0.7557 | Precision 0.7557 | AP 0.7252 | F1 0.7558 | Time 2.03\n",
      "Epoch 0078: Loss 0.0001 | AUC 0.4008 | Recall 0.7532 | Precision 0.7532 | AP 0.7229 | F1 0.7531 | Time 2.07\n",
      "Epoch 0079: Loss 0.0001 | AUC 0.3993 | Recall 0.7532 | Precision 0.7532 | AP 0.7230 | F1 0.7531 | Time 2.08\n",
      "Epoch 0080: Loss 0.0001 | AUC 0.3997 | Recall 0.7562 | Precision 0.7562 | AP 0.7219 | F1 0.7563 | Time 2.10\n",
      "Epoch 0081: Loss 0.0001 | AUC 0.4031 | Recall 0.7557 | Precision 0.7557 | AP 0.7300 | F1 0.7558 | Time 2.02\n",
      "Epoch 0082: Loss 0.0001 | AUC 0.4070 | Recall 0.7549 | Precision 0.7549 | AP 0.7408 | F1 0.7546 | Time 2.01\n",
      "Epoch 0083: Loss 0.0001 | AUC 0.4076 | Recall 0.7547 | Precision 0.7547 | AP 0.7410 | F1 0.7546 | Time 1.97\n",
      "Epoch 0084: Loss 0.0001 | AUC 0.3997 | Recall 0.7552 | Precision 0.7552 | AP 0.7229 | F1 0.7551 | Time 2.00\n",
      "Epoch 0085: Loss 0.0001 | AUC 0.3993 | Recall 0.7567 | Precision 0.7567 | AP 0.7208 | F1 0.7566 | Time 2.00\n",
      "Epoch 0086: Loss 0.0001 | AUC 0.3993 | Recall 0.7567 | Precision 0.7567 | AP 0.7199 | F1 0.7564 | Time 2.10\n",
      "Epoch 0087: Loss 0.0001 | AUC 0.3977 | Recall 0.7567 | Precision 0.7567 | AP 0.7185 | F1 0.7567 | Time 2.08\n",
      "Epoch 0088: Loss 0.0001 | AUC 0.3979 | Recall 0.7571 | Precision 0.7571 | AP 0.7189 | F1 0.7570 | Time 2.04\n",
      "Epoch 0089: Loss 0.0001 | AUC 0.3979 | Recall 0.7571 | Precision 0.7571 | AP 0.7190 | F1 0.7570 | Time 1.98\n",
      "Epoch 0090: Loss 0.0001 | AUC 0.3972 | Recall 0.7569 | Precision 0.7569 | AP 0.7182 | F1 0.7567 | Time 2.02\n",
      "Epoch 0091: Loss 0.0001 | AUC 0.3966 | Recall 0.7571 | Precision 0.7571 | AP 0.7173 | F1 0.7570 | Time 1.97\n",
      "Epoch 0092: Loss 0.0001 | AUC 0.3968 | Recall 0.7556 | Precision 0.7556 | AP 0.7174 | F1 0.7543 | Time 2.03\n",
      "Epoch 0093: Loss 0.0001 | AUC 0.3971 | Recall 0.7556 | Precision 0.7556 | AP 0.7178 | F1 0.7555 | Time 2.25\n",
      "Epoch 0094: Loss 0.0001 | AUC 0.3972 | Recall 0.7559 | Precision 0.7559 | AP 0.7182 | F1 0.7559 | Time 2.05\n",
      "Epoch 0095: Loss 0.0001 | AUC 0.3974 | Recall 0.7562 | Precision 0.7562 | AP 0.7178 | F1 0.7561 | Time 2.24\n",
      "Epoch 0096: Loss 0.0001 | AUC 0.3967 | Recall 0.7571 | Precision 0.7571 | AP 0.7168 | F1 0.7570 | Time 2.05\n",
      "Epoch 0097: Loss 0.0001 | AUC 0.3965 | Recall 0.7573 | Precision 0.7573 | AP 0.7164 | F1 0.7573 | Time 2.00\n",
      "Epoch 0098: Loss 0.0001 | AUC 0.3963 | Recall 0.7569 | Precision 0.7569 | AP 0.7161 | F1 0.7568 | Time 2.20\n",
      "Epoch 0099: Loss 0.0001 | AUC 0.3969 | Recall 0.7574 | Precision 0.7574 | AP 0.7164 | F1 0.7575 | Time 2.05\n"
     ]
    }
   ],
   "source": [
    "ocgnn_compile = ocgnn_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0000 | AUC 0.3317 | Recall 0.7683 | Precision 0.7683 | AP 0.6935 | F1 0.7681 | Time 0.39\n",
      "tensor([0, 1]) tensor([  99, 3746])\n"
     ]
    }
   ],
   "source": [
    "ocgnn_ip_pred_res, ocgnn_ip_score_res, ocgnn_ip_prob_res, ocgnn_ip_conf_res = ocgnn_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(ocgnn_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709203175536608\n"
     ]
    }
   ],
   "source": [
    "f1_score_ip = eval_f1(label_test_tensor, ocgnn_ip_pred_res)\n",
    "print(f1_score_ip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_model = GUIDE(num_layers=4, hid_a=16, hid_s=16, weight_decay=0.05,  \n",
    "                    contamination=0.12, lr=0.001, epoch=100, gpu=-1, dropout=0.5,\n",
    "                    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUIDE(act=<function relu at 0x000002F22EE0A8B0>, alpha=0.5, backbone=None,\n",
      "      batch_size=0, cache_dir=None, compile_model=False,\n",
      "      contamination=0.12, dropout=0.5, epoch=100, gpu=None,\n",
      "      graphlet_size=4, hid_a=None, hid_s=None, lr=0.001, num_layers=4,\n",
      "      num_neigh=[-1, -1, -1, -1], save_emb=False, selected_motif=True,\n",
      "      verbose=3, weight_decay=0.05)\n"
     ]
    }
   ],
   "source": [
    "print(guide_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-1.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-1.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m guide_compile \u001b[39m=\u001b[39m guide_model\u001b[39m.\u001b[39;49mfit(pyG_train)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:432\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, data, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    431\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_dim \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape\n\u001b[1;32m--> 432\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_graph(data)\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    434\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\guide.py:167\u001b[0m, in \u001b[0;36mGUIDE.process_graph\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_graph\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m--> 167\u001b[0m     data\u001b[39m.\u001b[39ms \u001b[39m=\u001b[39m GUIDEBase\u001b[39m.\u001b[39;49mcalc_gdd(data,\n\u001b[0;32m    168\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_dir,\n\u001b[0;32m    169\u001b[0m                                 graphlet_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraphlet_size,\n\u001b[0;32m    170\u001b[0m                                 selected_motif\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselected_motif)\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_s \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39ms\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\nn\\guide.py:182\u001b[0m, in \u001b[0;36mGUIDEBase.calc_gdd\u001b[1;34m(data, cache_dir, graphlet_size, selected_motif)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(new_subset)) \u001b[39m==\u001b[39m i:\n\u001b[0;32m    181\u001b[0m                 new_subset\u001b[39m.\u001b[39msort()\n\u001b[1;32m--> 182\u001b[0m                 unique_subsets[\u001b[39mtuple\u001b[39m(new_subset)] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    183\u001b[0m subsets \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(k) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m unique_subsets\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m    184\u001b[0m edge_subsets[i] \u001b[39m=\u001b[39m subsets\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "guide_compile = guide_model.fit(pyG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.8848 | AUC 1.0000 | Recall 1.0000 | Precision 1.0000 | AP 1.0000 | F1 1.0000 | Time 0.23\n",
      "tensor([0, 1]) tensor([4440, 2583])\n"
     ]
    }
   ],
   "source": [
    "guide_ip_pred_res, guide_ip_score_res, guide_ip_prob_res, guide_ip_conf_res = guide_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(guide_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae_model = GAE(hid_dim=64, num_layers=128, weight_decay=0.2, dropout=0.5,\n",
    "                contamination=0.12, lr=0.001, epoch=100, gpu=-1,\n",
    "                num_neigh=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 376054.5625 | AUC 0.5752 | Recall 0.7832 | Precision 0.7832 | AP 0.8389 | F1 0.7743 | Time 4.25\n",
      "Epoch 0001: Loss 376052.3750 | AUC 0.5735 | Recall 0.7812 | Precision 0.7812 | AP 0.8391 | F1 0.7812 | Time 3.87\n",
      "Epoch 0002: Loss 376049.5625 | AUC 0.5733 | Recall 0.7819 | Precision 0.7819 | AP 0.8390 | F1 0.7819 | Time 4.04\n",
      "Epoch 0003: Loss 376046.2812 | AUC 0.5730 | Recall 0.7816 | Precision 0.7816 | AP 0.8388 | F1 0.7816 | Time 3.97\n",
      "Epoch 0004: Loss 376042.8125 | AUC 0.5732 | Recall 0.7807 | Precision 0.7807 | AP 0.8390 | F1 0.7807 | Time 3.97\n",
      "Epoch 0005: Loss 376039.2500 | AUC 0.5732 | Recall 0.7817 | Precision 0.7817 | AP 0.8389 | F1 0.7817 | Time 4.00\n",
      "Epoch 0006: Loss 376034.2812 | AUC 0.5732 | Recall 0.7817 | Precision 0.7817 | AP 0.8391 | F1 0.7817 | Time 3.93\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir-latest-update\\data-prep-related\\graph_modeling\\fix-ipnyb\\trial-error\\try-1.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir-latest-update/data-prep-related/graph_modeling/fix-ipnyb/trial-error/try-1.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gae_compile \u001b[39m=\u001b[39m gae_model\u001b[39m.\u001b[39;49mfit(pyG_train, label_train_tensor)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:479\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_score_[node_idx[:batch_size]] \u001b[39m=\u001b[39m score\n\u001b[0;32m    478\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 479\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    480\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    482\u001b[0m loss_value \u001b[39m=\u001b[39m epoch_loss \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gae_compile = gae_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 85.4987 | AUC 0.5860 | Recall 0.7948 | Precision 0.7948 | AP 0.8682 | F1 0.7948 | Time 0.91\n",
      "tensor([0, 1]) tensor([3554,  291])\n"
     ]
    }
   ],
   "source": [
    "gae_ip_pred_res, gae_ip_score_res, gae_ip_prob_res, gae_ip_conf_res = gae_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(gae_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaan_model = GAAN(noise_dim=8, hid_dim=8, num_layers=8, dropout=0.0, \n",
    "                  weight_decay=0.02, contamination=0.12, lr=0.004, \n",
    "                  epoch=100, gpu=-1, batch_size=0, num_neigh=0, \n",
    "                  weight=0.5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 2.25\n",
      "Epoch 0001: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 1.85\n",
      "Epoch 0002: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8412 | F1 0.7858 | Time 1.86\n",
      "Epoch 0003: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 1.89\n",
      "Epoch 0004: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7859 | Precision 0.7859 | AP 0.8411 | F1 0.7859 | Time 1.93\n",
      "Epoch 0005: Loss G nan | Loss D nan | AUC 0.5809 | Recall 0.7863 | Precision 0.7863 | AP 0.8411 | F1 0.7863 | Time 2.04\n",
      "Epoch 0006: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.98\n",
      "Epoch 0007: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.84\n",
      "Epoch 0008: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.81\n",
      "Epoch 0009: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.74\n",
      "Epoch 0010: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7863 | Time 1.80\n",
      "Epoch 0011: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8410 | F1 0.7859 | Time 1.98\n",
      "Epoch 0012: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 1.89\n",
      "Epoch 0013: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.83\n",
      "Epoch 0014: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 2.20\n",
      "Epoch 0015: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 2.08\n",
      "Epoch 0016: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.03\n",
      "Epoch 0017: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.83\n",
      "Epoch 0018: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 1.79\n",
      "Epoch 0019: Loss G nan | Loss D nan | AUC 0.5809 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.86\n",
      "Epoch 0020: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.79\n",
      "Epoch 0021: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.91\n",
      "Epoch 0022: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7852 | Precision 0.7852 | AP 0.8411 | F1 0.7852 | Time 1.96\n",
      "Epoch 0023: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7856 | Precision 0.7856 | AP 0.8412 | F1 0.7856 | Time 1.84\n",
      "Epoch 0024: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7861 | Precision 0.7861 | AP 0.8410 | F1 0.7861 | Time 1.80\n",
      "Epoch 0025: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7854 | Precision 0.7854 | AP 0.8412 | F1 0.7854 | Time 1.79\n",
      "Epoch 0026: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8414 | F1 0.7861 | Time 1.91\n",
      "Epoch 0027: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7856 | Precision 0.7856 | AP 0.8412 | F1 0.7856 | Time 2.05\n",
      "Epoch 0028: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 1.84\n",
      "Epoch 0029: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7854 | Precision 0.7854 | AP 0.8411 | F1 0.7854 | Time 1.96\n",
      "Epoch 0030: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 1.84\n",
      "Epoch 0031: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.87\n",
      "Epoch 0032: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7861 | Time 1.87\n",
      "Epoch 0033: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.04\n",
      "Epoch 0034: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.91\n",
      "Epoch 0035: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 1.94\n",
      "Epoch 0036: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7863 | Precision 0.7863 | AP 0.8414 | F1 0.7863 | Time 1.90\n",
      "Epoch 0037: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.86\n",
      "Epoch 0038: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 2.17\n",
      "Epoch 0039: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 2.31\n",
      "Epoch 0040: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 2.10\n",
      "Epoch 0041: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.02\n",
      "Epoch 0042: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.86\n",
      "Epoch 0043: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8413 | F1 0.7863 | Time 2.40\n",
      "Epoch 0044: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.25\n",
      "Epoch 0045: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.17\n",
      "Epoch 0046: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7863 | Precision 0.7863 | AP 0.8413 | F1 0.7863 | Time 2.05\n",
      "Epoch 0047: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 1.93\n",
      "Epoch 0048: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.87\n",
      "Epoch 0049: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 2.04\n",
      "Epoch 0050: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.27\n",
      "Epoch 0051: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.25\n",
      "Epoch 0052: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7861 | Time 2.05\n",
      "Epoch 0053: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8411 | F1 0.7863 | Time 1.87\n",
      "Epoch 0054: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8410 | F1 0.7859 | Time 1.82\n",
      "Epoch 0055: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7849 | Precision 0.7849 | AP 0.8412 | F1 0.7849 | Time 1.86\n",
      "Epoch 0056: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.91\n",
      "Epoch 0057: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7863 | Time 1.86\n",
      "Epoch 0058: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.86\n",
      "Epoch 0059: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8409 | F1 0.7863 | Time 1.78\n",
      "Epoch 0060: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 1.84\n",
      "Epoch 0061: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 2.00\n",
      "Epoch 0062: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7858 | Precision 0.7858 | AP 0.8410 | F1 0.7858 | Time 1.98\n",
      "Epoch 0063: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.93\n",
      "Epoch 0064: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7861 | Precision 0.7861 | AP 0.8410 | F1 0.7861 | Time 1.93\n",
      "Epoch 0065: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 1.94\n",
      "Epoch 0066: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 2.21\n",
      "Epoch 0067: Loss G nan | Loss D nan | AUC 0.5799 | Recall 0.7859 | Precision 0.7859 | AP 0.8408 | F1 0.7859 | Time 1.80\n",
      "Epoch 0068: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 1.82\n",
      "Epoch 0069: Loss G nan | Loss D nan | AUC 0.5800 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.83\n",
      "Epoch 0070: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.83\n",
      "Epoch 0071: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.80\n",
      "Epoch 0072: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7861 | Precision 0.7861 | AP 0.8409 | F1 0.7861 | Time 1.90\n",
      "Epoch 0073: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.86\n",
      "Epoch 0074: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8409 | F1 0.7864 | Time 1.91\n",
      "Epoch 0075: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8414 | F1 0.7864 | Time 1.91\n",
      "Epoch 0076: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.03\n",
      "Epoch 0077: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7860 | Time 2.14\n",
      "Epoch 0078: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7864 | Precision 0.7864 | AP 0.8411 | F1 0.7865 | Time 2.16\n",
      "Epoch 0079: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7863 | Time 2.60\n",
      "Epoch 0080: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.07\n",
      "Epoch 0081: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7854 | Precision 0.7854 | AP 0.8409 | F1 0.7853 | Time 1.96\n",
      "Epoch 0082: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7860 | Time 2.21\n",
      "Epoch 0083: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 1.89\n",
      "Epoch 0084: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7865 | Time 1.87\n",
      "Epoch 0085: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 1.93\n",
      "Epoch 0086: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7858 | Precision 0.7858 | AP 0.8412 | F1 0.7856 | Time 1.99\n",
      "Epoch 0087: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 2.52\n",
      "Epoch 0088: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7858 | Precision 0.7858 | AP 0.8410 | F1 0.7856 | Time 2.77\n",
      "Epoch 0089: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7862 | Time 2.03\n",
      "Epoch 0090: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 2.05\n",
      "Epoch 0091: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7852 | Precision 0.7852 | AP 0.8413 | F1 0.7852 | Time 1.90\n",
      "Epoch 0092: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7860 | Time 1.87\n",
      "Epoch 0093: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7854 | Precision 0.7854 | AP 0.8411 | F1 0.7854 | Time 1.92\n",
      "Epoch 0094: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7865 | Time 2.10\n",
      "Epoch 0095: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7854 | Precision 0.7854 | AP 0.8412 | F1 0.7853 | Time 2.57\n",
      "Epoch 0096: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7852 | Precision 0.7852 | AP 0.8410 | F1 0.7851 | Time 2.07\n",
      "Epoch 0097: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7852 | Precision 0.7852 | AP 0.8409 | F1 0.7852 | Time 2.04\n",
      "Epoch 0098: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7860 | Time 1.92\n",
      "Epoch 0099: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 1.91\n"
     ]
    }
   ],
   "source": [
    "gaan_compile = gaan_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss nan | AUC 0.5099 | Recall 0.7938 | Precision 0.7938 | AP 0.8103 | F1 0.7938 | Time 0.48\n",
      "tensor([0, 1]) tensor([3358,  487])\n"
     ]
    }
   ],
   "source": [
    "gaan_ip_pred_res, gaan_ip_score_res, gaan_ip_prob_res, gaan_ip_conf_res = gaan_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(gaan_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "conad_mode = CONAD(hid_dim=64, num_layers=64, dropout=0.0, weight_decay=0.0, contamination=0.12, lr=0.001, \n",
    "      epoch=100, gpu=-1, num_neigh=-1, weight=0.5, eta=0.5, margin=0.5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 43.4965 | AUC 0.5820 | Recall 0.7864 | Precision 0.7864 | AP 0.8409 | F1 0.7851 | Time 6.70\n",
      "Epoch 0001: Loss 43.4961 | AUC 0.5821 | Recall 0.7864 | Precision 0.7864 | AP 0.8415 | F1 0.7864 | Time 6.47\n",
      "Epoch 0002: Loss 43.4919 | AUC 0.5820 | Recall 0.7861 | Precision 0.7861 | AP 0.8418 | F1 0.7861 | Time 6.50\n",
      "Epoch 0003: Loss 43.4889 | AUC 0.5820 | Recall 0.7863 | Precision 0.7863 | AP 0.8417 | F1 0.7863 | Time 6.87\n",
      "Epoch 0004: Loss 43.4835 | AUC 0.5820 | Recall 0.7863 | Precision 0.7863 | AP 0.8417 | F1 0.7863 | Time 6.69\n",
      "Epoch 0005: Loss 43.4810 | AUC 0.5815 | Recall 0.7861 | Precision 0.7861 | AP 0.8415 | F1 0.7861 | Time 6.38\n",
      "Epoch 0006: Loss 43.4760 | AUC 0.5812 | Recall 0.7859 | Precision 0.7859 | AP 0.8414 | F1 0.7859 | Time 6.88\n",
      "Epoch 0007: Loss 43.4690 | AUC 0.5810 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 6.38\n",
      "Epoch 0008: Loss 43.4593 | AUC 0.5809 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 6.39\n",
      "Epoch 0009: Loss 43.4471 | AUC 0.5809 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 6.36\n",
      "Epoch 0010: Loss 43.4350 | AUC 0.5808 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7861 | Time 6.44\n",
      "Epoch 0011: Loss 43.4076 | AUC 0.5807 | Recall 0.7863 | Precision 0.7863 | AP 0.8411 | F1 0.7863 | Time 6.46\n",
      "Epoch 0012: Loss 43.3681 | AUC 0.5804 | Recall 0.7861 | Precision 0.7861 | AP 0.8411 | F1 0.7861 | Time 6.38\n",
      "Epoch 0013: Loss 43.2797 | AUC 0.5795 | Recall 0.7858 | Precision 0.7858 | AP 0.8409 | F1 0.7858 | Time 6.33\n",
      "Epoch 0014: Loss 43.0615 | AUC 0.5774 | Recall 0.7842 | Precision 0.7842 | AP 0.8402 | F1 0.7842 | Time 8.05\n",
      "Epoch 0015: Loss 42.4813 | AUC 0.5692 | Recall 0.7789 | Precision 0.7789 | AP 0.8379 | F1 0.7789 | Time 6.78\n",
      "Epoch 0016: Loss 40.8534 | AUC 0.5482 | Recall 0.7725 | Precision 0.7725 | AP 0.8325 | F1 0.7724 | Time 6.52\n",
      "Epoch 0017: Loss 37.4801 | AUC 0.6310 | Recall 0.8002 | Precision 0.8002 | AP 0.8571 | F1 0.8002 | Time 7.44\n",
      "Epoch 0018: Loss 43.5892 | AUC 0.5555 | Recall 0.7388 | Precision 0.7388 | AP 0.8533 | F1 0.7388 | Time 7.41\n",
      "Epoch 0019: Loss 38.8735 | AUC 0.6478 | Recall 0.8151 | Precision 0.8151 | AP 0.8636 | F1 0.8151 | Time 8.15\n",
      "Epoch 0020: Loss 37.5498 | AUC 0.6219 | Recall 0.7985 | Precision 0.7985 | AP 0.8542 | F1 0.7985 | Time 6.43\n",
      "Epoch 0021: Loss 39.4061 | AUC 0.5410 | Recall 0.7678 | Precision 0.7678 | AP 0.8306 | F1 0.7678 | Time 6.43\n",
      "Epoch 0022: Loss 40.3587 | AUC 0.5444 | Recall 0.7695 | Precision 0.7695 | AP 0.8315 | F1 0.7695 | Time 6.68\n",
      "Epoch 0023: Loss 40.6904 | AUC 0.5467 | Recall 0.7715 | Precision 0.7715 | AP 0.8321 | F1 0.7715 | Time 6.42\n",
      "Epoch 0024: Loss 40.6437 | AUC 0.5463 | Recall 0.7712 | Precision 0.7712 | AP 0.8320 | F1 0.7712 | Time 6.42\n",
      "Epoch 0025: Loss 40.2543 | AUC 0.5434 | Recall 0.7690 | Precision 0.7690 | AP 0.8312 | F1 0.7690 | Time 6.39\n",
      "Epoch 0026: Loss 39.4141 | AUC 0.5412 | Recall 0.7678 | Precision 0.7678 | AP 0.8306 | F1 0.7678 | Time 6.40\n",
      "Epoch 0027: Loss 37.9811 | AUC 0.5895 | Recall 0.7859 | Precision 0.7859 | AP 0.8443 | F1 0.7859 | Time 6.36\n",
      "Epoch 0028: Loss 37.4942 | AUC 0.7158 | Recall 0.8438 | Precision 0.8438 | AP 0.8803 | F1 0.8438 | Time 6.35\n",
      "Epoch 0029: Loss 38.8547 | AUC 0.6482 | Recall 0.8158 | Precision 0.8158 | AP 0.8636 | F1 0.8158 | Time 6.19\n",
      "Epoch 0030: Loss 39.2942 | AUC 0.6214 | Recall 0.8022 | Precision 0.8022 | AP 0.8566 | F1 0.8022 | Time 6.26\n",
      "Epoch 0031: Loss 38.3086 | AUC 0.6779 | Recall 0.8303 | Precision 0.8303 | AP 0.8712 | F1 0.8303 | Time 6.19\n",
      "Epoch 0032: Loss 37.3627 | AUC 0.7038 | Recall 0.8337 | Precision 0.8337 | AP 0.8778 | F1 0.8337 | Time 6.24\n",
      "Epoch 0033: Loss 37.7943 | AUC 0.6014 | Recall 0.7933 | Precision 0.7933 | AP 0.8480 | F1 0.7933 | Time 6.23\n",
      "Epoch 0034: Loss 38.4468 | AUC 0.5644 | Recall 0.7769 | Precision 0.7769 | AP 0.8368 | F1 0.7769 | Time 6.32\n",
      "Epoch 0035: Loss 38.4586 | AUC 0.5636 | Recall 0.7769 | Precision 0.7769 | AP 0.8366 | F1 0.7769 | Time 6.29\n",
      "Epoch 0036: Loss 37.9140 | AUC 0.5936 | Recall 0.7861 | Precision 0.7861 | AP 0.8456 | F1 0.7861 | Time 6.20\n",
      "Epoch 0037: Loss 37.3647 | AUC 0.6572 | Recall 0.8139 | Precision 0.8139 | AP 0.8649 | F1 0.8139 | Time 6.23\n",
      "Epoch 0038: Loss 37.6038 | AUC 0.7127 | Recall 0.8419 | Precision 0.8419 | AP 0.8795 | F1 0.8419 | Time 6.21\n",
      "Epoch 0039: Loss 38.0870 | AUC 0.6894 | Recall 0.8350 | Precision 0.8350 | AP 0.8740 | F1 0.8350 | Time 6.24\n",
      "Epoch 0040: Loss 37.9781 | AUC 0.6950 | Recall 0.8362 | Precision 0.8362 | AP 0.8754 | F1 0.8362 | Time 6.23\n",
      "Epoch 0041: Loss 37.4804 | AUC 0.7157 | Recall 0.8438 | Precision 0.8438 | AP 0.8802 | F1 0.8438 | Time 6.33\n",
      "Epoch 0042: Loss 37.3778 | AUC 0.6514 | Recall 0.8121 | Precision 0.8121 | AP 0.8632 | F1 0.8121 | Time 6.18\n",
      "Epoch 0043: Loss 37.6793 | AUC 0.6100 | Recall 0.7968 | Precision 0.7968 | AP 0.8506 | F1 0.7968 | Time 6.21\n",
      "Epoch 0044: Loss 37.8154 | AUC 0.5997 | Recall 0.7903 | Precision 0.7903 | AP 0.8474 | F1 0.7903 | Time 6.23\n",
      "Epoch 0045: Loss 37.6020 | AUC 0.6161 | Recall 0.7987 | Precision 0.7987 | AP 0.8525 | F1 0.7987 | Time 6.26\n",
      "Epoch 0046: Loss 37.3577 | AUC 0.6629 | Recall 0.8132 | Precision 0.8132 | AP 0.8667 | F1 0.8132 | Time 6.41\n",
      "Epoch 0047: Loss 37.4346 | AUC 0.7143 | Recall 0.8451 | Precision 0.8451 | AP 0.8800 | F1 0.8451 | Time 6.23\n",
      "Epoch 0048: Loss 37.6252 | AUC 0.7114 | Recall 0.8409 | Precision 0.8409 | AP 0.8791 | F1 0.8409 | Time 6.36\n",
      "Epoch 0049: Loss 37.5688 | AUC 0.7141 | Recall 0.8422 | Precision 0.8422 | AP 0.8798 | F1 0.8422 | Time 6.23\n",
      "Epoch 0050: Loss 37.3787 | AUC 0.7079 | Recall 0.8369 | Precision 0.8369 | AP 0.8788 | F1 0.8369 | Time 6.24\n",
      "Epoch 0051: Loss 37.3686 | AUC 0.6558 | Recall 0.8129 | Precision 0.8129 | AP 0.8645 | F1 0.8129 | Time 6.24\n",
      "Epoch 0052: Loss 37.4949 | AUC 0.6290 | Recall 0.7997 | Precision 0.7997 | AP 0.8563 | F1 0.7997 | Time 6.29\n",
      "Epoch 0053: Loss 37.5284 | AUC 0.6244 | Recall 0.7990 | Precision 0.7990 | AP 0.8549 | F1 0.7990 | Time 6.30\n",
      "Epoch 0054: Loss 37.4204 | AUC 0.6404 | Recall 0.8027 | Precision 0.8027 | AP 0.8598 | F1 0.8027 | Time 6.32\n",
      "Epoch 0055: Loss 37.3436 | AUC 0.6843 | Recall 0.8210 | Precision 0.8210 | AP 0.8727 | F1 0.8210 | Time 6.34\n",
      "Epoch 0056: Loss 37.4043 | AUC 0.7116 | Recall 0.8429 | Precision 0.8429 | AP 0.8795 | F1 0.8429 | Time 6.36\n",
      "Epoch 0057: Loss 37.4717 | AUC 0.7154 | Recall 0.8438 | Precision 0.8438 | AP 0.8801 | F1 0.8438 | Time 6.47\n",
      "Epoch 0058: Loss 37.4188 | AUC 0.7131 | Recall 0.8449 | Precision 0.8449 | AP 0.8798 | F1 0.8449 | Time 6.47\n",
      "Epoch 0059: Loss 37.3442 | AUC 0.6929 | Recall 0.8262 | Precision 0.8262 | AP 0.8750 | F1 0.8262 | Time 6.19\n",
      "Epoch 0060: Loss 37.3702 | AUC 0.6552 | Recall 0.8126 | Precision 0.8126 | AP 0.8643 | F1 0.8126 | Time 6.31\n",
      "Epoch 0061: Loss 37.4206 | AUC 0.6397 | Recall 0.8032 | Precision 0.8032 | AP 0.8596 | F1 0.8032 | Time 6.25\n",
      "Epoch 0062: Loss 37.4048 | AUC 0.6439 | Recall 0.8059 | Precision 0.8059 | AP 0.8608 | F1 0.8059 | Time 6.26\n",
      "Epoch 0063: Loss 37.3488 | AUC 0.6693 | Recall 0.8148 | Precision 0.8148 | AP 0.8685 | F1 0.8148 | Time 6.37\n",
      "Epoch 0064: Loss 37.3544 | AUC 0.6999 | Recall 0.8302 | Precision 0.8302 | AP 0.8768 | F1 0.8302 | Time 6.30\n",
      "Epoch 0065: Loss 37.3918 | AUC 0.7104 | Recall 0.8427 | Precision 0.8427 | AP 0.8793 | F1 0.8427 | Time 6.29\n",
      "Epoch 0066: Loss 37.3915 | AUC 0.7096 | Recall 0.8404 | Precision 0.8404 | AP 0.8791 | F1 0.8404 | Time 6.45\n",
      "Epoch 0067: Loss 37.3523 | AUC 0.6981 | Recall 0.8282 | Precision 0.8282 | AP 0.8764 | F1 0.8282 | Time 6.44\n",
      "Epoch 0068: Loss 37.3454 | AUC 0.6737 | Recall 0.8178 | Precision 0.8178 | AP 0.8698 | F1 0.8178 | Time 6.14\n",
      "Epoch 0069: Loss 37.3680 | AUC 0.6557 | Recall 0.8126 | Precision 0.8126 | AP 0.8645 | F1 0.8126 | Time 6.46\n",
      "Epoch 0070: Loss 37.3679 | AUC 0.6555 | Recall 0.8126 | Precision 0.8126 | AP 0.8644 | F1 0.8126 | Time 6.28\n",
      "Epoch 0071: Loss 37.3460 | AUC 0.6706 | Recall 0.8158 | Precision 0.8158 | AP 0.8689 | F1 0.8158 | Time 6.17\n",
      "Epoch 0072: Loss 37.3444 | AUC 0.6926 | Recall 0.8258 | Precision 0.8258 | AP 0.8750 | F1 0.8258 | Time 6.43\n",
      "Epoch 0073: Loss 37.3608 | AUC 0.7031 | Recall 0.8330 | Precision 0.8330 | AP 0.8776 | F1 0.8330 | Time 6.33\n",
      "Epoch 0074: Loss 37.3620 | AUC 0.7033 | Recall 0.8334 | Precision 0.8334 | AP 0.8777 | F1 0.8334 | Time 6.21\n",
      "Epoch 0075: Loss 37.3452 | AUC 0.6946 | Recall 0.8262 | Precision 0.8262 | AP 0.8755 | F1 0.8261 | Time 6.27\n",
      "Epoch 0076: Loss 37.3457 | AUC 0.6780 | Recall 0.8179 | Precision 0.8179 | AP 0.8711 | F1 0.8179 | Time 6.30\n",
      "Epoch 0077: Loss 37.3582 | AUC 0.6627 | Recall 0.8134 | Precision 0.8134 | AP 0.8666 | F1 0.8134 | Time 6.45\n",
      "Epoch 0078: Loss 37.3657 | AUC 0.6586 | Recall 0.8129 | Precision 0.8129 | AP 0.8653 | F1 0.8129 | Time 6.28\n",
      "Epoch 0079: Loss 37.3535 | AUC 0.6700 | Recall 0.8149 | Precision 0.8149 | AP 0.8687 | F1 0.8149 | Time 6.29\n",
      "Epoch 0080: Loss 37.3499 | AUC 0.6872 | Recall 0.8225 | Precision 0.8225 | AP 0.8735 | F1 0.8225 | Time 6.31\n",
      "Epoch 0081: Loss 37.3572 | AUC 0.6990 | Recall 0.8295 | Precision 0.8295 | AP 0.8766 | F1 0.8295 | Time 6.24\n",
      "Epoch 0082: Loss 37.3589 | AUC 0.7015 | Recall 0.8327 | Precision 0.8327 | AP 0.8772 | F1 0.8327 | Time 6.26\n",
      "Epoch 0083: Loss 37.3488 | AUC 0.6935 | Recall 0.8260 | Precision 0.8260 | AP 0.8751 | F1 0.8260 | Time 6.20\n",
      "Epoch 0084: Loss 37.3459 | AUC 0.6789 | Recall 0.8181 | Precision 0.8181 | AP 0.8712 | F1 0.8181 | Time 6.31\n",
      "Epoch 0085: Loss 37.3535 | AUC 0.6656 | Recall 0.8139 | Precision 0.8139 | AP 0.8675 | F1 0.8139 | Time 6.11\n",
      "Epoch 0086: Loss 37.3557 | AUC 0.6634 | Recall 0.8134 | Precision 0.8134 | AP 0.8668 | F1 0.8134 | Time 6.33\n",
      "Epoch 0087: Loss 37.3473 | AUC 0.6715 | Recall 0.8163 | Precision 0.8163 | AP 0.8692 | F1 0.8163 | Time 6.17\n",
      "Epoch 0088: Loss 37.3428 | AUC 0.6867 | Recall 0.8220 | Precision 0.8220 | AP 0.8734 | F1 0.8220 | Time 6.24\n",
      "Epoch 0089: Loss 37.3488 | AUC 0.6974 | Recall 0.8272 | Precision 0.8272 | AP 0.8762 | F1 0.8272 | Time 6.21\n",
      "Epoch 0090: Loss 37.3556 | AUC 0.6998 | Recall 0.8302 | Precision 0.8302 | AP 0.8768 | F1 0.8302 | Time 6.31\n",
      "Epoch 0091: Loss 37.3476 | AUC 0.6934 | Recall 0.8258 | Precision 0.8258 | AP 0.8751 | F1 0.8258 | Time 6.15\n",
      "Epoch 0092: Loss 37.3424 | AUC 0.6809 | Recall 0.8188 | Precision 0.8188 | AP 0.8718 | F1 0.8188 | Time 6.10\n",
      "Epoch 0093: Loss 37.3498 | AUC 0.6700 | Recall 0.8149 | Precision 0.8149 | AP 0.8687 | F1 0.8149 | Time 6.32\n",
      "Epoch 0094: Loss 37.3509 | AUC 0.6690 | Recall 0.8148 | Precision 0.8148 | AP 0.8684 | F1 0.8148 | Time 6.24\n",
      "Epoch 0095: Loss 37.3441 | AUC 0.6775 | Recall 0.8178 | Precision 0.8178 | AP 0.8709 | F1 0.8178 | Time 6.21\n",
      "Epoch 0096: Loss 37.3432 | AUC 0.6861 | Recall 0.8220 | Precision 0.8220 | AP 0.8732 | F1 0.8220 | Time 6.23\n",
      "Epoch 0097: Loss 37.3465 | AUC 0.6936 | Recall 0.8256 | Precision 0.8256 | AP 0.8752 | F1 0.8256 | Time 6.20\n",
      "Epoch 0098: Loss 37.3492 | AUC 0.6948 | Recall 0.8262 | Precision 0.8262 | AP 0.8755 | F1 0.8262 | Time 6.27\n",
      "Epoch 0099: Loss 37.3455 | AUC 0.6905 | Recall 0.8241 | Precision 0.8241 | AP 0.8744 | F1 0.8241 | Time 6.15\n"
     ]
    }
   ],
   "source": [
    "conda_compile = conad_mode.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0183 | AUC 0.5953 | Recall 0.8226 | Precision 0.8226 | AP 0.8325 | F1 0.8226 | Time 0.86\n",
      "tensor([0, 1]) tensor([3354,  491])\n"
     ]
    }
   ],
   "source": [
    "conad_ip_pred_res, conad_ip_score_res, conad_ip_prob_res, conad_ip_conf_res = conda_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(conad_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnomalyDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalydae_model = AnomalyDAE(emb_dim=128, hid_dim=128, num_layers=68, weight_decay=0.02, \n",
    "                            backbone=None, alpha=0.5, theta=1.0, eta=1.0, \n",
    "                            contamination=0.1, lr=0.004, epoch=100, gpu=-1, \n",
    "                            verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 322.5231 | AUC 0.5455 | Recall 0.7839 | Precision 0.7839 | AP 0.8296 | F1 0.7839 | Time 2.27\n",
      "Epoch 0001: Loss 786615.7500 | AUC 0.5049 | Recall 0.7975 | Precision 0.7975 | AP 0.7971 | F1 0.7975 | Time 2.19\n",
      "Epoch 0002: Loss 180216.4688 | AUC 0.5083 | Recall 0.7953 | Precision 0.7953 | AP 0.7985 | F1 0.7953 | Time 2.14\n",
      "Epoch 0003: Loss 288449.0938 | AUC 0.5111 | Recall 0.7940 | Precision 0.7940 | AP 0.8001 | F1 0.7940 | Time 2.21\n",
      "Epoch 0004: Loss 85409.9531 | AUC 0.5130 | Recall 0.7928 | Precision 0.7928 | AP 0.8010 | F1 0.7928 | Time 2.20\n",
      "Epoch 0005: Loss 260072.4219 | AUC 0.5112 | Recall 0.7921 | Precision 0.7921 | AP 0.8001 | F1 0.7921 | Time 2.14\n",
      "Epoch 0006: Loss 201477.9219 | AUC 0.5113 | Recall 0.7920 | Precision 0.7920 | AP 0.8002 | F1 0.7920 | Time 2.17\n",
      "Epoch 0007: Loss 43496.6055 | AUC 0.5105 | Recall 0.7908 | Precision 0.7908 | AP 0.7997 | F1 0.7908 | Time 2.31\n",
      "Epoch 0008: Loss 108959.7188 | AUC 0.5137 | Recall 0.7909 | Precision 0.7909 | AP 0.8015 | F1 0.7909 | Time 2.39\n",
      "Epoch 0009: Loss 115391.0547 | AUC 0.5136 | Recall 0.7909 | Precision 0.7909 | AP 0.8015 | F1 0.7909 | Time 2.24\n",
      "Epoch 0010: Loss 55420.0977 | AUC 0.5207 | Recall 0.7909 | Precision 0.7909 | AP 0.8029 | F1 0.7909 | Time 2.47\n",
      "Epoch 0011: Loss 18445.8672 | AUC 0.5135 | Recall 0.7908 | Precision 0.7908 | AP 0.7992 | F1 0.7908 | Time 2.59\n",
      "Epoch 0012: Loss 41848.1758 | AUC 0.5143 | Recall 0.7908 | Precision 0.7908 | AP 0.7999 | F1 0.7908 | Time 2.31\n",
      "Epoch 0013: Loss 32211.5820 | AUC 0.5127 | Recall 0.7904 | Precision 0.7904 | AP 0.7993 | F1 0.7904 | Time 2.42\n",
      "Epoch 0014: Loss 4952.4624 | AUC 0.4988 | Recall 0.7893 | Precision 0.7893 | AP 0.7932 | F1 0.7890 | Time 2.36\n",
      "Epoch 0015: Loss 29850.3613 | AUC 0.5126 | Recall 0.7903 | Precision 0.7903 | AP 0.8011 | F1 0.7903 | Time 2.42\n",
      "Epoch 0016: Loss 38234.3828 | AUC 0.5107 | Recall 0.7899 | Precision 0.7899 | AP 0.8005 | F1 0.7899 | Time 2.47\n",
      "Epoch 0017: Loss 30269.8652 | AUC 0.5090 | Recall 0.7894 | Precision 0.7894 | AP 0.8003 | F1 0.7894 | Time 2.27\n",
      "Epoch 0018: Loss 16014.0088 | AUC 0.5070 | Recall 0.7884 | Precision 0.7884 | AP 0.8007 | F1 0.7883 | Time 2.60\n",
      "Epoch 0019: Loss 4236.7529 | AUC 0.5150 | Recall 0.7899 | Precision 0.7899 | AP 0.8074 | F1 0.7899 | Time 3.19\n",
      "Epoch 0020: Loss 1441.8619 | AUC 0.4866 | Recall 0.7811 | Precision 0.7811 | AP 0.7880 | F1 0.7811 | Time 3.40\n",
      "Epoch 0021: Loss 1163.3936 | AUC 0.4892 | Recall 0.7832 | Precision 0.7832 | AP 0.7882 | F1 0.7832 | Time 3.67\n",
      "Epoch 0022: Loss 130.1402 | AUC 0.5734 | Recall 0.7817 | Precision 0.7817 | AP 0.8394 | F1 0.7817 | Time 2.98\n",
      "Epoch 0023: Loss 129.7206 | AUC 0.5728 | Recall 0.7816 | Precision 0.7816 | AP 0.8392 | F1 0.7815 | Time 2.50\n",
      "Epoch 0024: Loss 129.1476 | AUC 0.5764 | Recall 0.7839 | Precision 0.7839 | AP 0.8397 | F1 0.7839 | Time 2.79\n",
      "Epoch 0025: Loss 128.4349 | AUC 0.5781 | Recall 0.7839 | Precision 0.7839 | AP 0.8400 | F1 0.7839 | Time 3.16\n",
      "Epoch 0026: Loss 127.5948 | AUC 0.5806 | Recall 0.7842 | Precision 0.7842 | AP 0.8407 | F1 0.7841 | Time 2.56\n",
      "Epoch 0027: Loss 126.6392 | AUC 0.5838 | Recall 0.7864 | Precision 0.7864 | AP 0.8415 | F1 0.7857 | Time 2.47\n",
      "Epoch 0028: Loss 125.5793 | AUC 0.5877 | Recall 0.7863 | Precision 0.7863 | AP 0.8426 | F1 0.7863 | Time 2.29\n",
      "Epoch 0029: Loss 124.4250 | AUC 0.5917 | Recall 0.7881 | Precision 0.7881 | AP 0.8436 | F1 0.7881 | Time 2.26\n",
      "Epoch 0030: Loss 123.1854 | AUC 0.5960 | Recall 0.7894 | Precision 0.7894 | AP 0.8446 | F1 0.7894 | Time 2.34\n",
      "Epoch 0031: Loss 121.8689 | AUC 0.6003 | Recall 0.7908 | Precision 0.7908 | AP 0.8456 | F1 0.7907 | Time 2.34\n",
      "Epoch 0032: Loss 120.4831 | AUC 0.6036 | Recall 0.7918 | Precision 0.7918 | AP 0.8462 | F1 0.7917 | Time 2.23\n",
      "Epoch 0033: Loss 119.0349 | AUC 0.6058 | Recall 0.7930 | Precision 0.7930 | AP 0.8465 | F1 0.7930 | Time 2.30\n",
      "Epoch 0034: Loss 117.6137 | AUC 0.6080 | Recall 0.7988 | Precision 0.7988 | AP 0.8468 | F1 0.7988 | Time 2.34\n",
      "Epoch 0035: Loss 117.0741 | AUC 0.6130 | Recall 0.7951 | Precision 0.7951 | AP 0.8479 | F1 0.7950 | Time 2.29\n",
      "Epoch 0036: Loss 116.7439 | AUC 0.6154 | Recall 0.8013 | Precision 0.8013 | AP 0.8481 | F1 0.7990 | Time 2.37\n",
      "Epoch 0037: Loss 116.5685 | AUC 0.6063 | Recall 0.7995 | Precision 0.7995 | AP 0.8448 | F1 0.7994 | Time 2.37\n",
      "Epoch 0038: Loss 116.5112 | AUC 0.5963 | Recall 0.7977 | Precision 0.7977 | AP 0.8412 | F1 0.7977 | Time 2.35\n",
      "Epoch 0039: Loss 116.5367 | AUC 0.5838 | Recall 0.7933 | Precision 0.7933 | AP 0.8372 | F1 0.7933 | Time 2.30\n",
      "Epoch 0040: Loss 116.6102 | AUC 0.5737 | Recall 0.7901 | Precision 0.7901 | AP 0.8338 | F1 0.7901 | Time 2.31\n",
      "Epoch 0041: Loss 116.7191 | AUC 0.5640 | Recall 0.7859 | Precision 0.7859 | AP 0.8304 | F1 0.7859 | Time 2.24\n",
      "Epoch 0042: Loss 116.8424 | AUC 0.5552 | Recall 0.7826 | Precision 0.7826 | AP 0.8273 | F1 0.7826 | Time 2.36\n",
      "Epoch 0043: Loss 116.9653 | AUC 0.5481 | Recall 0.7797 | Precision 0.7797 | AP 0.8247 | F1 0.7797 | Time 2.35\n",
      "Epoch 0044: Loss 117.0813 | AUC 0.5421 | Recall 0.7801 | Precision 0.7801 | AP 0.8225 | F1 0.7801 | Time 2.33\n",
      "Epoch 0045: Loss 117.1838 | AUC 0.5374 | Recall 0.7792 | Precision 0.7792 | AP 0.8207 | F1 0.7792 | Time 2.41\n",
      "Epoch 0046: Loss 117.2709 | AUC 0.5341 | Recall 0.7779 | Precision 0.7779 | AP 0.8194 | F1 0.7779 | Time 2.42\n",
      "Epoch 0047: Loss 117.3387 | AUC 0.5309 | Recall 0.7774 | Precision 0.7774 | AP 0.8182 | F1 0.7769 | Time 2.35\n",
      "Epoch 0048: Loss 117.3878 | AUC 0.5290 | Recall 0.7779 | Precision 0.7779 | AP 0.8175 | F1 0.7778 | Time 2.35\n",
      "Epoch 0049: Loss 117.4150 | AUC 0.5285 | Recall 0.7777 | Precision 0.7777 | AP 0.8173 | F1 0.7776 | Time 2.31\n",
      "Epoch 0050: Loss 117.4208 | AUC 0.5284 | Recall 0.7777 | Precision 0.7777 | AP 0.8173 | F1 0.7776 | Time 2.29\n",
      "Epoch 0051: Loss 117.4067 | AUC 0.5286 | Recall 0.7779 | Precision 0.7779 | AP 0.8173 | F1 0.7776 | Time 2.42\n",
      "Epoch 0052: Loss 117.3745 | AUC 0.5300 | Recall 0.7779 | Precision 0.7779 | AP 0.8179 | F1 0.7778 | Time 2.33\n",
      "Epoch 0053: Loss 117.3264 | AUC 0.5315 | Recall 0.7775 | Precision 0.7775 | AP 0.8185 | F1 0.7770 | Time 2.42\n",
      "Epoch 0054: Loss 117.2673 | AUC 0.5341 | Recall 0.7779 | Precision 0.7779 | AP 0.8195 | F1 0.7779 | Time 2.29\n",
      "Epoch 0055: Loss 117.1976 | AUC 0.5368 | Recall 0.7794 | Precision 0.7794 | AP 0.8205 | F1 0.7794 | Time 2.31\n",
      "Epoch 0056: Loss 117.1202 | AUC 0.5401 | Recall 0.7794 | Precision 0.7794 | AP 0.8218 | F1 0.7794 | Time 2.34\n",
      "Epoch 0057: Loss 117.0387 | AUC 0.5441 | Recall 0.7801 | Precision 0.7801 | AP 0.8232 | F1 0.7801 | Time 2.28\n",
      "Epoch 0058: Loss 116.9544 | AUC 0.5485 | Recall 0.7801 | Precision 0.7801 | AP 0.8249 | F1 0.7801 | Time 2.30\n",
      "Epoch 0059: Loss 116.8715 | AUC 0.5535 | Recall 0.7817 | Precision 0.7817 | AP 0.8267 | F1 0.7819 | Time 2.34\n",
      "Epoch 0060: Loss 116.7910 | AUC 0.5585 | Recall 0.7834 | Precision 0.7834 | AP 0.8285 | F1 0.7836 | Time 2.37\n",
      "Epoch 0061: Loss 116.7151 | AUC 0.5639 | Recall 0.7858 | Precision 0.7858 | AP 0.8304 | F1 0.7847 | Time 2.36\n",
      "Epoch 0062: Loss 116.6487 | AUC 0.5695 | Recall 0.7894 | Precision 0.7894 | AP 0.8323 | F1 0.7894 | Time 2.30\n",
      "Epoch 0063: Loss 116.5929 | AUC 0.5747 | Recall 0.7904 | Precision 0.7904 | AP 0.8342 | F1 0.7905 | Time 2.28\n",
      "Epoch 0064: Loss 116.5510 | AUC 0.5798 | Recall 0.7923 | Precision 0.7923 | AP 0.8359 | F1 0.7923 | Time 2.30\n",
      "Epoch 0065: Loss 116.5216 | AUC 0.5845 | Recall 0.7935 | Precision 0.7935 | AP 0.8374 | F1 0.7935 | Time 2.27\n",
      "Epoch 0066: Loss 116.5021 | AUC 0.5895 | Recall 0.7958 | Precision 0.7958 | AP 0.8391 | F1 0.7959 | Time 2.36\n",
      "Epoch 0067: Loss 116.4955 | AUC 0.5947 | Recall 0.7972 | Precision 0.7972 | AP 0.8407 | F1 0.7967 | Time 2.31\n",
      "Epoch 0068: Loss 116.4959 | AUC 0.5989 | Recall 0.7970 | Precision 0.7970 | AP 0.8422 | F1 0.7970 | Time 2.43\n",
      "Epoch 0069: Loss 116.5054 | AUC 0.6020 | Recall 0.7978 | Precision 0.7978 | AP 0.8433 | F1 0.7976 | Time 2.38\n",
      "Epoch 0070: Loss 116.5180 | AUC 0.6042 | Recall 0.7983 | Precision 0.7983 | AP 0.8441 | F1 0.7985 | Time 2.30\n",
      "Epoch 0071: Loss 116.5285 | AUC 0.6053 | Recall 0.7997 | Precision 0.7997 | AP 0.8445 | F1 0.7997 | Time 2.31\n",
      "Epoch 0072: Loss 116.5345 | AUC 0.6060 | Recall 0.7998 | Precision 0.7998 | AP 0.8448 | F1 0.7998 | Time 2.40\n",
      "Epoch 0073: Loss 116.5335 | AUC 0.6059 | Recall 0.7998 | Precision 0.7998 | AP 0.8448 | F1 0.7998 | Time 2.31\n",
      "Epoch 0074: Loss 116.5264 | AUC 0.6058 | Recall 0.7993 | Precision 0.7993 | AP 0.8447 | F1 0.7992 | Time 2.28\n",
      "Epoch 0075: Loss 116.5151 | AUC 0.6050 | Recall 0.7983 | Precision 0.7983 | AP 0.8444 | F1 0.7983 | Time 2.27\n",
      "Epoch 0076: Loss 116.5009 | AUC 0.6039 | Recall 0.7982 | Precision 0.7982 | AP 0.8440 | F1 0.7980 | Time 2.35\n",
      "Epoch 0077: Loss 116.4853 | AUC 0.6021 | Recall 0.7977 | Precision 0.7977 | AP 0.8433 | F1 0.7976 | Time 2.30\n",
      "Epoch 0078: Loss 116.4739 | AUC 0.5994 | Recall 0.7973 | Precision 0.7973 | AP 0.8424 | F1 0.7973 | Time 2.27\n",
      "Epoch 0079: Loss 116.4685 | AUC 0.5965 | Recall 0.7978 | Precision 0.7978 | AP 0.8414 | F1 0.7978 | Time 2.37\n",
      "Epoch 0080: Loss 116.4670 | AUC 0.5933 | Recall 0.7958 | Precision 0.7958 | AP 0.8404 | F1 0.7959 | Time 2.36\n",
      "Epoch 0081: Loss 116.4694 | AUC 0.5905 | Recall 0.7956 | Precision 0.7956 | AP 0.8395 | F1 0.7956 | Time 2.24\n",
      "Epoch 0082: Loss 116.4719 | AUC 0.5890 | Recall 0.7940 | Precision 0.7940 | AP 0.8390 | F1 0.7939 | Time 2.27\n",
      "Epoch 0083: Loss 116.4724 | AUC 0.5885 | Recall 0.7948 | Precision 0.7948 | AP 0.8389 | F1 0.7949 | Time 2.34\n",
      "Epoch 0084: Loss 116.4702 | AUC 0.5889 | Recall 0.7948 | Precision 0.7948 | AP 0.8390 | F1 0.7948 | Time 2.28\n",
      "Epoch 0085: Loss 116.4664 | AUC 0.5900 | Recall 0.7948 | Precision 0.7948 | AP 0.8394 | F1 0.7948 | Time 2.33\n",
      "Epoch 0086: Loss 116.4621 | AUC 0.5916 | Recall 0.7960 | Precision 0.7960 | AP 0.8398 | F1 0.7960 | Time 2.29\n",
      "Epoch 0087: Loss 116.4587 | AUC 0.5937 | Recall 0.7966 | Precision 0.7966 | AP 0.8405 | F1 0.7960 | Time 2.33\n",
      "Epoch 0088: Loss 116.4576 | AUC 0.5956 | Recall 0.7970 | Precision 0.7970 | AP 0.8411 | F1 0.7966 | Time 2.32\n",
      "Epoch 0089: Loss 116.4579 | AUC 0.5974 | Recall 0.7978 | Precision 0.7978 | AP 0.8417 | F1 0.7980 | Time 2.31\n",
      "Epoch 0090: Loss 116.4589 | AUC 0.5990 | Recall 0.7972 | Precision 0.7972 | AP 0.8423 | F1 0.7972 | Time 2.35\n",
      "Epoch 0091: Loss 116.4598 | AUC 0.5998 | Recall 0.7973 | Precision 0.7973 | AP 0.8425 | F1 0.7973 | Time 2.31\n",
      "Epoch 0092: Loss 116.4602 | AUC 0.6002 | Recall 0.7972 | Precision 0.7972 | AP 0.8427 | F1 0.7972 | Time 2.26\n",
      "Epoch 0093: Loss 116.4594 | AUC 0.6003 | Recall 0.7972 | Precision 0.7972 | AP 0.8427 | F1 0.7972 | Time 2.44\n",
      "Epoch 0094: Loss 116.4579 | AUC 0.5998 | Recall 0.7973 | Precision 0.7973 | AP 0.8425 | F1 0.7973 | Time 2.36\n",
      "Epoch 0095: Loss 116.4562 | AUC 0.5991 | Recall 0.7972 | Precision 0.7972 | AP 0.8423 | F1 0.7972 | Time 2.35\n",
      "Epoch 0096: Loss 116.4546 | AUC 0.5979 | Recall 0.7977 | Precision 0.7977 | AP 0.8419 | F1 0.7977 | Time 2.35\n",
      "Epoch 0097: Loss 116.4532 | AUC 0.5969 | Recall 0.7973 | Precision 0.7973 | AP 0.8416 | F1 0.7963 | Time 2.42\n",
      "Epoch 0098: Loss 116.4522 | AUC 0.5954 | Recall 0.7966 | Precision 0.7966 | AP 0.8411 | F1 0.7968 | Time 2.35\n",
      "Epoch 0099: Loss 116.4517 | AUC 0.5945 | Recall 0.7963 | Precision 0.7963 | AP 0.8408 | F1 0.7960 | Time 2.35\n"
     ]
    }
   ],
   "source": [
    "anomalydae_compile = anomalydae_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0183 | AUC 0.5953 | Recall 0.8226 | Precision 0.8226 | AP 0.8325 | F1 0.8226 | Time 0.86\n",
      "tensor([0, 1]) tensor([3354,  491])\n"
     ]
    }
   ],
   "source": [
    "anomalydae_ip_pred_res, anomalydae_ip_score_res, anomalydae_ip_prob_res, anomalydae_ip_conf_res = conda_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(anomalydae_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
