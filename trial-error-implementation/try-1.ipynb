{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_labeled_path = \"C:\\\\Users\\\\asus\\\\Documents\\\\nids-pcap-dataset\\\\unsw_parquet_used_dataset\\\\unsw_labeled.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import parquet file\n",
    "unsw_w_st = pd.read_parquet(unsw_labeled_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_ip</th>\n",
       "      <th>destination_ip</th>\n",
       "      <th>source_port</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>info_message</th>\n",
       "      <th>attack_category</th>\n",
       "      <th>is_malware</th>\n",
       "      <th>source_ip_info</th>\n",
       "      <th>source_port_info</th>\n",
       "      <th>dest_ip_info</th>\n",
       "      <th>dest_port_info</th>\n",
       "      <th>count_benign</th>\n",
       "      <th>count_malware</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>4657</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>4657 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>149.171.126.18 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>80 GET /oKmwKoVbq HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.45.176.3</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>32473</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /level/15/exec/-/buffers/assigned/dump HTT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>175.45.176.3 GET /level/15/exec/-/buffers/assi...</td>\n",
       "      <td>32473 GET /level/15/exec/-/buffers/assigned/du...</td>\n",
       "      <td>149.171.126.18 GET /level/15/exec/-/buffers/as...</td>\n",
       "      <td>80 GET /level/15/exec/-/buffers/assigned/dump ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>49194</td>\n",
       "      <td>80</td>\n",
       "      <td>GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.0 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>49194 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>149.171.126.17 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>80 GET eLWfxXSPkc HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.14</td>\n",
       "      <td>51435</td>\n",
       "      <td>80</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET / HTTP/1.1</td>\n",
       "      <td>51435 GET / HTTP/1.1</td>\n",
       "      <td>149.171.126.14 GET / HTTP/1.1</td>\n",
       "      <td>80 GET / HTTP/1.1</td>\n",
       "      <td>46862</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>64694</td>\n",
       "      <td>80</td>\n",
       "      <td>GET /scripts/cbag/ag.exe?page=FileDownload&amp;id=...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>175.45.176.1 GET /scripts/cbag/ag.exe?page=Fil...</td>\n",
       "      <td>64694 GET /scripts/cbag/ag.exe?page=FileDownlo...</td>\n",
       "      <td>149.171.126.19 GET /scripts/cbag/ag.exe?page=F...</td>\n",
       "      <td>80 GET /scripts/cbag/ag.exe?page=FileDownload&amp;...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_ip  destination_ip source_port destination_port   \n",
       "index                                                              \n",
       "1      175.45.176.1  149.171.126.18        4657               80  \\\n",
       "2      175.45.176.3  149.171.126.18       32473               80   \n",
       "6      175.45.176.0  149.171.126.17       49194               80   \n",
       "9      175.45.176.1  149.171.126.14       51435               80   \n",
       "10     175.45.176.1  149.171.126.19       64694               80   \n",
       "\n",
       "                                            info_message attack_category   \n",
       "index                                                                      \n",
       "1                               GET /oKmwKoVbq HTTP/1.1              NaN  \\\n",
       "2      GET /level/15/exec/-/buffers/assigned/dump HTT...             NaN   \n",
       "6                               GET eLWfxXSPkc HTTP/1.1              NaN   \n",
       "9                                        GET / HTTP/1.1              NaN   \n",
       "10     GET /scripts/cbag/ag.exe?page=FileDownload&id=...             NaN   \n",
       "\n",
       "       is_malware                                     source_ip_info   \n",
       "index                                                                  \n",
       "1               0              175.45.176.1 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2               1  175.45.176.3 GET /level/15/exec/-/buffers/assi...   \n",
       "6               0              175.45.176.0 GET eLWfxXSPkc HTTP/1.1    \n",
       "9               0                       175.45.176.1 GET / HTTP/1.1    \n",
       "10              0  175.45.176.1 GET /scripts/cbag/ag.exe?page=Fil...   \n",
       "\n",
       "                                        source_port_info   \n",
       "index                                                      \n",
       "1                          4657 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2      32473 GET /level/15/exec/-/buffers/assigned/du...   \n",
       "6                         49194 GET eLWfxXSPkc HTTP/1.1    \n",
       "9                                  51435 GET / HTTP/1.1    \n",
       "10     64694 GET /scripts/cbag/ag.exe?page=FileDownlo...   \n",
       "\n",
       "                                            dest_ip_info   \n",
       "index                                                      \n",
       "1                149.171.126.18 GET /oKmwKoVbq HTTP/1.1   \\\n",
       "2      149.171.126.18 GET /level/15/exec/-/buffers/as...   \n",
       "6                149.171.126.17 GET eLWfxXSPkc HTTP/1.1    \n",
       "9                         149.171.126.14 GET / HTTP/1.1    \n",
       "10     149.171.126.19 GET /scripts/cbag/ag.exe?page=F...   \n",
       "\n",
       "                                          dest_port_info  count_benign   \n",
       "index                                                                    \n",
       "1                            80 GET /oKmwKoVbq HTTP/1.1              1  \\\n",
       "2      80 GET /level/15/exec/-/buffers/assigned/dump ...             1   \n",
       "6                            80 GET eLWfxXSPkc HTTP/1.1              1   \n",
       "9                                     80 GET / HTTP/1.1          46862   \n",
       "10     80 GET /scripts/cbag/ag.exe?page=FileDownload&...             1   \n",
       "\n",
       "       count_malware  \n",
       "index                 \n",
       "1                  0  \n",
       "2                  7  \n",
       "6                  0  \n",
       "9               1313  \n",
       "10                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsw_w_st.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 125180 entries, 1 to 490022\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   source_ip         125180 non-null  object  \n",
      " 1   destination_ip    125180 non-null  object  \n",
      " 2   source_port       125180 non-null  object  \n",
      " 3   destination_port  125180 non-null  object  \n",
      " 4   info_message      125180 non-null  object  \n",
      " 5   attack_category   15657 non-null   category\n",
      " 6   is_malware        125180 non-null  int64   \n",
      " 7   source_ip_info    125180 non-null  object  \n",
      " 8   source_port_info  125180 non-null  object  \n",
      " 9   dest_ip_info      125180 non-null  object  \n",
      " 10  dest_port_info    125180 non-null  object  \n",
      " 11  count_benign      125180 non-null  int64   \n",
      " 12  count_malware     125180 non-null  int64   \n",
      "dtypes: category(1), int64(3), object(9)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "unsw_w_st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_w_st['source_port'] = unsw_w_st.source_port.astype('int32')\n",
    "unsw_w_st['destination_port']= unsw_w_st.destination_port.astype('int32')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(unsw_w_st, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    77142\n",
       "1    10484\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87626 entries, 356428 to 256185\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   source_ip         87626 non-null  object  \n",
      " 1   destination_ip    87626 non-null  object  \n",
      " 2   source_port       87626 non-null  int32   \n",
      " 3   destination_port  87626 non-null  int32   \n",
      " 4   info_message      87626 non-null  object  \n",
      " 5   attack_category   10995 non-null  category\n",
      " 6   is_malware        87626 non-null  int64   \n",
      " 7   source_ip_info    87626 non-null  object  \n",
      " 8   source_port_info  87626 non-null  object  \n",
      " 9   dest_ip_info      87626 non-null  object  \n",
      " 10  dest_port_info    87626 non-null  object  \n",
      " 11  count_benign      87626 non-null  int64   \n",
      " 12  count_malware     87626 non-null  int64   \n",
      " 13  sip_ohe           87626 non-null  int32   \n",
      "dtypes: category(1), int32(3), int64(3), object(7)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = train_df.is_malware.value_counts()\n",
    "if value_counts[1] > 160:\n",
    "    df_to_lower = train_df[train_df['is_malware'] == 1].sample(n=160)\n",
    "    train_df = pd.concat([train_df[train_df['is_malware'] == 0], df_to_lower])\n",
    "    nD_train_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([1623,  159], dtype=int64))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_train_df = train_df.drop_duplicates(subset=['dest_port_info'])\n",
    "label_train = nD_train_df['is_malware'].to_numpy()\n",
    "label_train_tensor = torch.tensor(label_train, dtype=torch.float)\n",
    "value_counts = np.unique(label_train, return_counts=True)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37554 entries, 150048 to 143999\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   source_ip         37554 non-null  object  \n",
      " 1   destination_ip    37554 non-null  object  \n",
      " 2   source_port       37554 non-null  int32   \n",
      " 3   destination_port  37554 non-null  int32   \n",
      " 4   info_message      37554 non-null  object  \n",
      " 5   attack_category   4662 non-null   category\n",
      " 6   is_malware        37554 non-null  int64   \n",
      " 7   source_ip_info    37554 non-null  object  \n",
      " 8   source_port_info  37554 non-null  object  \n",
      " 9   dest_ip_info      37554 non-null  object  \n",
      " 10  dest_port_info    37554 non-null  object  \n",
      " 11  count_benign      37554 non-null  int64   \n",
      " 12  count_malware     37554 non-null  int64   \n",
      " 13  sip_ohe           37554 non-null  int32   \n",
      "dtypes: category(1), int32(3), int64(3), object(7)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "1    3044\n",
       "0     849\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_test_df = test_df.drop_duplicates(subset=['dest_port_info'])\n",
    "nD_test_df.is_malware.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = test_df.is_malware.value_counts()\n",
    "if value_counts[1] > 849:\n",
    "    df_to_lower = test_df[test_df['is_malware'] == 1].sample(n=849)\n",
    "    test_df = pd.concat([test_df[test_df['is_malware'] == 0], df_to_lower])\n",
    "    nD_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([849, 757], dtype=int64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nD_test_df = test_df.drop_duplicates(subset=['dest_port_info'])\n",
    "label_test = nD_test_df['is_malware'].to_numpy()\n",
    "value_counts = np.unique(label_test, return_counts=True)\n",
    "label_test_tensor = torch.tensor(label_test, dtype=torch.float)\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_malware\n",
       "0    33132\n",
       "1      849\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.is_malware.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_train = nx.Graph()\n",
    "node_features = []\n",
    "attr = []\n",
    "labels = []\n",
    "\n",
    "for dest_port_info in train_df[\"dest_port_info\"].unique():\n",
    "    nD_graph_train.add_node(dest_port_info)\n",
    "    info_message = train_df[train_df[\"dest_port_info\"] == dest_port_info][\"info_message\"].iloc[0]\n",
    "    label = train_df[train_df[\"dest_port_info\"] == dest_port_info][\"is_malware\"].iloc[0]\n",
    "    node_features.append([float(len(info_message))])\n",
    "    labels.append(label)\n",
    "    \n",
    "for (source_ip), group in train_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"dest_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"dest_port_info\"]\n",
    "        if nD_graph_train.has_edge(from_node, to_node):\n",
    "            nD_graph_train[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_train.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = torch.tensor(labels, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor = torch.tensor(node_features)\n",
    "node_features_tensor = node_features_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 28.],\n",
       "        [199.],\n",
       "        [ 15.],\n",
       "        ...,\n",
       "        [ 34.],\n",
       "        [ 30.],\n",
       "        [ 33.]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1782 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print num of nodes\n",
    "print(\"Number of nodes:\", nD_graph_train.number_of_nodes(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = list(nx.isolates(nD_graph_train))\n",
    "\n",
    "print(\"Isolated nodes:\", len(isolated_nodes), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nD_graph_test = nx.Graph()\n",
    "node_features_test = []\n",
    "labels = []\n",
    "ground_truth = []\n",
    "\n",
    "for dest_port_info in test_df[\"dest_port_info\"].unique():\n",
    "    nD_graph_test.add_node(dest_port_info)\n",
    "    info_message = test_df[test_df[\"dest_port_info\"] == dest_port_info][\"info_message\"].iloc[0]\n",
    "    label = test_df[test_df[\"dest_port_info\"] == dest_port_info][\"is_malware\"].iloc[0]\n",
    "    # print(info_message)\n",
    "    node_features_test.append([float(len(info_message))])\n",
    "    labels.append(label)\n",
    "\n",
    "for (source_ip), group in test_df.groupby([\"source_ip\"]):\n",
    "    for i in range(len(group) - 1):\n",
    "        from_node = group.iloc[i][\"dest_port_info\"]\n",
    "        to_node = group.iloc[i+1][\"dest_port_info\"]\n",
    "        if nD_graph_test.has_edge(from_node, to_node):\n",
    "            nD_graph_test[from_node][to_node][\"weight\"] += 1\n",
    "        else:\n",
    "            nD_graph_test.add_edge(from_node, to_node, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_tensor_test = torch.tensor(node_features_test)\n",
    "node_features_tensor_test = node_features_tensor_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28.],\n",
       "        [15.],\n",
       "        [24.],\n",
       "        ...,\n",
       "        [27.],\n",
       "        [25.],\n",
       "        [36.]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isolated_nodes = list(nx.isolates(nD_graph_test))\n",
    "\n",
    "print(\"Isolated nodes:\", len(isolated_nodes), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from pygod.detector import DOMINANT, OCGNN, GUIDE, GAE, GAAN, AnomalyDAE, CONAD\n",
    "from pygod.metric import eval_average_precision, eval_roc_auc, eval_f1, eval_precision_at_k, eval_recall_at_k\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "import pickle\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyG_train = from_networkx(nD_graph_train)\n",
    "pyG_train = pyG_train\n",
    "pyG_train.x = node_features_tensor\n",
    "\n",
    "pyG_test = from_networkx(nD_graph_test)\n",
    "pyG_test = pyG_test\n",
    "pyG_test.x = node_features_tensor_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOMINANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_model = DOMINANT(gpu=0, weight=0.02, num_layers=144, hid_dim=64, contamination=0.1, lr=0.001, verbose=3, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 3.0377 | AUC 0.6184 | Recall 0.1132 | Precision 0.1132 | AP 0.1885 | F1 0.1132 | Time 0.92\n",
      "Epoch 0001: Loss 3.0375 | AUC 0.6094 | Recall 0.1132 | Precision 0.1132 | AP 0.1879 | F1 0.1132 | Time 0.60\n",
      "Epoch 0002: Loss 3.0372 | AUC 0.6093 | Recall 0.1132 | Precision 0.1132 | AP 0.1878 | F1 0.1132 | Time 0.58\n",
      "Epoch 0003: Loss 3.0360 | AUC 0.6191 | Recall 0.1132 | Precision 0.1132 | AP 0.1896 | F1 0.1132 | Time 0.64\n",
      "Epoch 0004: Loss 3.0315 | AUC 0.6190 | Recall 0.1132 | Precision 0.1132 | AP 0.1896 | F1 0.1132 | Time 0.58\n",
      "Epoch 0005: Loss 3.0224 | AUC 0.6291 | Recall 0.1132 | Precision 0.1132 | AP 0.1917 | F1 0.1132 | Time 0.63\n",
      "Epoch 0006: Loss 3.0166 | AUC 0.6561 | Recall 0.1195 | Precision 0.1195 | AP 0.1980 | F1 0.1195 | Time 0.52\n",
      "Epoch 0007: Loss 3.0220 | AUC 0.6744 | Recall 0.1195 | Precision 0.1195 | AP 0.2030 | F1 0.1195 | Time 0.60\n",
      "Epoch 0008: Loss 3.0133 | AUC 0.6654 | Recall 0.1195 | Precision 0.1195 | AP 0.2006 | F1 0.1195 | Time 0.61\n",
      "Epoch 0009: Loss 3.0095 | AUC 0.6466 | Recall 0.1195 | Precision 0.1195 | AP 0.1957 | F1 0.1195 | Time 0.50\n",
      "Epoch 0010: Loss 3.0087 | AUC 0.6390 | Recall 0.1195 | Precision 0.1195 | AP 0.1938 | F1 0.1195 | Time 0.48\n",
      "Epoch 0011: Loss 3.0064 | AUC 0.6389 | Recall 0.1195 | Precision 0.1195 | AP 0.1937 | F1 0.1195 | Time 0.48\n",
      "Epoch 0012: Loss 3.0014 | AUC 0.6389 | Recall 0.1195 | Precision 0.1195 | AP 0.1937 | F1 0.1195 | Time 0.51\n",
      "Epoch 0013: Loss 2.9938 | AUC 0.6457 | Recall 0.1195 | Precision 0.1195 | AP 0.1953 | F1 0.1195 | Time 0.49\n",
      "Epoch 0014: Loss 2.9848 | AUC 0.6574 | Recall 0.1195 | Precision 0.1195 | AP 0.1983 | F1 0.1195 | Time 0.50\n",
      "Epoch 0015: Loss 2.9739 | AUC 0.6664 | Recall 0.1195 | Precision 0.1195 | AP 0.2006 | F1 0.1195 | Time 0.48\n",
      "Epoch 0016: Loss 2.9547 | AUC 0.6662 | Recall 0.1195 | Precision 0.1195 | AP 0.2006 | F1 0.1195 | Time 0.51\n",
      "Epoch 0017: Loss 2.9204 | AUC 0.6573 | Recall 0.1195 | Precision 0.1195 | AP 0.1984 | F1 0.1195 | Time 0.47\n",
      "Epoch 0018: Loss 2.8631 | AUC 0.6327 | Recall 0.1195 | Precision 0.1195 | AP 0.1926 | F1 0.1195 | Time 0.51\n",
      "Epoch 0019: Loss 2.7601 | AUC 0.6011 | Recall 0.1132 | Precision 0.1132 | AP 0.1863 | F1 0.1132 | Time 0.48\n",
      "Epoch 0020: Loss 2.5714 | AUC 0.6046 | Recall 0.1132 | Precision 0.1132 | AP 0.1849 | F1 0.1132 | Time 0.47\n",
      "Epoch 0021: Loss 2.5364 | AUC 0.7733 | Recall 0.1132 | Precision 0.1132 | AP 0.2439 | F1 0.1132 | Time 0.48\n",
      "Epoch 0022: Loss 2.5990 | AUC 0.7485 | Recall 0.1132 | Precision 0.1132 | AP 0.2391 | F1 0.1132 | Time 0.50\n",
      "Epoch 0023: Loss 2.5166 | AUC 0.7841 | Recall 0.1132 | Precision 0.1132 | AP 0.2481 | F1 0.1132 | Time 0.50\n",
      "Epoch 0024: Loss 2.4876 | AUC 0.7770 | Recall 0.1132 | Precision 0.1132 | AP 0.2429 | F1 0.1136 | Time 0.48\n",
      "Epoch 0025: Loss 2.5292 | AUC 0.6815 | Recall 0.1195 | Precision 0.1195 | AP 0.2027 | F1 0.1195 | Time 0.47\n",
      "Epoch 0026: Loss 2.5481 | AUC 0.6442 | Recall 0.1132 | Precision 0.1132 | AP 0.1930 | F1 0.1136 | Time 0.50\n",
      "Epoch 0027: Loss 2.5287 | AUC 0.6693 | Recall 0.1132 | Precision 0.1132 | AP 0.1992 | F1 0.1132 | Time 0.61\n",
      "Epoch 0028: Loss 2.4927 | AUC 0.7507 | Recall 0.1132 | Precision 0.1132 | AP 0.2301 | F1 0.1132 | Time 0.66\n",
      "Epoch 0029: Loss 2.4807 | AUC 0.7846 | Recall 0.1132 | Precision 0.1132 | AP 0.2478 | F1 0.1132 | Time 0.57\n",
      "Epoch 0030: Loss 2.5092 | AUC 0.7866 | Recall 0.1132 | Precision 0.1132 | AP 0.2488 | F1 0.1132 | Time 0.75\n",
      "Epoch 0031: Loss 2.5160 | AUC 0.7853 | Recall 0.1132 | Precision 0.1132 | AP 0.2486 | F1 0.1132 | Time 0.48\n",
      "Epoch 0032: Loss 2.4872 | AUC 0.7876 | Recall 0.1132 | Precision 0.1132 | AP 0.2496 | F1 0.1136 | Time 0.48\n",
      "Epoch 0033: Loss 2.4761 | AUC 0.7842 | Recall 0.1132 | Precision 0.1132 | AP 0.2462 | F1 0.1132 | Time 0.46\n",
      "Epoch 0034: Loss 2.4881 | AUC 0.7537 | Recall 0.1132 | Precision 0.1132 | AP 0.2315 | F1 0.1136 | Time 0.48\n",
      "Epoch 0035: Loss 2.4974 | AUC 0.7311 | Recall 0.1195 | Precision 0.1195 | AP 0.2216 | F1 0.1195 | Time 0.47\n",
      "Epoch 0036: Loss 2.4921 | AUC 0.7424 | Recall 0.1195 | Precision 0.1195 | AP 0.2264 | F1 0.1195 | Time 0.49\n",
      "Epoch 0037: Loss 2.4778 | AUC 0.7724 | Recall 0.1195 | Precision 0.1195 | AP 0.2403 | F1 0.1195 | Time 0.46\n",
      "Epoch 0038: Loss 2.4693 | AUC 0.7864 | Recall 0.1132 | Precision 0.1132 | AP 0.2479 | F1 0.1132 | Time 0.48\n",
      "Epoch 0039: Loss 2.4739 | AUC 0.7878 | Recall 0.1195 | Precision 0.1195 | AP 0.2500 | F1 0.1195 | Time 0.48\n",
      "Epoch 0040: Loss 2.4789 | AUC 0.7894 | Recall 0.1195 | Precision 0.1195 | AP 0.2508 | F1 0.1195 | Time 0.48\n",
      "Epoch 0041: Loss 2.4717 | AUC 0.7896 | Recall 0.1195 | Precision 0.1195 | AP 0.2510 | F1 0.1195 | Time 0.47\n",
      "Epoch 0042: Loss 2.4616 | AUC 0.7870 | Recall 0.1195 | Precision 0.1195 | AP 0.2493 | F1 0.1195 | Time 0.50\n",
      "Epoch 0043: Loss 2.4591 | AUC 0.7857 | Recall 0.1195 | Precision 0.1195 | AP 0.2477 | F1 0.1195 | Time 0.47\n",
      "Epoch 0044: Loss 2.4617 | AUC 0.7721 | Recall 0.1195 | Precision 0.1195 | AP 0.2404 | F1 0.1195 | Time 0.48\n",
      "Epoch 0045: Loss 2.4615 | AUC 0.7729 | Recall 0.1195 | Precision 0.1195 | AP 0.2410 | F1 0.1195 | Time 0.58\n",
      "Epoch 0046: Loss 2.4612 | AUC 0.7702 | Recall 0.1132 | Precision 0.1132 | AP 0.2396 | F1 0.1132 | Time 0.64\n",
      "Epoch 0047: Loss 2.4464 | AUC 0.7849 | Recall 0.1195 | Precision 0.1195 | AP 0.2476 | F1 0.1195 | Time 0.54\n",
      "Epoch 0048: Loss 2.4687 | AUC 0.7979 | Recall 0.1258 | Precision 0.1258 | AP 0.2572 | F1 0.1266 | Time 0.69\n",
      "Epoch 0049: Loss 2.4595 | AUC 0.7812 | Recall 0.1132 | Precision 0.1132 | AP 0.2470 | F1 0.1132 | Time 0.58\n",
      "Epoch 0050: Loss 2.4794 | AUC 0.7754 | Recall 0.1132 | Precision 0.1132 | AP 0.2437 | F1 0.1132 | Time 0.55\n",
      "Epoch 0051: Loss 2.4723 | AUC 0.7756 | Recall 0.1132 | Precision 0.1132 | AP 0.2439 | F1 0.1132 | Time 0.59\n",
      "Epoch 0052: Loss 2.4509 | AUC 0.7828 | Recall 0.1195 | Precision 0.1195 | AP 0.2460 | F1 0.1195 | Time 0.79\n",
      "Epoch 0053: Loss 2.4542 | AUC 0.7849 | Recall 0.1258 | Precision 0.1258 | AP 0.2487 | F1 0.1258 | Time 0.60\n",
      "Epoch 0054: Loss 2.4611 | AUC 0.7836 | Recall 0.1258 | Precision 0.1258 | AP 0.2484 | F1 0.1258 | Time 0.55\n",
      "Epoch 0055: Loss 2.4419 | AUC 0.7804 | Recall 0.1195 | Precision 0.1195 | AP 0.2452 | F1 0.1195 | Time 0.55\n",
      "Epoch 0056: Loss 2.4484 | AUC 0.7809 | Recall 0.1195 | Precision 0.1195 | AP 0.2450 | F1 0.1195 | Time 0.56\n",
      "Epoch 0057: Loss 2.4491 | AUC 0.7807 | Recall 0.1195 | Precision 0.1195 | AP 0.2460 | F1 0.1195 | Time 0.58\n",
      "Epoch 0058: Loss 2.4395 | AUC 0.7842 | Recall 0.1195 | Precision 0.1195 | AP 0.2485 | F1 0.1195 | Time 0.51\n",
      "Epoch 0059: Loss 2.4390 | AUC 0.7910 | Recall 0.1195 | Precision 0.1195 | AP 0.2527 | F1 0.1195 | Time 0.50\n",
      "Epoch 0060: Loss 2.4394 | AUC 0.7902 | Recall 0.1258 | Precision 0.1258 | AP 0.2523 | F1 0.1274 | Time 0.48\n",
      "Epoch 0061: Loss 2.4261 | AUC 0.7839 | Recall 0.1195 | Precision 0.1195 | AP 0.2481 | F1 0.1195 | Time 0.49\n",
      "Epoch 0062: Loss 2.4294 | AUC 0.7802 | Recall 0.1195 | Precision 0.1195 | AP 0.2451 | F1 0.1195 | Time 0.52\n",
      "Epoch 0063: Loss 2.4275 | AUC 0.7763 | Recall 0.1195 | Precision 0.1195 | AP 0.2429 | F1 0.1195 | Time 0.49\n",
      "Epoch 0064: Loss 2.4204 | AUC 0.7771 | Recall 0.1195 | Precision 0.1195 | AP 0.2439 | F1 0.1195 | Time 0.49\n",
      "Epoch 0065: Loss 2.4231 | AUC 0.7801 | Recall 0.1258 | Precision 0.1258 | AP 0.2463 | F1 0.1262 | Time 0.49\n",
      "Epoch 0066: Loss 2.4129 | AUC 0.7826 | Recall 0.1195 | Precision 0.1195 | AP 0.2474 | F1 0.1195 | Time 0.50\n",
      "Epoch 0067: Loss 2.4141 | AUC 0.7825 | Recall 0.1195 | Precision 0.1195 | AP 0.2479 | F1 0.1195 | Time 0.52\n",
      "Epoch 0068: Loss 2.4096 | AUC 0.7827 | Recall 0.1195 | Precision 0.1195 | AP 0.2482 | F1 0.1195 | Time 0.56\n",
      "Epoch 0069: Loss 2.4062 | AUC 0.7821 | Recall 0.1258 | Precision 0.1258 | AP 0.2478 | F1 0.1258 | Time 0.58\n",
      "Epoch 0070: Loss 2.4011 | AUC 0.7791 | Recall 0.1258 | Precision 0.1258 | AP 0.2457 | F1 0.1258 | Time 0.51\n",
      "Epoch 0071: Loss 2.3993 | AUC 0.7789 | Recall 0.1258 | Precision 0.1258 | AP 0.2451 | F1 0.1258 | Time 0.56\n",
      "Epoch 0072: Loss 2.3952 | AUC 0.7756 | Recall 0.1258 | Precision 0.1258 | AP 0.2433 | F1 0.1258 | Time 0.49\n",
      "Epoch 0073: Loss 2.3955 | AUC 0.7697 | Recall 0.1258 | Precision 0.1258 | AP 0.2400 | F1 0.1258 | Time 0.55\n",
      "Epoch 0074: Loss 2.3907 | AUC 0.7794 | Recall 0.1258 | Precision 0.1258 | AP 0.2458 | F1 0.1258 | Time 0.96\n",
      "Epoch 0075: Loss 2.3896 | AUC 0.7810 | Recall 0.1258 | Precision 0.1258 | AP 0.2473 | F1 0.1258 | Time 0.54\n",
      "Epoch 0076: Loss 2.3895 | AUC 0.7765 | Recall 0.1321 | Precision 0.1321 | AP 0.2442 | F1 0.1321 | Time 0.63\n",
      "Epoch 0077: Loss 2.3865 | AUC 0.7820 | Recall 0.1258 | Precision 0.1258 | AP 0.2479 | F1 0.1258 | Time 0.57\n",
      "Epoch 0078: Loss 2.3863 | AUC 0.7837 | Recall 0.1321 | Precision 0.1321 | AP 0.2487 | F1 0.1329 | Time 0.58\n",
      "Epoch 0079: Loss 2.3863 | AUC 0.7787 | Recall 0.1321 | Precision 0.1321 | AP 0.2451 | F1 0.1321 | Time 0.58\n",
      "Epoch 0080: Loss 2.3849 | AUC 0.7833 | Recall 0.1321 | Precision 0.1321 | AP 0.2479 | F1 0.1321 | Time 0.57\n",
      "Epoch 0081: Loss 2.3841 | AUC 0.7824 | Recall 0.1321 | Precision 0.1321 | AP 0.2472 | F1 0.1321 | Time 0.51\n",
      "Epoch 0082: Loss 2.3844 | AUC 0.7784 | Recall 0.1321 | Precision 0.1321 | AP 0.2444 | F1 0.1321 | Time 0.49\n",
      "Epoch 0083: Loss 2.3830 | AUC 0.7843 | Recall 0.1321 | Precision 0.1321 | AP 0.2487 | F1 0.1321 | Time 0.51\n",
      "Epoch 0084: Loss 2.3816 | AUC 0.7827 | Recall 0.1321 | Precision 0.1321 | AP 0.2479 | F1 0.1321 | Time 0.58\n",
      "Epoch 0085: Loss 2.3821 | AUC 0.7790 | Recall 0.1321 | Precision 0.1321 | AP 0.2452 | F1 0.1321 | Time 0.55\n",
      "Epoch 0086: Loss 2.3810 | AUC 0.7835 | Recall 0.1321 | Precision 0.1321 | AP 0.2485 | F1 0.1321 | Time 0.50\n",
      "Epoch 0087: Loss 2.3797 | AUC 0.7814 | Recall 0.1321 | Precision 0.1321 | AP 0.2470 | F1 0.1321 | Time 0.52\n",
      "Epoch 0088: Loss 2.3803 | AUC 0.7751 | Recall 0.1321 | Precision 0.1321 | AP 0.2426 | F1 0.1321 | Time 0.61\n",
      "Epoch 0089: Loss 2.3793 | AUC 0.7803 | Recall 0.1321 | Precision 0.1321 | AP 0.2460 | F1 0.1321 | Time 0.52\n",
      "Epoch 0090: Loss 2.3782 | AUC 0.7794 | Recall 0.1321 | Precision 0.1321 | AP 0.2453 | F1 0.1321 | Time 0.56\n",
      "Epoch 0091: Loss 2.3786 | AUC 0.7758 | Recall 0.1321 | Precision 0.1321 | AP 0.2428 | F1 0.1321 | Time 0.52\n",
      "Epoch 0092: Loss 2.3774 | AUC 0.7822 | Recall 0.1321 | Precision 0.1321 | AP 0.2474 | F1 0.1321 | Time 0.52\n",
      "Epoch 0093: Loss 2.3766 | AUC 0.7821 | Recall 0.1321 | Precision 0.1321 | AP 0.2475 | F1 0.1321 | Time 0.50\n",
      "Epoch 0094: Loss 2.3771 | AUC 0.7791 | Recall 0.1321 | Precision 0.1321 | AP 0.2449 | F1 0.1321 | Time 0.53\n",
      "Epoch 0095: Loss 2.3758 | AUC 0.7834 | Recall 0.1321 | Precision 0.1321 | AP 0.2483 | F1 0.1321 | Time 0.49\n",
      "Epoch 0096: Loss 2.3749 | AUC 0.7818 | Recall 0.1321 | Precision 0.1321 | AP 0.2470 | F1 0.1321 | Time 0.57\n",
      "Epoch 0097: Loss 2.3754 | AUC 0.7785 | Recall 0.1321 | Precision 0.1321 | AP 0.2442 | F1 0.1321 | Time 0.53\n",
      "Epoch 0098: Loss 2.3743 | AUC 0.7825 | Recall 0.1321 | Precision 0.1321 | AP 0.2473 | F1 0.1321 | Time 0.55\n",
      "Epoch 0099: Loss 2.3735 | AUC 0.7818 | Recall 0.1321 | Precision 0.1321 | AP 0.2469 | F1 0.1321 | Time 0.50\n"
     ]
    }
   ],
   "source": [
    "dominant_compile = dominant_model.fit(pyG_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0021 | AUC 0.7186 | Recall 0.6605 | Precision 0.6605 | AP 0.6132 | F1 0.6605 | Time 0.53\n",
      "tensor([0, 1]) tensor([1411,  195])\n"
     ]
    }
   ],
   "source": [
    "dominant_ip_pred_res, dominant_ip_score_res, dominant_ip_prob_res, dominant_ip_conf_res = dominant_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(dominant_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18277310924369747\n",
      "tensor(0.4714)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "f1_score_ip = eval_f1(label_test_tensor, dominant_ip_pred_res)\n",
    "print(f1_score_ip)\n",
    "precision = eval_precision_at_k(label_test_tensor, dominant_ip_score_res, k=1606)\n",
    "print(precision)\n",
    "recall = eval_recall_at_k(label_test_tensor, dominant_ip_score_res, k=1606)\n",
    "print(recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocgnn_model = OCGNN(hid_dim=64, num_layers=64, weight_decay=0.02, \n",
    "                    contamination=0.1, lr=0.001, epoch=100, gpu=-1, batch_size=0, num_neigh=-1, \n",
    "                    beta=0.5, warmup=2, eps=0.001, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 0.0000 | AUC 0.9777 | Recall 0.7987 | Precision 0.7987 | AP 0.8374 | F1 0.7987 | Time 0.93\n",
      "Epoch 0001: Loss 0.0002 | AUC 0.9665 | Recall 0.7987 | Precision 0.7987 | AP 0.7165 | F1 0.7987 | Time 0.77\n",
      "Epoch 0002: Loss 0.0004 | AUC 0.9521 | Recall 0.7044 | Precision 0.7044 | AP 0.5467 | F1 0.7044 | Time 0.64\n",
      "Epoch 0003: Loss 0.0002 | AUC 0.9501 | Recall 0.6918 | Precision 0.6918 | AP 0.5556 | F1 0.6877 | Time 0.68\n",
      "Epoch 0004: Loss 0.0001 | AUC 0.2881 | Recall 0.0000 | Precision 0.0000 | AP 0.0740 | F1 0.0000 | Time 0.64\n",
      "Epoch 0005: Loss 0.0001 | AUC 0.8981 | Recall 0.2327 | Precision 0.2327 | AP 0.3835 | F1 0.2327 | Time 0.67\n",
      "Epoch 0006: Loss 0.0001 | AUC 0.9061 | Recall 0.2830 | Precision 0.2830 | AP 0.3988 | F1 0.2500 | Time 0.62\n",
      "Epoch 0007: Loss 0.0001 | AUC 0.9433 | Recall 0.6478 | Precision 0.6478 | AP 0.5529 | F1 0.2776 | Time 0.78\n",
      "Epoch 0008: Loss 0.0001 | AUC 0.9571 | Recall 0.7484 | Precision 0.7484 | AP 0.6556 | F1 0.7476 | Time 0.58\n",
      "Epoch 0009: Loss 0.0001 | AUC 0.9547 | Recall 0.7296 | Precision 0.7296 | AP 0.5742 | F1 0.5923 | Time 0.52\n",
      "Epoch 0010: Loss 0.0001 | AUC 0.9542 | Recall 0.6981 | Precision 0.6981 | AP 0.5859 | F1 0.3614 | Time 0.54\n",
      "Epoch 0011: Loss 0.0001 | AUC 0.9673 | Recall 0.8050 | Precision 0.8050 | AP 0.6997 | F1 0.8013 | Time 0.51\n",
      "Epoch 0012: Loss 0.0001 | AUC 0.9743 | Recall 0.8176 | Precision 0.8176 | AP 0.7888 | F1 0.8190 | Time 0.51\n",
      "Epoch 0013: Loss 0.0001 | AUC 0.9790 | Recall 0.8239 | Precision 0.8239 | AP 0.8649 | F1 0.8265 | Time 0.51\n",
      "Epoch 0014: Loss 0.0001 | AUC 0.8118 | Recall 0.0252 | Precision 0.0252 | AP 0.2476 | F1 0.0254 | Time 0.50\n",
      "Epoch 0015: Loss 0.0001 | AUC 0.9439 | Recall 0.6101 | Precision 0.6101 | AP 0.5363 | F1 0.4291 | Time 0.53\n",
      "Epoch 0016: Loss 0.0001 | AUC 0.8533 | Recall 0.0503 | Precision 0.0503 | AP 0.2779 | F1 0.0506 | Time 0.52\n",
      "Epoch 0017: Loss 0.0001 | AUC 0.8563 | Recall 0.0503 | Precision 0.0503 | AP 0.3030 | F1 0.0510 | Time 0.51\n",
      "Epoch 0018: Loss 0.0001 | AUC 0.8561 | Recall 0.0503 | Precision 0.0503 | AP 0.2979 | F1 0.0511 | Time 0.50\n",
      "Epoch 0019: Loss 0.0001 | AUC 0.8071 | Recall 0.0440 | Precision 0.0440 | AP 0.2365 | F1 0.0450 | Time 0.51\n",
      "Epoch 0020: Loss 0.0001 | AUC 0.8001 | Recall 0.0000 | Precision 0.0000 | AP 0.2187 | F1 0.0000 | Time 0.50\n",
      "Epoch 0021: Loss 0.0001 | AUC 0.7011 | Recall 0.0063 | Precision 0.0063 | AP 0.1795 | F1 0.0000 | Time 0.54\n",
      "Epoch 0022: Loss 0.0001 | AUC 0.6999 | Recall 0.0000 | Precision 0.0000 | AP 0.1691 | F1 0.0000 | Time 0.50\n",
      "Epoch 0023: Loss 0.0001 | AUC 0.7109 | Recall 0.0000 | Precision 0.0000 | AP 0.1804 | F1 0.0000 | Time 0.51\n",
      "Epoch 0024: Loss 0.0001 | AUC 0.6985 | Recall 0.0000 | Precision 0.0000 | AP 0.1727 | F1 0.0000 | Time 0.53\n",
      "Epoch 0025: Loss 0.0001 | AUC 0.6974 | Recall 0.0000 | Precision 0.0000 | AP 0.1645 | F1 0.0000 | Time 0.51\n",
      "Epoch 0026: Loss 0.0001 | AUC 0.6909 | Recall 0.0063 | Precision 0.0063 | AP 0.1733 | F1 0.0063 | Time 0.60\n",
      "Epoch 0027: Loss 0.0001 | AUC 0.6893 | Recall 0.0000 | Precision 0.0000 | AP 0.1730 | F1 0.0000 | Time 0.53\n",
      "Epoch 0028: Loss 0.0001 | AUC 0.6895 | Recall 0.0000 | Precision 0.0000 | AP 0.1717 | F1 0.0000 | Time 0.60\n",
      "Epoch 0029: Loss 0.0001 | AUC 0.6874 | Recall 0.0000 | Precision 0.0000 | AP 0.1691 | F1 0.0000 | Time 0.54\n",
      "Epoch 0030: Loss 0.0001 | AUC 0.6872 | Recall 0.0000 | Precision 0.0000 | AP 0.1690 | F1 0.0000 | Time 0.52\n",
      "Epoch 0031: Loss 0.0001 | AUC 0.6867 | Recall 0.0063 | Precision 0.0063 | AP 0.1709 | F1 0.0064 | Time 0.53\n",
      "Epoch 0032: Loss 0.0001 | AUC 0.6816 | Recall 0.0000 | Precision 0.0000 | AP 0.1730 | F1 0.0000 | Time 0.51\n",
      "Epoch 0033: Loss 0.0001 | AUC 0.6662 | Recall 0.0000 | Precision 0.0000 | AP 0.1632 | F1 0.0000 | Time 0.67\n",
      "Epoch 0034: Loss 0.0001 | AUC 0.6560 | Recall 0.0000 | Precision 0.0000 | AP 0.1545 | F1 0.0000 | Time 0.49\n",
      "Epoch 0035: Loss 0.0001 | AUC 0.6788 | Recall 0.0000 | Precision 0.0000 | AP 0.1713 | F1 0.0000 | Time 0.54\n",
      "Epoch 0036: Loss 0.0001 | AUC 0.6819 | Recall 0.0000 | Precision 0.0000 | AP 0.1667 | F1 0.0000 | Time 0.54\n",
      "Epoch 0037: Loss 0.0001 | AUC 0.6812 | Recall 0.0000 | Precision 0.0000 | AP 0.1782 | F1 0.0000 | Time 0.57\n",
      "Epoch 0038: Loss 0.0001 | AUC 0.6863 | Recall 0.0000 | Precision 0.0000 | AP 0.1806 | F1 0.0000 | Time 0.60\n",
      "Epoch 0039: Loss 0.0001 | AUC 0.7086 | Recall 0.0000 | Precision 0.0000 | AP 0.1883 | F1 0.0000 | Time 0.57\n",
      "Epoch 0040: Loss 0.0001 | AUC 0.5623 | Recall 0.0000 | Precision 0.0000 | AP 0.1332 | F1 0.0000 | Time 0.49\n",
      "Epoch 0041: Loss 0.0001 | AUC 0.4388 | Recall 0.0000 | Precision 0.0000 | AP 0.1058 | F1 0.0000 | Time 0.51\n",
      "Epoch 0042: Loss 0.0001 | AUC 0.4106 | Recall 0.0000 | Precision 0.0000 | AP 0.1044 | F1 0.0000 | Time 0.51\n",
      "Epoch 0043: Loss 0.0001 | AUC 0.4007 | Recall 0.0000 | Precision 0.0000 | AP 0.1022 | F1 0.0000 | Time 0.52\n",
      "Epoch 0044: Loss 0.0001 | AUC 0.3647 | Recall 0.0000 | Precision 0.0000 | AP 0.0856 | F1 0.0000 | Time 0.52\n",
      "Epoch 0045: Loss 0.0001 | AUC 0.5245 | Recall 0.0063 | Precision 0.0063 | AP 0.1205 | F1 0.0063 | Time 0.60\n",
      "Epoch 0046: Loss 0.0001 | AUC 0.6806 | Recall 0.0063 | Precision 0.0063 | AP 0.1671 | F1 0.0063 | Time 0.52\n",
      "Epoch 0047: Loss 0.0001 | AUC 0.6860 | Recall 0.0063 | Precision 0.0063 | AP 0.1675 | F1 0.0063 | Time 0.51\n",
      "Epoch 0048: Loss 0.0001 | AUC 0.6873 | Recall 0.0000 | Precision 0.0000 | AP 0.1714 | F1 0.0000 | Time 0.49\n",
      "Epoch 0049: Loss 0.0001 | AUC 0.6898 | Recall 0.0000 | Precision 0.0000 | AP 0.1690 | F1 0.0000 | Time 0.51\n",
      "Epoch 0050: Loss 0.0001 | AUC 0.6896 | Recall 0.0000 | Precision 0.0000 | AP 0.1730 | F1 0.0000 | Time 0.52\n",
      "Epoch 0051: Loss 0.0001 | AUC 0.6871 | Recall 0.0000 | Precision 0.0000 | AP 0.1707 | F1 0.0000 | Time 0.48\n",
      "Epoch 0052: Loss 0.0001 | AUC 0.6859 | Recall 0.0000 | Precision 0.0000 | AP 0.1726 | F1 0.0000 | Time 0.52\n",
      "Epoch 0053: Loss 0.0001 | AUC 0.6870 | Recall 0.0000 | Precision 0.0000 | AP 0.1741 | F1 0.0000 | Time 0.49\n",
      "Epoch 0054: Loss 0.0001 | AUC 0.6859 | Recall 0.0000 | Precision 0.0000 | AP 0.1720 | F1 0.0000 | Time 0.52\n",
      "Epoch 0055: Loss 0.0001 | AUC 0.6848 | Recall 0.0063 | Precision 0.0063 | AP 0.1678 | F1 0.0063 | Time 0.51\n",
      "Epoch 0056: Loss 0.0001 | AUC 0.8160 | Recall 0.0503 | Precision 0.0503 | AP 0.2568 | F1 0.0523 | Time 0.51\n",
      "Epoch 0057: Loss 0.0001 | AUC 0.7831 | Recall 0.0252 | Precision 0.0252 | AP 0.2390 | F1 0.0266 | Time 0.51\n",
      "Epoch 0058: Loss 0.0001 | AUC 0.7817 | Recall 0.0252 | Precision 0.0252 | AP 0.2264 | F1 0.0267 | Time 0.50\n",
      "Epoch 0059: Loss 0.0001 | AUC 0.7822 | Recall 0.0252 | Precision 0.0252 | AP 0.2289 | F1 0.0267 | Time 0.51\n",
      "Epoch 0060: Loss 0.0001 | AUC 0.7869 | Recall 0.0252 | Precision 0.0252 | AP 0.2423 | F1 0.0258 | Time 0.49\n",
      "Epoch 0061: Loss 0.0001 | AUC 0.8530 | Recall 0.0755 | Precision 0.0755 | AP 0.3105 | F1 0.0755 | Time 0.52\n",
      "Epoch 0062: Loss 0.0001 | AUC 0.8167 | Recall 0.0503 | Precision 0.0503 | AP 0.2637 | F1 0.0518 | Time 0.49\n",
      "Epoch 0063: Loss 0.0001 | AUC 0.6853 | Recall 0.0189 | Precision 0.0189 | AP 0.1747 | F1 0.0193 | Time 0.51\n",
      "Epoch 0064: Loss 0.0001 | AUC 0.6849 | Recall 0.0189 | Precision 0.0189 | AP 0.1769 | F1 0.0194 | Time 0.49\n",
      "Epoch 0065: Loss 0.0001 | AUC 0.6837 | Recall 0.0189 | Precision 0.0189 | AP 0.1781 | F1 0.0192 | Time 0.50\n",
      "Epoch 0066: Loss 0.0001 | AUC 0.6793 | Recall 0.0189 | Precision 0.0189 | AP 0.1671 | F1 0.0192 | Time 0.49\n",
      "Epoch 0067: Loss 0.0001 | AUC 0.6799 | Recall 0.0189 | Precision 0.0189 | AP 0.1706 | F1 0.0192 | Time 0.51\n",
      "Epoch 0068: Loss 0.0001 | AUC 0.6885 | Recall 0.0189 | Precision 0.0189 | AP 0.1755 | F1 0.0190 | Time 0.47\n",
      "Epoch 0069: Loss 0.0001 | AUC 0.6912 | Recall 0.0189 | Precision 0.0189 | AP 0.1776 | F1 0.0191 | Time 0.53\n",
      "Epoch 0070: Loss 0.0001 | AUC 0.8353 | Recall 0.0503 | Precision 0.0503 | AP 0.2894 | F1 0.0533 | Time 0.48\n",
      "Epoch 0071: Loss 0.0001 | AUC 0.8296 | Recall 0.0440 | Precision 0.0440 | AP 0.2790 | F1 0.0462 | Time 0.50\n",
      "Epoch 0072: Loss 0.0001 | AUC 0.8720 | Recall 0.0692 | Precision 0.0692 | AP 0.3429 | F1 0.0692 | Time 0.51\n",
      "Epoch 0073: Loss 0.0001 | AUC 0.8026 | Recall 0.0566 | Precision 0.0566 | AP 0.2564 | F1 0.0590 | Time 0.48\n",
      "Epoch 0074: Loss 0.0001 | AUC 0.8778 | Recall 0.0818 | Precision 0.0818 | AP 0.3445 | F1 0.0828 | Time 0.49\n",
      "Epoch 0075: Loss 0.0001 | AUC 0.6855 | Recall 0.0000 | Precision 0.0000 | AP 0.1627 | F1 0.0000 | Time 0.47\n",
      "Epoch 0076: Loss 0.0001 | AUC 0.6724 | Recall 0.0189 | Precision 0.0189 | AP 0.1717 | F1 0.0211 | Time 0.50\n",
      "Epoch 0077: Loss 0.0001 | AUC 0.4003 | Recall 0.0000 | Precision 0.0000 | AP 0.1022 | F1 0.0000 | Time 0.52\n",
      "Epoch 0078: Loss 0.0001 | AUC 0.7463 | Recall 0.0314 | Precision 0.0314 | AP 0.2025 | F1 0.0388 | Time 0.51\n",
      "Epoch 0079: Loss 0.0001 | AUC 0.9290 | Recall 0.5220 | Precision 0.5220 | AP 0.5325 | F1 0.1459 | Time 0.60\n",
      "Epoch 0080: Loss 0.0001 | AUC 0.8463 | Recall 0.0440 | Precision 0.0440 | AP 0.3071 | F1 0.0194 | Time 0.73\n",
      "Epoch 0081: Loss 0.0001 | AUC 0.5840 | Recall 0.0189 | Precision 0.0189 | AP 0.1401 | F1 0.0228 | Time 0.86\n",
      "Epoch 0082: Loss 0.0001 | AUC 0.0430 | Recall 0.0000 | Precision 0.0000 | AP 0.0635 | F1 0.0000 | Time 0.78\n",
      "Epoch 0083: Loss 0.0001 | AUC 0.0428 | Recall 0.0000 | Precision 0.0000 | AP 0.0660 | F1 0.0000 | Time 0.76\n",
      "Epoch 0084: Loss 0.0001 | AUC 0.0462 | Recall 0.0000 | Precision 0.0000 | AP 0.0677 | F1 0.0000 | Time 0.56\n",
      "Epoch 0085: Loss 0.0001 | AUC 0.0459 | Recall 0.0000 | Precision 0.0000 | AP 0.0677 | F1 0.0000 | Time 0.55\n",
      "Epoch 0086: Loss 0.0001 | AUC 0.0423 | Recall 0.0000 | Precision 0.0000 | AP 0.0640 | F1 0.0000 | Time 0.65\n",
      "Epoch 0087: Loss 0.0001 | AUC 0.0457 | Recall 0.0000 | Precision 0.0000 | AP 0.0684 | F1 0.0000 | Time 0.64\n",
      "Epoch 0088: Loss 0.0001 | AUC 0.0467 | Recall 0.0000 | Precision 0.0000 | AP 0.0690 | F1 0.0000 | Time 0.66\n",
      "Epoch 0089: Loss 0.0001 | AUC 0.0464 | Recall 0.0000 | Precision 0.0000 | AP 0.0675 | F1 0.0000 | Time 0.55\n",
      "Epoch 0090: Loss 0.0001 | AUC 0.0477 | Recall 0.0000 | Precision 0.0000 | AP 0.0698 | F1 0.0000 | Time 0.54\n",
      "Epoch 0091: Loss 0.0001 | AUC 0.0455 | Recall 0.0000 | Precision 0.0000 | AP 0.0706 | F1 0.0000 | Time 0.52\n",
      "Epoch 0092: Loss 0.0001 | AUC 0.0465 | Recall 0.0000 | Precision 0.0000 | AP 0.0706 | F1 0.0000 | Time 0.56\n",
      "Epoch 0093: Loss 0.0001 | AUC 0.0442 | Recall 0.0000 | Precision 0.0000 | AP 0.0675 | F1 0.0000 | Time 0.53\n",
      "Epoch 0094: Loss 0.0001 | AUC 0.0462 | Recall 0.0000 | Precision 0.0000 | AP 0.0698 | F1 0.0000 | Time 0.60\n",
      "Epoch 0095: Loss 0.0001 | AUC 0.0468 | Recall 0.0000 | Precision 0.0000 | AP 0.0684 | F1 0.0000 | Time 0.58\n",
      "Epoch 0096: Loss 0.0001 | AUC 0.0506 | Recall 0.0000 | Precision 0.0000 | AP 0.0696 | F1 0.0000 | Time 0.63\n",
      "Epoch 0097: Loss 0.0001 | AUC 0.0447 | Recall 0.0000 | Precision 0.0000 | AP 0.0682 | F1 0.0000 | Time 0.71\n",
      "Epoch 0098: Loss 0.0001 | AUC 0.0482 | Recall 0.0000 | Precision 0.0000 | AP 0.0698 | F1 0.0000 | Time 0.52\n",
      "Epoch 0099: Loss 0.0001 | AUC 0.0524 | Recall 0.0000 | Precision 0.0000 | AP 0.0730 | F1 0.0000 | Time 0.53\n"
     ]
    }
   ],
   "source": [
    "ocgnn_compile = ocgnn_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0000 | AUC 0.1767 | Recall 0.2550 | Precision 0.2550 | AP 0.3196 | F1 0.2515 | Time 0.50\n"
     ]
    }
   ],
   "source": [
    "ocgnn_ip_pred_res, ocgnn_ip_score_res, ocgnn_ip_prob_res, ocgnn_ip_conf_res = ocgnn_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6179775280898877\n",
      "tensor(0.4714)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "f1_score_ip = eval_f1(label_test_tensor, ocgnn_ip_pred_res)\n",
    "print(f1_score_ip)\n",
    "precision = eval_precision_at_k(label_test_tensor, ocgnn_ip_score_res, k=1606)\n",
    "print(precision)\n",
    "recall = eval_recall_at_k(label_test_tensor, ocgnn_ip_score_res, k=1606)\n",
    "print(recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GUIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_model = GUIDE(num_layers=4, hid_a=16, hid_s=16, weight_decay=0.05,  \n",
    "                    contamination=0.1, lr=0.001, epoch=100, gpu=-1, dropout=0.5,\n",
    "                    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUIDE(act=<function relu at 0x0000027008028AF0>, alpha=0.5, backbone=None,\n",
      "      batch_size=0, cache_dir=None, compile_model=False, contamination=0.1,\n",
      "      dropout=0.5, epoch=100, gpu=None, graphlet_size=4, hid_a=None,\n",
      "      hid_s=None, lr=0.001, num_layers=4, num_neigh=[-1, -1, -1, -1],\n",
      "      save_emb=False, selected_motif=True, verbose=3, weight_decay=0.05)\n"
     ]
    }
   ],
   "source": [
    "print(guide_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\tugas-akhir\\network-intrusion-detection\\trial-error-implementation\\try-1.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/tugas-akhir/network-intrusion-detection/trial-error-implementation/try-1.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m guide_compile \u001b[39m=\u001b[39m guide_model\u001b[39m.\u001b[39;49mfit(pyG_train)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\base.py:432\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, data, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    431\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_dim \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape\n\u001b[1;32m--> 432\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_graph(data)\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    434\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\detector\\guide.py:167\u001b[0m, in \u001b[0;36mGUIDE.process_graph\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_graph\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m--> 167\u001b[0m     data\u001b[39m.\u001b[39ms \u001b[39m=\u001b[39m GUIDEBase\u001b[39m.\u001b[39;49mcalc_gdd(data,\n\u001b[0;32m    168\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_dir,\n\u001b[0;32m    169\u001b[0m                                 graphlet_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraphlet_size,\n\u001b[0;32m    170\u001b[0m                                 selected_motif\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselected_motif)\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim_s \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39ms\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pygod\\nn\\guide.py:182\u001b[0m, in \u001b[0;36mGUIDEBase.calc_gdd\u001b[1;34m(data, cache_dir, graphlet_size, selected_motif)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(new_subset)) \u001b[39m==\u001b[39m i:\n\u001b[0;32m    181\u001b[0m                 new_subset\u001b[39m.\u001b[39msort()\n\u001b[1;32m--> 182\u001b[0m                 unique_subsets[\u001b[39mtuple\u001b[39m(new_subset)] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    183\u001b[0m subsets \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(k) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m unique_subsets\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m    184\u001b[0m edge_subsets[i] \u001b[39m=\u001b[39m subsets\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "guide_compile = guide_model.fit(pyG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.8848 | AUC 1.0000 | Recall 1.0000 | Precision 1.0000 | AP 1.0000 | F1 1.0000 | Time 0.23\n",
      "tensor([0, 1]) tensor([4440, 2583])\n"
     ]
    }
   ],
   "source": [
    "guide_ip_pred_res, guide_ip_score_res, guide_ip_prob_res, guide_ip_conf_res = guide_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(guide_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gae_model = GAE(hid_dim=64, num_layers=128, weight_decay=0.2, dropout=0.5,\n",
    "                contamination=0.1, lr=0.001, epoch=100, gpu=-1,\n",
    "                num_neigh=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 91767.5156 | AUC 0.5823 | Recall 0.1384 | Precision 0.1384 | AP 0.2027 | F1 0.1373 | Time 2.16\n",
      "Epoch 0001: Loss 91765.6406 | AUC 0.5753 | Recall 0.1321 | Precision 0.1321 | AP 0.2022 | F1 0.1321 | Time 1.30\n",
      "Epoch 0002: Loss 91763.5391 | AUC 0.5759 | Recall 0.1384 | Precision 0.1384 | AP 0.2023 | F1 0.1384 | Time 1.49\n",
      "Epoch 0003: Loss 91761.5703 | AUC 0.5730 | Recall 0.1321 | Precision 0.1321 | AP 0.2017 | F1 0.1321 | Time 1.10\n",
      "Epoch 0004: Loss 91757.7578 | AUC 0.5765 | Recall 0.1321 | Precision 0.1321 | AP 0.2023 | F1 0.1321 | Time 1.07\n",
      "Epoch 0005: Loss 91753.4375 | AUC 0.5763 | Recall 0.1321 | Precision 0.1321 | AP 0.2024 | F1 0.1321 | Time 1.06\n",
      "Epoch 0006: Loss 91749.3281 | AUC 0.5790 | Recall 0.1321 | Precision 0.1321 | AP 0.2028 | F1 0.1321 | Time 1.06\n",
      "Epoch 0007: Loss 91743.7109 | AUC 0.5762 | Recall 0.1321 | Precision 0.1321 | AP 0.2023 | F1 0.1321 | Time 1.12\n",
      "Epoch 0008: Loss 91738.3984 | AUC 0.5774 | Recall 0.1384 | Precision 0.1384 | AP 0.2026 | F1 0.1384 | Time 1.21\n",
      "Epoch 0009: Loss 91728.0625 | AUC 0.5817 | Recall 0.1384 | Precision 0.1384 | AP 0.2034 | F1 0.1384 | Time 1.18\n",
      "Epoch 0010: Loss 91718.2812 | AUC 0.5783 | Recall 0.1384 | Precision 0.1384 | AP 0.2027 | F1 0.1384 | Time 1.09\n",
      "Epoch 0011: Loss 91696.1719 | AUC 0.5805 | Recall 0.1384 | Precision 0.1384 | AP 0.2031 | F1 0.1384 | Time 1.23\n",
      "Epoch 0012: Loss 91685.1250 | AUC 0.5766 | Recall 0.1384 | Precision 0.1384 | AP 0.2024 | F1 0.1384 | Time 1.20\n",
      "Epoch 0013: Loss 91668.0703 | AUC 0.5760 | Recall 0.1321 | Precision 0.1321 | AP 0.2021 | F1 0.1321 | Time 0.98\n",
      "Epoch 0014: Loss 91636.4531 | AUC 0.5749 | Recall 0.1384 | Precision 0.1384 | AP 0.2023 | F1 0.1384 | Time 1.07\n",
      "Epoch 0015: Loss 91573.7969 | AUC 0.5738 | Recall 0.1384 | Precision 0.1384 | AP 0.2019 | F1 0.1384 | Time 1.18\n",
      "Epoch 0016: Loss 91524.0938 | AUC 0.5709 | Recall 0.1321 | Precision 0.1321 | AP 0.2015 | F1 0.1321 | Time 1.15\n",
      "Epoch 0017: Loss 91441.3047 | AUC 0.5650 | Recall 0.1321 | Precision 0.1321 | AP 0.2004 | F1 0.1321 | Time 1.19\n",
      "Epoch 0018: Loss 91330.9297 | AUC 0.5552 | Recall 0.1321 | Precision 0.1321 | AP 0.1995 | F1 0.1321 | Time 1.08\n",
      "Epoch 0019: Loss 91064.5234 | AUC 0.5518 | Recall 0.1384 | Precision 0.1384 | AP 0.1982 | F1 0.1384 | Time 1.18\n",
      "Epoch 0020: Loss 90860.0156 | AUC 0.5508 | Recall 0.1321 | Precision 0.1321 | AP 0.1986 | F1 0.1321 | Time 1.36\n",
      "Epoch 0021: Loss 90346.1797 | AUC 0.5063 | Recall 0.1384 | Precision 0.1384 | AP 0.1910 | F1 0.1384 | Time 1.18\n",
      "Epoch 0022: Loss 89814.1172 | AUC 0.5059 | Recall 0.1321 | Precision 0.1321 | AP 0.1924 | F1 0.1321 | Time 1.07\n",
      "Epoch 0023: Loss 88783.5312 | AUC 0.5759 | Recall 0.1384 | Precision 0.1384 | AP 0.2015 | F1 0.1384 | Time 1.15\n",
      "Epoch 0024: Loss 87184.4844 | AUC 0.6267 | Recall 0.1321 | Precision 0.1321 | AP 0.2093 | F1 0.1321 | Time 1.08\n",
      "Epoch 0025: Loss 86562.0547 | AUC 0.7093 | Recall 0.1195 | Precision 0.1195 | AP 0.2299 | F1 0.1195 | Time 1.12\n",
      "Epoch 0026: Loss 86161.4297 | AUC 0.6671 | Recall 0.1195 | Precision 0.1195 | AP 0.2141 | F1 0.1195 | Time 1.06\n",
      "Epoch 0027: Loss 90544.4609 | AUC 0.7149 | Recall 0.3270 | Precision 0.3270 | AP 0.3204 | F1 0.3270 | Time 1.08\n",
      "Epoch 0028: Loss 88046.7500 | AUC 0.6395 | Recall 0.2893 | Precision 0.2893 | AP 0.2409 | F1 0.2893 | Time 1.13\n",
      "Epoch 0029: Loss 86726.6406 | AUC 0.5775 | Recall 0.2201 | Precision 0.2201 | AP 0.2148 | F1 0.2201 | Time 1.11\n",
      "Epoch 0030: Loss 86391.6406 | AUC 0.6909 | Recall 0.1321 | Precision 0.1321 | AP 0.2224 | F1 0.1321 | Time 1.34\n",
      "Epoch 0031: Loss 86415.5781 | AUC 0.7239 | Recall 0.1069 | Precision 0.1069 | AP 0.2302 | F1 0.1069 | Time 1.19\n",
      "Epoch 0032: Loss 87146.8359 | AUC 0.7043 | Recall 0.1195 | Precision 0.1195 | AP 0.2237 | F1 0.1195 | Time 1.24\n",
      "Epoch 0033: Loss 87595.5234 | AUC 0.6711 | Recall 0.1258 | Precision 0.1258 | AP 0.2177 | F1 0.1258 | Time 1.42\n",
      "Epoch 0034: Loss 87733.0469 | AUC 0.6499 | Recall 0.1384 | Precision 0.1384 | AP 0.2157 | F1 0.1384 | Time 1.16\n",
      "Epoch 0035: Loss 87653.8594 | AUC 0.6713 | Recall 0.1195 | Precision 0.1195 | AP 0.2177 | F1 0.1195 | Time 1.29\n",
      "Epoch 0036: Loss 87835.6875 | AUC 0.6472 | Recall 0.1321 | Precision 0.1321 | AP 0.2198 | F1 0.1321 | Time 1.22\n",
      "Epoch 0037: Loss 87575.7188 | AUC 0.6449 | Recall 0.1258 | Precision 0.1258 | AP 0.2177 | F1 0.1258 | Time 1.11\n",
      "Epoch 0038: Loss 87367.7109 | AUC 0.6086 | Recall 0.1195 | Precision 0.1195 | AP 0.2030 | F1 0.1195 | Time 1.17\n",
      "Epoch 0039: Loss 87638.3984 | AUC 0.6439 | Recall 0.1258 | Precision 0.1258 | AP 0.2130 | F1 0.1258 | Time 1.18\n",
      "Epoch 0040: Loss 87474.6484 | AUC 0.6206 | Recall 0.1321 | Precision 0.1321 | AP 0.2107 | F1 0.1321 | Time 1.22\n",
      "Epoch 0041: Loss 85867.7109 | AUC 0.6505 | Recall 0.1321 | Precision 0.1321 | AP 0.2123 | F1 0.1321 | Time 1.16\n",
      "Epoch 0042: Loss 86599.5000 | AUC 0.6808 | Recall 0.1258 | Precision 0.1258 | AP 0.2236 | F1 0.1258 | Time 1.23\n",
      "Epoch 0043: Loss 85788.3984 | AUC 0.6677 | Recall 0.1258 | Precision 0.1258 | AP 0.2176 | F1 0.1258 | Time 1.58\n",
      "Epoch 0044: Loss 85961.9922 | AUC 0.6686 | Recall 0.1447 | Precision 0.1447 | AP 0.2249 | F1 0.1447 | Time 1.80\n",
      "Epoch 0045: Loss 86153.7578 | AUC 0.5502 | Recall 0.1258 | Precision 0.1258 | AP 0.1876 | F1 0.1258 | Time 1.39\n",
      "Epoch 0046: Loss 86227.3906 | AUC 0.7101 | Recall 0.2579 | Precision 0.2579 | AP 0.2789 | F1 0.2579 | Time 1.28\n",
      "Epoch 0047: Loss 86344.2812 | AUC 0.6700 | Recall 0.2201 | Precision 0.2201 | AP 0.2562 | F1 0.2201 | Time 1.27\n",
      "Epoch 0048: Loss 86708.9141 | AUC 0.7050 | Recall 0.2704 | Precision 0.2704 | AP 0.2989 | F1 0.2704 | Time 1.33\n",
      "Epoch 0049: Loss 87337.9219 | AUC 0.6094 | Recall 0.2704 | Precision 0.2704 | AP 0.2487 | F1 0.2704 | Time 2.23\n",
      "Epoch 0050: Loss 85923.0703 | AUC 0.6323 | Recall 0.2138 | Precision 0.2138 | AP 0.2446 | F1 0.2138 | Time 1.40\n",
      "Epoch 0051: Loss 84588.2266 | AUC 0.6700 | Recall 0.2704 | Precision 0.2704 | AP 0.2862 | F1 0.2704 | Time 1.28\n",
      "Epoch 0052: Loss 85968.7969 | AUC 0.6146 | Recall 0.1950 | Precision 0.1950 | AP 0.2317 | F1 0.1950 | Time 1.35\n",
      "Epoch 0053: Loss 86204.1328 | AUC 0.6497 | Recall 0.1572 | Precision 0.1572 | AP 0.2287 | F1 0.1572 | Time 1.38\n",
      "Epoch 0054: Loss 86415.7969 | AUC 0.5442 | Recall 0.1698 | Precision 0.1698 | AP 0.1996 | F1 0.1698 | Time 1.32\n",
      "Epoch 0055: Loss 85997.0938 | AUC 0.5266 | Recall 0.1447 | Precision 0.1447 | AP 0.1915 | F1 0.1447 | Time 1.15\n",
      "Epoch 0056: Loss 85968.2969 | AUC 0.7141 | Recall 0.1195 | Precision 0.1195 | AP 0.2248 | F1 0.1195 | Time 1.21\n",
      "Epoch 0057: Loss 86577.6250 | AUC 0.6888 | Recall 0.1321 | Precision 0.1321 | AP 0.2207 | F1 0.1321 | Time 1.10\n",
      "Epoch 0058: Loss 86425.6875 | AUC 0.5695 | Recall 0.1447 | Precision 0.1447 | AP 0.1979 | F1 0.1447 | Time 1.08\n",
      "Epoch 0059: Loss 86680.5547 | AUC 0.7121 | Recall 0.1258 | Precision 0.1258 | AP 0.2220 | F1 0.1258 | Time 1.08\n",
      "Epoch 0060: Loss 86226.8203 | AUC 0.6853 | Recall 0.1195 | Precision 0.1195 | AP 0.2251 | F1 0.1195 | Time 1.26\n",
      "Epoch 0061: Loss 86401.2266 | AUC 0.5531 | Recall 0.1132 | Precision 0.1132 | AP 0.1863 | F1 0.1132 | Time 1.18\n",
      "Epoch 0062: Loss 86092.9062 | AUC 0.5632 | Recall 0.1258 | Precision 0.1258 | AP 0.1919 | F1 0.1258 | Time 1.11\n",
      "Epoch 0063: Loss 86435.9688 | AUC 0.7033 | Recall 0.1195 | Precision 0.1195 | AP 0.2315 | F1 0.1195 | Time 1.29\n",
      "Epoch 0064: Loss 86155.1797 | AUC 0.5754 | Recall 0.1321 | Precision 0.1321 | AP 0.1922 | F1 0.1321 | Time 1.09\n",
      "Epoch 0065: Loss 85965.0469 | AUC 0.6439 | Recall 0.1635 | Precision 0.1635 | AP 0.2151 | F1 0.1635 | Time 1.08\n",
      "Epoch 0066: Loss 86275.0156 | AUC 0.6648 | Recall 0.1698 | Precision 0.1698 | AP 0.2413 | F1 0.1698 | Time 1.12\n",
      "Epoch 0067: Loss 86483.1406 | AUC 0.6289 | Recall 0.1635 | Precision 0.1635 | AP 0.2223 | F1 0.1635 | Time 1.10\n",
      "Epoch 0068: Loss 85821.7656 | AUC 0.5800 | Recall 0.1384 | Precision 0.1384 | AP 0.1978 | F1 0.1384 | Time 1.08\n",
      "Epoch 0069: Loss 86080.3672 | AUC 0.6464 | Recall 0.1635 | Precision 0.1635 | AP 0.2236 | F1 0.1635 | Time 1.14\n",
      "Epoch 0070: Loss 86829.1875 | AUC 0.5649 | Recall 0.2138 | Precision 0.2138 | AP 0.2249 | F1 0.2138 | Time 1.08\n",
      "Epoch 0071: Loss 86306.3672 | AUC 0.5819 | Recall 0.1321 | Precision 0.1321 | AP 0.2022 | F1 0.1321 | Time 1.07\n",
      "Epoch 0072: Loss 85897.9141 | AUC 0.7299 | Recall 0.1258 | Precision 0.1258 | AP 0.2332 | F1 0.1258 | Time 1.10\n",
      "Epoch 0073: Loss 86496.9141 | AUC 0.5050 | Recall 0.1447 | Precision 0.1447 | AP 0.1800 | F1 0.1447 | Time 1.22\n",
      "Epoch 0074: Loss 86583.8359 | AUC 0.5309 | Recall 0.1572 | Precision 0.1572 | AP 0.1927 | F1 0.1572 | Time 1.23\n",
      "Epoch 0075: Loss 86560.6562 | AUC 0.6644 | Recall 0.1321 | Precision 0.1321 | AP 0.2106 | F1 0.1321 | Time 1.24\n",
      "Epoch 0076: Loss 86060.1875 | AUC 0.6249 | Recall 0.1195 | Precision 0.1195 | AP 0.2038 | F1 0.1195 | Time 1.25\n",
      "Epoch 0077: Loss 85695.2969 | AUC 0.6732 | Recall 0.1195 | Precision 0.1195 | AP 0.2201 | F1 0.1195 | Time 1.23\n",
      "Epoch 0078: Loss 86167.2266 | AUC 0.5663 | Recall 0.1447 | Precision 0.1447 | AP 0.1975 | F1 0.1447 | Time 1.23\n",
      "Epoch 0079: Loss 85650.8828 | AUC 0.5683 | Recall 0.1321 | Precision 0.1321 | AP 0.1988 | F1 0.1321 | Time 1.23\n",
      "Epoch 0080: Loss 86249.7188 | AUC 0.6823 | Recall 0.1384 | Precision 0.1384 | AP 0.2312 | F1 0.1384 | Time 1.29\n",
      "Epoch 0081: Loss 85850.7109 | AUC 0.5092 | Recall 0.1635 | Precision 0.1635 | AP 0.1978 | F1 0.1635 | Time 1.37\n",
      "Epoch 0082: Loss 86144.0078 | AUC 0.6692 | Recall 0.1195 | Precision 0.1195 | AP 0.2143 | F1 0.1195 | Time 1.55\n",
      "Epoch 0083: Loss 86233.0312 | AUC 0.5562 | Recall 0.1321 | Precision 0.1321 | AP 0.1912 | F1 0.1321 | Time 1.29\n",
      "Epoch 0084: Loss 85564.6719 | AUC 0.7017 | Recall 0.1321 | Precision 0.1321 | AP 0.2271 | F1 0.1321 | Time 1.27\n",
      "Epoch 0085: Loss 85242.6016 | AUC 0.7039 | Recall 0.1698 | Precision 0.1698 | AP 0.2410 | F1 0.1698 | Time 1.30\n",
      "Epoch 0086: Loss 84819.7109 | AUC 0.6904 | Recall 0.1195 | Precision 0.1195 | AP 0.2321 | F1 0.1195 | Time 1.34\n",
      "Epoch 0087: Loss 86945.1953 | AUC 0.5513 | Recall 0.2138 | Precision 0.2138 | AP 0.2260 | F1 0.2138 | Time 1.32\n",
      "Epoch 0088: Loss 85826.3672 | AUC 0.7146 | Recall 0.2390 | Precision 0.2390 | AP 0.2827 | F1 0.2390 | Time 1.35\n",
      "Epoch 0089: Loss 85869.3750 | AUC 0.7096 | Recall 0.1384 | Precision 0.1384 | AP 0.2388 | F1 0.1384 | Time 1.32\n",
      "Epoch 0090: Loss 85924.8047 | AUC 0.6873 | Recall 0.1887 | Precision 0.1887 | AP 0.2426 | F1 0.1887 | Time 1.35\n",
      "Epoch 0091: Loss 85809.5547 | AUC 0.6682 | Recall 0.1950 | Precision 0.1950 | AP 0.2410 | F1 0.1950 | Time 1.47\n",
      "Epoch 0092: Loss 85693.7266 | AUC 0.6499 | Recall 0.1258 | Precision 0.1258 | AP 0.2152 | F1 0.1258 | Time 1.56\n",
      "Epoch 0093: Loss 86369.7344 | AUC 0.6197 | Recall 0.1572 | Precision 0.1572 | AP 0.2129 | F1 0.1572 | Time 1.36\n",
      "Epoch 0094: Loss 85338.3672 | AUC 0.6589 | Recall 0.1698 | Precision 0.1698 | AP 0.2344 | F1 0.1698 | Time 1.39\n",
      "Epoch 0095: Loss 86346.2891 | AUC 0.5829 | Recall 0.1321 | Precision 0.1321 | AP 0.1922 | F1 0.1321 | Time 1.44\n",
      "Epoch 0096: Loss 85602.9844 | AUC 0.6534 | Recall 0.1258 | Precision 0.1258 | AP 0.2166 | F1 0.1258 | Time 1.43\n",
      "Epoch 0097: Loss 84554.2109 | AUC 0.7071 | Recall 0.1509 | Precision 0.1509 | AP 0.2389 | F1 0.1509 | Time 1.47\n",
      "Epoch 0098: Loss 86961.1016 | AUC 0.6248 | Recall 0.1447 | Precision 0.1447 | AP 0.2114 | F1 0.1447 | Time 1.38\n",
      "Epoch 0099: Loss 86199.0625 | AUC 0.6893 | Recall 0.1761 | Precision 0.1761 | AP 0.2535 | F1 0.1761 | Time 1.35\n"
     ]
    }
   ],
   "source": [
    "gae_compile = gae_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 110.0177 | AUC 0.6630 | Recall 0.6420 | Precision 0.6420 | AP 0.5840 | F1 0.6420 | Time 0.58\n",
      "tensor([0, 1]) tensor([1336,  270])\n"
     ]
    }
   ],
   "source": [
    "gae_ip_pred_res, gae_ip_score_res, gae_ip_prob_res, gae_ip_conf_res = gae_compile.predict(data=pyG_test, label=label_test_tensor, return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(gae_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaan_model = GAAN(noise_dim=8, hid_dim=8, num_layers=8, dropout=0.0, \n",
    "                  weight_decay=0.02, contamination=0.1, lr=0.004, \n",
    "                  epoch=100, gpu=-1, batch_size=0, num_neigh=0, \n",
    "                  weight=0.5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 2.25\n",
      "Epoch 0001: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 1.85\n",
      "Epoch 0002: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8412 | F1 0.7858 | Time 1.86\n",
      "Epoch 0003: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 1.89\n",
      "Epoch 0004: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7859 | Precision 0.7859 | AP 0.8411 | F1 0.7859 | Time 1.93\n",
      "Epoch 0005: Loss G nan | Loss D nan | AUC 0.5809 | Recall 0.7863 | Precision 0.7863 | AP 0.8411 | F1 0.7863 | Time 2.04\n",
      "Epoch 0006: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.98\n",
      "Epoch 0007: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.84\n",
      "Epoch 0008: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.81\n",
      "Epoch 0009: Loss G nan | Loss D nan | AUC 0.5810 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.74\n",
      "Epoch 0010: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7863 | Time 1.80\n",
      "Epoch 0011: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8410 | F1 0.7859 | Time 1.98\n",
      "Epoch 0012: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 1.89\n",
      "Epoch 0013: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.83\n",
      "Epoch 0014: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8413 | F1 0.7856 | Time 2.20\n",
      "Epoch 0015: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 2.08\n",
      "Epoch 0016: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.03\n",
      "Epoch 0017: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.83\n",
      "Epoch 0018: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 1.79\n",
      "Epoch 0019: Loss G nan | Loss D nan | AUC 0.5809 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.86\n",
      "Epoch 0020: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.79\n",
      "Epoch 0021: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.91\n",
      "Epoch 0022: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7852 | Precision 0.7852 | AP 0.8411 | F1 0.7852 | Time 1.96\n",
      "Epoch 0023: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7856 | Precision 0.7856 | AP 0.8412 | F1 0.7856 | Time 1.84\n",
      "Epoch 0024: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7861 | Precision 0.7861 | AP 0.8410 | F1 0.7861 | Time 1.80\n",
      "Epoch 0025: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7854 | Precision 0.7854 | AP 0.8412 | F1 0.7854 | Time 1.79\n",
      "Epoch 0026: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8414 | F1 0.7861 | Time 1.91\n",
      "Epoch 0027: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7856 | Precision 0.7856 | AP 0.8412 | F1 0.7856 | Time 2.05\n",
      "Epoch 0028: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 1.84\n",
      "Epoch 0029: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7854 | Precision 0.7854 | AP 0.8411 | F1 0.7854 | Time 1.96\n",
      "Epoch 0030: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 1.84\n",
      "Epoch 0031: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.87\n",
      "Epoch 0032: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7861 | Time 1.87\n",
      "Epoch 0033: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.04\n",
      "Epoch 0034: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.91\n",
      "Epoch 0035: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 1.94\n",
      "Epoch 0036: Loss G nan | Loss D nan | AUC 0.5808 | Recall 0.7863 | Precision 0.7863 | AP 0.8414 | F1 0.7863 | Time 1.90\n",
      "Epoch 0037: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.86\n",
      "Epoch 0038: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 2.17\n",
      "Epoch 0039: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 2.31\n",
      "Epoch 0040: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 2.10\n",
      "Epoch 0041: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.02\n",
      "Epoch 0042: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.86\n",
      "Epoch 0043: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8413 | F1 0.7863 | Time 2.40\n",
      "Epoch 0044: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.25\n",
      "Epoch 0045: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.17\n",
      "Epoch 0046: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7863 | Precision 0.7863 | AP 0.8413 | F1 0.7863 | Time 2.05\n",
      "Epoch 0047: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 1.93\n",
      "Epoch 0048: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 1.87\n",
      "Epoch 0049: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 2.04\n",
      "Epoch 0050: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.27\n",
      "Epoch 0051: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7858 | Precision 0.7858 | AP 0.8411 | F1 0.7858 | Time 2.25\n",
      "Epoch 0052: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7861 | Time 2.05\n",
      "Epoch 0053: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8411 | F1 0.7863 | Time 1.87\n",
      "Epoch 0054: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8410 | F1 0.7859 | Time 1.82\n",
      "Epoch 0055: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7849 | Precision 0.7849 | AP 0.8412 | F1 0.7849 | Time 1.86\n",
      "Epoch 0056: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.91\n",
      "Epoch 0057: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7863 | Time 1.86\n",
      "Epoch 0058: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.86\n",
      "Epoch 0059: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8409 | F1 0.7863 | Time 1.78\n",
      "Epoch 0060: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 1.84\n",
      "Epoch 0061: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7859 | Precision 0.7859 | AP 0.8413 | F1 0.7859 | Time 2.00\n",
      "Epoch 0062: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7858 | Precision 0.7858 | AP 0.8410 | F1 0.7858 | Time 1.98\n",
      "Epoch 0063: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7859 | Time 1.93\n",
      "Epoch 0064: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7861 | Precision 0.7861 | AP 0.8410 | F1 0.7861 | Time 1.93\n",
      "Epoch 0065: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 1.94\n",
      "Epoch 0066: Loss G nan | Loss D nan | AUC 0.5806 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 2.21\n",
      "Epoch 0067: Loss G nan | Loss D nan | AUC 0.5799 | Recall 0.7859 | Precision 0.7859 | AP 0.8408 | F1 0.7859 | Time 1.80\n",
      "Epoch 0068: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7864 | Time 1.82\n",
      "Epoch 0069: Loss G nan | Loss D nan | AUC 0.5800 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.83\n",
      "Epoch 0070: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7863 | Time 1.83\n",
      "Epoch 0071: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8413 | F1 0.7864 | Time 1.80\n",
      "Epoch 0072: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7861 | Precision 0.7861 | AP 0.8409 | F1 0.7861 | Time 1.90\n",
      "Epoch 0073: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7866 | Time 1.86\n",
      "Epoch 0074: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7864 | Precision 0.7864 | AP 0.8409 | F1 0.7864 | Time 1.91\n",
      "Epoch 0075: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7864 | Precision 0.7864 | AP 0.8414 | F1 0.7864 | Time 1.91\n",
      "Epoch 0076: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7864 | Precision 0.7864 | AP 0.8412 | F1 0.7864 | Time 2.03\n",
      "Epoch 0077: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7860 | Time 2.14\n",
      "Epoch 0078: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7864 | Precision 0.7864 | AP 0.8411 | F1 0.7865 | Time 2.16\n",
      "Epoch 0079: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7864 | Precision 0.7864 | AP 0.8410 | F1 0.7863 | Time 2.60\n",
      "Epoch 0080: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7858 | Precision 0.7858 | AP 0.8413 | F1 0.7858 | Time 2.07\n",
      "Epoch 0081: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7854 | Precision 0.7854 | AP 0.8409 | F1 0.7853 | Time 1.96\n",
      "Epoch 0082: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7860 | Time 2.21\n",
      "Epoch 0083: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7861 | Precision 0.7861 | AP 0.8413 | F1 0.7861 | Time 1.89\n",
      "Epoch 0084: Loss G nan | Loss D nan | AUC 0.5807 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7865 | Time 1.87\n",
      "Epoch 0085: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 1.93\n",
      "Epoch 0086: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7858 | Precision 0.7858 | AP 0.8412 | F1 0.7856 | Time 1.99\n",
      "Epoch 0087: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7856 | Precision 0.7856 | AP 0.8410 | F1 0.7856 | Time 2.52\n",
      "Epoch 0088: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7858 | Precision 0.7858 | AP 0.8410 | F1 0.7856 | Time 2.77\n",
      "Epoch 0089: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7863 | Precision 0.7863 | AP 0.8410 | F1 0.7862 | Time 2.03\n",
      "Epoch 0090: Loss G nan | Loss D nan | AUC 0.5804 | Recall 0.7859 | Precision 0.7859 | AP 0.8412 | F1 0.7858 | Time 2.05\n",
      "Epoch 0091: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7852 | Precision 0.7852 | AP 0.8413 | F1 0.7852 | Time 1.90\n",
      "Epoch 0092: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7863 | Precision 0.7863 | AP 0.8412 | F1 0.7860 | Time 1.87\n",
      "Epoch 0093: Loss G nan | Loss D nan | AUC 0.5802 | Recall 0.7854 | Precision 0.7854 | AP 0.8411 | F1 0.7854 | Time 1.92\n",
      "Epoch 0094: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7866 | Precision 0.7866 | AP 0.8412 | F1 0.7865 | Time 2.10\n",
      "Epoch 0095: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7854 | Precision 0.7854 | AP 0.8412 | F1 0.7853 | Time 2.57\n",
      "Epoch 0096: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7852 | Precision 0.7852 | AP 0.8410 | F1 0.7851 | Time 2.07\n",
      "Epoch 0097: Loss G nan | Loss D nan | AUC 0.5801 | Recall 0.7852 | Precision 0.7852 | AP 0.8409 | F1 0.7852 | Time 2.04\n",
      "Epoch 0098: Loss G nan | Loss D nan | AUC 0.5803 | Recall 0.7861 | Precision 0.7861 | AP 0.8412 | F1 0.7860 | Time 1.92\n",
      "Epoch 0099: Loss G nan | Loss D nan | AUC 0.5805 | Recall 0.7856 | Precision 0.7856 | AP 0.8411 | F1 0.7856 | Time 1.91\n"
     ]
    }
   ],
   "source": [
    "gaan_compile = gaan_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss nan | AUC 0.5099 | Recall 0.7938 | Precision 0.7938 | AP 0.8103 | F1 0.7938 | Time 0.48\n",
      "tensor([0, 1]) tensor([3358,  487])\n"
     ]
    }
   ],
   "source": [
    "gaan_ip_pred_res, gaan_ip_score_res, gaan_ip_prob_res, gaan_ip_conf_res = gaan_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(gaan_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "conad_mode = CONAD(hid_dim=64, num_layers=64, dropout=0.0, weight_decay=0.0, contamination=0.1, lr=0.001, \n",
    "      epoch=100, gpu=-1, num_neigh=-1, weight=0.5, eta=0.5, margin=0.5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 20.2718 | AUC 0.5831 | Recall 0.1321 | Precision 0.1321 | AP 0.2030 | F1 0.1321 | Time 2.85\n",
      "Epoch 0001: Loss 20.2727 | AUC 0.5742 | Recall 0.1321 | Precision 0.1321 | AP 0.2024 | F1 0.1321 | Time 1.89\n",
      "Epoch 0002: Loss 20.2658 | AUC 0.5838 | Recall 0.1321 | Precision 0.1321 | AP 0.2037 | F1 0.1321 | Time 1.91\n",
      "Epoch 0003: Loss 20.2611 | AUC 0.5839 | Recall 0.1321 | Precision 0.1321 | AP 0.2038 | F1 0.1321 | Time 1.78\n",
      "Epoch 0004: Loss 20.2569 | AUC 0.5921 | Recall 0.1321 | Precision 0.1321 | AP 0.2052 | F1 0.1321 | Time 1.63\n",
      "Epoch 0005: Loss 20.2510 | AUC 0.5855 | Recall 0.1321 | Precision 0.1321 | AP 0.2040 | F1 0.1321 | Time 1.64\n",
      "Epoch 0006: Loss 20.2494 | AUC 0.5838 | Recall 0.1321 | Precision 0.1321 | AP 0.2036 | F1 0.1321 | Time 1.59\n",
      "Epoch 0007: Loss 20.2440 | AUC 0.5838 | Recall 0.1321 | Precision 0.1321 | AP 0.2035 | F1 0.1321 | Time 1.38\n",
      "Epoch 0008: Loss 20.2330 | AUC 0.5836 | Recall 0.1321 | Precision 0.1321 | AP 0.2033 | F1 0.1321 | Time 1.46\n",
      "Epoch 0009: Loss 20.2191 | AUC 0.5834 | Recall 0.1321 | Precision 0.1321 | AP 0.2033 | F1 0.1321 | Time 1.54\n",
      "Epoch 0010: Loss 20.2100 | AUC 0.5835 | Recall 0.1321 | Precision 0.1321 | AP 0.2033 | F1 0.1321 | Time 1.66\n",
      "Epoch 0011: Loss 20.1915 | AUC 0.5834 | Recall 0.1321 | Precision 0.1321 | AP 0.2033 | F1 0.1321 | Time 1.52\n",
      "Epoch 0012: Loss 20.1627 | AUC 0.5766 | Recall 0.1321 | Precision 0.1321 | AP 0.2021 | F1 0.1321 | Time 1.47\n",
      "Epoch 0013: Loss 20.1139 | AUC 0.5741 | Recall 0.1321 | Precision 0.1321 | AP 0.2017 | F1 0.1325 | Time 1.32\n",
      "Epoch 0014: Loss 20.0340 | AUC 0.5713 | Recall 0.1321 | Precision 0.1321 | AP 0.2012 | F1 0.1325 | Time 1.28\n",
      "Epoch 0015: Loss 19.8710 | AUC 0.5581 | Recall 0.1321 | Precision 0.1321 | AP 0.1991 | F1 0.1325 | Time 1.53\n",
      "Epoch 0016: Loss 19.5148 | AUC 0.5094 | Recall 0.1321 | Precision 0.1321 | AP 0.1921 | F1 0.1321 | Time 1.70\n",
      "Epoch 0017: Loss 18.6642 | AUC 0.4258 | Recall 0.1321 | Precision 0.1321 | AP 0.1794 | F1 0.1321 | Time 1.69\n",
      "Epoch 0018: Loss 16.9103 | AUC 0.5415 | Recall 0.1258 | Precision 0.1258 | AP 0.1968 | F1 0.1262 | Time 1.38\n",
      "Epoch 0019: Loss 14.7162 | AUC 0.8462 | Recall 0.3082 | Precision 0.3082 | AP 0.4221 | F1 0.3082 | Time 1.52\n",
      "Epoch 0020: Loss 15.9801 | AUC 0.8455 | Recall 0.4025 | Precision 0.4025 | AP 0.4854 | F1 0.4025 | Time 1.47\n",
      "Epoch 0021: Loss 14.6539 | AUC 0.7926 | Recall 0.1509 | Precision 0.1509 | AP 0.2858 | F1 0.1509 | Time 1.78\n",
      "Epoch 0022: Loss 15.4895 | AUC 0.6736 | Recall 0.1132 | Precision 0.1132 | AP 0.2242 | F1 0.1139 | Time 1.94\n",
      "Epoch 0023: Loss 15.4938 | AUC 0.6646 | Recall 0.1195 | Precision 0.1195 | AP 0.2209 | F1 0.1199 | Time 1.61\n",
      "Epoch 0024: Loss 14.7744 | AUC 0.7566 | Recall 0.1069 | Precision 0.1069 | AP 0.2534 | F1 0.1069 | Time 1.78\n",
      "Epoch 0025: Loss 14.4126 | AUC 0.8384 | Recall 0.2642 | Precision 0.2642 | AP 0.3540 | F1 0.2642 | Time 1.69\n",
      "Epoch 0026: Loss 15.2682 | AUC 0.8392 | Recall 0.3459 | Precision 0.3459 | AP 0.4309 | F1 0.3470 | Time 2.06\n",
      "Epoch 0027: Loss 14.3891 | AUC 0.8374 | Recall 0.2264 | Precision 0.2264 | AP 0.3381 | F1 0.2271 | Time 1.85\n",
      "Epoch 0028: Loss 14.3615 | AUC 0.7815 | Recall 0.1069 | Precision 0.1069 | AP 0.2638 | F1 0.1069 | Time 1.45\n",
      "Epoch 0029: Loss 14.6594 | AUC 0.7337 | Recall 0.1195 | Precision 0.1195 | AP 0.2408 | F1 0.1199 | Time 2.60\n",
      "Epoch 0030: Loss 14.5805 | AUC 0.7341 | Recall 0.1195 | Precision 0.1195 | AP 0.2410 | F1 0.1203 | Time 2.34\n",
      "Epoch 0031: Loss 14.2239 | AUC 0.7701 | Recall 0.1132 | Precision 0.1132 | AP 0.2603 | F1 0.1132 | Time 2.10\n",
      "Epoch 0032: Loss 14.0951 | AUC 0.8203 | Recall 0.1195 | Precision 0.1195 | AP 0.2813 | F1 0.1195 | Time 3.03\n",
      "Epoch 0033: Loss 14.3518 | AUC 0.8234 | Recall 0.1384 | Precision 0.1384 | AP 0.2926 | F1 0.1384 | Time 2.23\n",
      "Epoch 0034: Loss 14.2138 | AUC 0.8194 | Recall 0.1258 | Precision 0.1258 | AP 0.2830 | F1 0.1258 | Time 1.65\n",
      "Epoch 0035: Loss 13.9673 | AUC 0.8056 | Recall 0.1195 | Precision 0.1195 | AP 0.2750 | F1 0.1195 | Time 1.55\n",
      "Epoch 0036: Loss 14.0237 | AUC 0.7820 | Recall 0.1258 | Precision 0.1258 | AP 0.2613 | F1 0.1262 | Time 1.68\n",
      "Epoch 0037: Loss 14.0919 | AUC 0.7553 | Recall 0.1258 | Precision 0.1258 | AP 0.2510 | F1 0.1258 | Time 1.57\n",
      "Epoch 0038: Loss 14.0201 | AUC 0.7665 | Recall 0.1258 | Precision 0.1258 | AP 0.2548 | F1 0.1258 | Time 1.35\n",
      "Epoch 0039: Loss 13.8857 | AUC 0.7919 | Recall 0.1258 | Precision 0.1258 | AP 0.2668 | F1 0.1258 | Time 1.34\n",
      "Epoch 0040: Loss 13.8902 | AUC 0.8064 | Recall 0.1258 | Precision 0.1258 | AP 0.2742 | F1 0.1258 | Time 1.38\n",
      "Epoch 0041: Loss 13.9710 | AUC 0.8072 | Recall 0.1258 | Precision 0.1258 | AP 0.2748 | F1 0.1258 | Time 1.38\n",
      "Epoch 0042: Loss 13.9342 | AUC 0.8015 | Recall 0.1258 | Precision 0.1258 | AP 0.2730 | F1 0.1258 | Time 1.40\n",
      "Epoch 0043: Loss 13.8363 | AUC 0.7951 | Recall 0.1258 | Precision 0.1258 | AP 0.2697 | F1 0.1258 | Time 1.61\n",
      "Epoch 0044: Loss 13.8359 | AUC 0.7882 | Recall 0.1321 | Precision 0.1321 | AP 0.2636 | F1 0.1329 | Time 2.42\n",
      "Epoch 0045: Loss 13.8844 | AUC 0.7670 | Recall 0.1321 | Precision 0.1321 | AP 0.2561 | F1 0.1325 | Time 2.23\n",
      "Epoch 0046: Loss 13.8787 | AUC 0.7648 | Recall 0.1321 | Precision 0.1321 | AP 0.2550 | F1 0.1329 | Time 1.90\n",
      "Epoch 0047: Loss 13.8232 | AUC 0.7791 | Recall 0.1321 | Precision 0.1321 | AP 0.2614 | F1 0.1329 | Time 1.82\n",
      "Epoch 0048: Loss 13.7958 | AUC 0.7911 | Recall 0.1321 | Precision 0.1321 | AP 0.2677 | F1 0.1321 | Time 1.41\n",
      "Epoch 0049: Loss 13.8347 | AUC 0.7915 | Recall 0.1321 | Precision 0.1321 | AP 0.2691 | F1 0.1321 | Time 1.65\n",
      "Epoch 0050: Loss 13.8469 | AUC 0.7904 | Recall 0.1321 | Precision 0.1321 | AP 0.2691 | F1 0.1321 | Time 1.63\n",
      "Epoch 0051: Loss 13.8086 | AUC 0.7916 | Recall 0.1321 | Precision 0.1321 | AP 0.2689 | F1 0.1321 | Time 1.50\n",
      "Epoch 0052: Loss 13.7899 | AUC 0.7881 | Recall 0.1321 | Precision 0.1321 | AP 0.2659 | F1 0.1321 | Time 1.48\n",
      "Epoch 0053: Loss 13.8057 | AUC 0.7727 | Recall 0.1321 | Precision 0.1321 | AP 0.2594 | F1 0.1329 | Time 1.58\n",
      "Epoch 0054: Loss 13.8223 | AUC 0.7646 | Recall 0.1321 | Precision 0.1321 | AP 0.2557 | F1 0.1325 | Time 1.79\n",
      "Epoch 0055: Loss 13.8059 | AUC 0.7688 | Recall 0.1321 | Precision 0.1321 | AP 0.2576 | F1 0.1329 | Time 1.88\n",
      "Epoch 0056: Loss 13.7809 | AUC 0.7827 | Recall 0.1321 | Precision 0.1321 | AP 0.2642 | F1 0.1321 | Time 2.06\n",
      "Epoch 0057: Loss 13.7909 | AUC 0.7875 | Recall 0.1321 | Precision 0.1321 | AP 0.2667 | F1 0.1321 | Time 1.90\n",
      "Epoch 0058: Loss 13.8059 | AUC 0.7882 | Recall 0.1321 | Precision 0.1321 | AP 0.2672 | F1 0.1321 | Time 2.60\n",
      "Epoch 0059: Loss 13.7929 | AUC 0.7866 | Recall 0.1321 | Precision 0.1321 | AP 0.2667 | F1 0.1321 | Time 2.11\n",
      "Epoch 0060: Loss 13.7770 | AUC 0.7828 | Recall 0.1321 | Precision 0.1321 | AP 0.2645 | F1 0.1321 | Time 2.04\n",
      "Epoch 0061: Loss 13.7841 | AUC 0.7727 | Recall 0.1321 | Precision 0.1321 | AP 0.2594 | F1 0.1321 | Time 1.72\n",
      "Epoch 0062: Loss 13.7882 | AUC 0.7642 | Recall 0.1321 | Precision 0.1321 | AP 0.2556 | F1 0.1321 | Time 2.18\n",
      "Epoch 0063: Loss 13.7833 | AUC 0.7651 | Recall 0.1321 | Precision 0.1321 | AP 0.2561 | F1 0.1329 | Time 1.48\n",
      "Epoch 0064: Loss 13.7739 | AUC 0.7709 | Recall 0.1321 | Precision 0.1321 | AP 0.2588 | F1 0.1321 | Time 1.56\n",
      "Epoch 0065: Loss 13.7744 | AUC 0.7773 | Recall 0.1321 | Precision 0.1321 | AP 0.2621 | F1 0.1321 | Time 1.45\n",
      "Epoch 0066: Loss 13.7799 | AUC 0.7802 | Recall 0.1321 | Precision 0.1321 | AP 0.2637 | F1 0.1321 | Time 1.40\n",
      "Epoch 0067: Loss 13.7763 | AUC 0.7791 | Recall 0.1321 | Precision 0.1321 | AP 0.2632 | F1 0.1321 | Time 1.45\n",
      "Epoch 0068: Loss 13.7731 | AUC 0.7756 | Recall 0.1321 | Precision 0.1321 | AP 0.2612 | F1 0.1321 | Time 1.49\n",
      "Epoch 0069: Loss 13.7765 | AUC 0.7684 | Recall 0.1321 | Precision 0.1321 | AP 0.2577 | F1 0.1321 | Time 1.31\n",
      "Epoch 0070: Loss 13.7701 | AUC 0.7625 | Recall 0.1321 | Precision 0.1321 | AP 0.2549 | F1 0.1321 | Time 1.42\n",
      "Epoch 0071: Loss 13.7940 | AUC 0.7627 | Recall 0.1321 | Precision 0.1321 | AP 0.2550 | F1 0.1325 | Time 1.39\n",
      "Epoch 0072: Loss 13.7844 | AUC 0.7648 | Recall 0.1321 | Precision 0.1321 | AP 0.2560 | F1 0.1321 | Time 1.38\n",
      "Epoch 0073: Loss 13.7979 | AUC 0.7680 | Recall 0.1321 | Precision 0.1321 | AP 0.2579 | F1 0.1321 | Time 1.68\n",
      "Epoch 0074: Loss 13.8089 | AUC 0.7688 | Recall 0.1321 | Precision 0.1321 | AP 0.2583 | F1 0.1321 | Time 1.90\n",
      "Epoch 0075: Loss 13.8051 | AUC 0.7680 | Recall 0.1321 | Precision 0.1321 | AP 0.2580 | F1 0.1321 | Time 1.77\n",
      "Epoch 0076: Loss 13.8074 | AUC 0.7653 | Recall 0.1321 | Precision 0.1321 | AP 0.2568 | F1 0.1321 | Time 1.65\n",
      "Epoch 0077: Loss 13.8005 | AUC 0.7605 | Recall 0.1321 | Precision 0.1321 | AP 0.2546 | F1 0.1321 | Time 1.80\n",
      "Epoch 0078: Loss 13.7951 | AUC 0.7542 | Recall 0.1321 | Precision 0.1321 | AP 0.2515 | F1 0.1321 | Time 1.60\n",
      "Epoch 0079: Loss 13.7922 | AUC 0.7511 | Recall 0.1321 | Precision 0.1321 | AP 0.2501 | F1 0.1321 | Time 1.77\n",
      "Epoch 0080: Loss 13.7873 | AUC 0.7533 | Recall 0.1321 | Precision 0.1321 | AP 0.2509 | F1 0.1321 | Time 1.74\n",
      "Epoch 0081: Loss 13.7850 | AUC 0.7580 | Recall 0.1321 | Precision 0.1321 | AP 0.2532 | F1 0.1321 | Time 1.53\n",
      "Epoch 0082: Loss 13.7867 | AUC 0.7608 | Recall 0.1321 | Precision 0.1321 | AP 0.2545 | F1 0.1321 | Time 1.43\n",
      "Epoch 0083: Loss 13.7866 | AUC 0.7608 | Recall 0.1321 | Precision 0.1321 | AP 0.2545 | F1 0.1321 | Time 1.43\n",
      "Epoch 0084: Loss 13.7817 | AUC 0.7581 | Recall 0.1321 | Precision 0.1321 | AP 0.2532 | F1 0.1321 | Time 1.50\n",
      "Epoch 0085: Loss 13.7766 | AUC 0.7533 | Recall 0.1321 | Precision 0.1321 | AP 0.2512 | F1 0.1321 | Time 1.51\n",
      "Epoch 0086: Loss 13.7753 | AUC 0.7461 | Recall 0.1321 | Precision 0.1321 | AP 0.2479 | F1 0.1321 | Time 1.37\n",
      "Epoch 0087: Loss 13.7729 | AUC 0.7450 | Recall 0.1321 | Precision 0.1321 | AP 0.2475 | F1 0.1321 | Time 1.44\n",
      "Epoch 0088: Loss 13.7724 | AUC 0.7472 | Recall 0.1321 | Precision 0.1321 | AP 0.2485 | F1 0.1321 | Time 1.41\n",
      "Epoch 0089: Loss 13.7700 | AUC 0.7489 | Recall 0.1321 | Precision 0.1321 | AP 0.2497 | F1 0.1321 | Time 1.39\n",
      "Epoch 0090: Loss 13.7675 | AUC 0.7493 | Recall 0.1321 | Precision 0.1321 | AP 0.2497 | F1 0.1321 | Time 1.33\n",
      "Epoch 0091: Loss 13.7707 | AUC 0.7486 | Recall 0.1321 | Precision 0.1321 | AP 0.2493 | F1 0.1321 | Time 1.50\n",
      "Epoch 0092: Loss 13.7722 | AUC 0.7460 | Recall 0.1321 | Precision 0.1321 | AP 0.2480 | F1 0.1321 | Time 1.32\n",
      "Epoch 0093: Loss 13.7634 | AUC 0.7401 | Recall 0.1321 | Precision 0.1321 | AP 0.2455 | F1 0.1321 | Time 1.35\n",
      "Epoch 0094: Loss 13.7663 | AUC 0.7352 | Recall 0.1321 | Precision 0.1321 | AP 0.2435 | F1 0.1321 | Time 1.47\n",
      "Epoch 0095: Loss 13.7612 | AUC 0.7347 | Recall 0.1384 | Precision 0.1384 | AP 0.2435 | F1 0.1384 | Time 1.44\n",
      "Epoch 0096: Loss 13.7685 | AUC 0.7352 | Recall 0.1384 | Precision 0.1384 | AP 0.2437 | F1 0.1384 | Time 1.37\n",
      "Epoch 0097: Loss 13.7641 | AUC 0.7343 | Recall 0.1384 | Precision 0.1384 | AP 0.2434 | F1 0.1384 | Time 1.54\n",
      "Epoch 0098: Loss 13.7651 | AUC 0.7324 | Recall 0.1384 | Precision 0.1384 | AP 0.2427 | F1 0.1384 | Time 1.41\n",
      "Epoch 0099: Loss 13.7606 | AUC 0.7281 | Recall 0.1384 | Precision 0.1384 | AP 0.2410 | F1 0.1384 | Time 1.49\n"
     ]
    }
   ],
   "source": [
    "conda_compile = conad_mode.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0306 | AUC 0.6676 | Recall 0.6420 | Precision 0.6420 | AP 0.5881 | F1 0.6420 | Time 0.70\n",
      "tensor([0, 1]) tensor([1344,  262])\n"
     ]
    }
   ],
   "source": [
    "conad_ip_pred_res, conad_ip_score_res, conad_ip_prob_res, conad_ip_conf_res = conda_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)\n",
    "unique_values, counts = torch.unique(conad_ip_pred_res, return_counts=True)\n",
    "print(unique_values, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnomalyDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalydae_model = AnomalyDAE(emb_dim=128, hid_dim=128, num_layers=68, weight_decay=0.02, \n",
    "                            alpha=0.5, theta=1.0, eta=1.0, \n",
    "                            contamination=0.1, lr=0.004, epoch=100, gpu=-1, \n",
    "                            verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000: Loss 4816.1001 | AUC 0.7670 | Recall 0.3270 | Precision 0.3270 | AP 0.3926 | F1 0.3291 | Time 0.41\n",
      "Epoch 0001: Loss 520817.8750 | AUC 0.7674 | Recall 0.3333 | Precision 0.3333 | AP 0.3945 | F1 0.3333 | Time 0.21\n",
      "Epoch 0002: Loss 211217.8438 | AUC 0.7667 | Recall 0.3333 | Precision 0.3333 | AP 0.3947 | F1 0.3376 | Time 0.35\n",
      "Epoch 0003: Loss 28883.8184 | AUC 0.7662 | Recall 0.3333 | Precision 0.3333 | AP 0.3949 | F1 0.3333 | Time 0.19\n",
      "Epoch 0004: Loss 7822.3154 | AUC 0.7756 | Recall 0.3333 | Precision 0.3333 | AP 0.3976 | F1 0.3333 | Time 0.18\n",
      "Epoch 0005: Loss 18032.4980 | AUC 0.7979 | Recall 0.3082 | Precision 0.3082 | AP 0.2699 | F1 0.3082 | Time 0.16\n",
      "Epoch 0006: Loss 14277.4443 | AUC 0.8430 | Recall 0.2893 | Precision 0.2893 | AP 0.3271 | F1 0.2893 | Time 0.16\n",
      "Epoch 0007: Loss 5742.2998 | AUC 0.8481 | Recall 0.3019 | Precision 0.3019 | AP 0.3396 | F1 0.3019 | Time 0.16\n",
      "Epoch 0008: Loss 18290.9297 | AUC 0.8689 | Recall 0.3396 | Precision 0.3396 | AP 0.3755 | F1 0.3396 | Time 0.16\n",
      "Epoch 0009: Loss 13280.0879 | AUC 0.8689 | Recall 0.3459 | Precision 0.3459 | AP 0.3828 | F1 0.3459 | Time 0.16\n",
      "Epoch 0010: Loss 4786.0269 | AUC 0.8551 | Recall 0.3208 | Precision 0.3208 | AP 0.3560 | F1 0.3208 | Time 0.22\n",
      "Epoch 0011: Loss 5835.2480 | AUC 0.8569 | Recall 0.3208 | Precision 0.3208 | AP 0.3594 | F1 0.3208 | Time 0.17\n",
      "Epoch 0012: Loss 3491.1868 | AUC 0.8717 | Recall 0.3648 | Precision 0.3648 | AP 0.4135 | F1 0.3648 | Time 0.16\n",
      "Epoch 0013: Loss 914.3859 | AUC 0.8756 | Recall 0.3899 | Precision 0.3899 | AP 0.4377 | F1 0.3899 | Time 0.15\n",
      "Epoch 0014: Loss 11093.8623 | AUC 0.8656 | Recall 0.3333 | Precision 0.3333 | AP 0.3683 | F1 0.3333 | Time 0.19\n",
      "Epoch 0015: Loss 12162.4863 | AUC 0.8659 | Recall 0.3333 | Precision 0.3333 | AP 0.3688 | F1 0.3333 | Time 0.17\n",
      "Epoch 0016: Loss 4447.7842 | AUC 0.8562 | Recall 0.3270 | Precision 0.3270 | AP 0.3585 | F1 0.3270 | Time 0.17\n",
      "Epoch 0017: Loss 11528.1650 | AUC 0.8690 | Recall 0.3585 | Precision 0.3585 | AP 0.3918 | F1 0.3585 | Time 0.15\n",
      "Epoch 0018: Loss 16019.9551 | AUC 0.8681 | Recall 0.3585 | Precision 0.3585 | AP 0.3878 | F1 0.3585 | Time 0.19\n",
      "Epoch 0019: Loss 10509.0312 | AUC 0.8700 | Recall 0.3585 | Precision 0.3585 | AP 0.3926 | F1 0.3585 | Time 0.20\n",
      "Epoch 0020: Loss 1768.0651 | AUC 0.8332 | Recall 0.3208 | Precision 0.3208 | AP 0.3481 | F1 0.3208 | Time 0.18\n",
      "Epoch 0021: Loss 4867.6104 | AUC 0.8576 | Recall 0.3270 | Precision 0.3270 | AP 0.3608 | F1 0.3270 | Time 0.16\n",
      "Epoch 0022: Loss 1356.0629 | AUC 0.8269 | Recall 0.3208 | Precision 0.3208 | AP 0.3456 | F1 0.3208 | Time 0.16\n",
      "Epoch 0023: Loss 7589.8467 | AUC 0.8721 | Recall 0.3648 | Precision 0.3648 | AP 0.3992 | F1 0.3648 | Time 0.16\n",
      "Epoch 0024: Loss 9489.6768 | AUC 0.8716 | Recall 0.3648 | Precision 0.3648 | AP 0.3969 | F1 0.3648 | Time 0.17\n",
      "Epoch 0025: Loss 5636.6704 | AUC 0.8730 | Recall 0.3648 | Precision 0.3648 | AP 0.4052 | F1 0.3648 | Time 0.16\n",
      "Epoch 0026: Loss 2224.3750 | AUC 0.8367 | Recall 0.3208 | Precision 0.3208 | AP 0.3507 | F1 0.3208 | Time 0.16\n",
      "Epoch 0027: Loss 4329.7168 | AUC 0.8570 | Recall 0.3270 | Precision 0.3270 | AP 0.3601 | F1 0.3270 | Time 0.16\n",
      "Epoch 0028: Loss 2207.0181 | AUC 0.8367 | Recall 0.3208 | Precision 0.3208 | AP 0.3507 | F1 0.3208 | Time 0.18\n",
      "Epoch 0029: Loss 3352.9343 | AUC 0.8749 | Recall 0.3648 | Precision 0.3648 | AP 0.4195 | F1 0.3648 | Time 0.20\n",
      "Epoch 0030: Loss 4566.5898 | AUC 0.8739 | Recall 0.3648 | Precision 0.3648 | AP 0.4120 | F1 0.3648 | Time 0.18\n",
      "Epoch 0031: Loss 2247.8657 | AUC 0.8755 | Recall 0.3648 | Precision 0.3648 | AP 0.4278 | F1 0.3648 | Time 0.26\n",
      "Epoch 0032: Loss 2735.9185 | AUC 0.8496 | Recall 0.3270 | Precision 0.3270 | AP 0.3551 | F1 0.3270 | Time 0.18\n",
      "Epoch 0033: Loss 4031.9043 | AUC 0.8561 | Recall 0.3270 | Precision 0.3270 | AP 0.3591 | F1 0.3270 | Time 0.19\n",
      "Epoch 0034: Loss 2492.8120 | AUC 0.8486 | Recall 0.3208 | Precision 0.3208 | AP 0.3540 | F1 0.3208 | Time 0.16\n",
      "Epoch 0035: Loss 1348.4484 | AUC 0.8749 | Recall 0.3774 | Precision 0.3774 | AP 0.4344 | F1 0.3774 | Time 0.17\n",
      "Epoch 0036: Loss 2270.1140 | AUC 0.8755 | Recall 0.3648 | Precision 0.3648 | AP 0.4273 | F1 0.3648 | Time 0.17\n",
      "Epoch 0037: Loss 845.5058 | AUC 0.8777 | Recall 0.4025 | Precision 0.4025 | AP 0.4417 | F1 0.4025 | Time 0.20\n",
      "Epoch 0038: Loss 2435.5791 | AUC 0.8448 | Recall 0.3208 | Precision 0.3208 | AP 0.3528 | F1 0.3208 | Time 0.18\n",
      "Epoch 0039: Loss 3221.4978 | AUC 0.8543 | Recall 0.3270 | Precision 0.3270 | AP 0.3568 | F1 0.3270 | Time 0.16\n",
      "Epoch 0040: Loss 2059.8877 | AUC 0.8344 | Recall 0.3208 | Precision 0.3208 | AP 0.3500 | F1 0.3208 | Time 0.16\n",
      "Epoch 0041: Loss 694.3666 | AUC 0.8762 | Recall 0.4214 | Precision 0.4214 | AP 0.4461 | F1 0.4214 | Time 0.17\n",
      "Epoch 0042: Loss 1378.7408 | AUC 0.8747 | Recall 0.3648 | Precision 0.3648 | AP 0.4332 | F1 0.3648 | Time 0.17\n",
      "Epoch 0043: Loss 416.3853 | AUC 0.8027 | Recall 0.3459 | Precision 0.3459 | AP 0.3861 | F1 0.3481 | Time 0.16\n",
      "Epoch 0044: Loss 1873.3422 | AUC 0.8336 | Recall 0.3208 | Precision 0.3208 | AP 0.3491 | F1 0.3208 | Time 0.16\n",
      "Epoch 0045: Loss 2418.8564 | AUC 0.8445 | Recall 0.3208 | Precision 0.3208 | AP 0.3526 | F1 0.3208 | Time 0.16\n",
      "Epoch 0046: Loss 1608.1515 | AUC 0.8279 | Recall 0.3208 | Precision 0.3208 | AP 0.3469 | F1 0.3208 | Time 0.16\n",
      "Epoch 0047: Loss 311.4016 | AUC 0.7614 | Recall 0.1824 | Precision 0.1824 | AP 0.2858 | F1 0.1830 | Time 0.17\n",
      "Epoch 0048: Loss 779.8687 | AUC 0.8775 | Recall 0.3962 | Precision 0.3962 | AP 0.4410 | F1 0.3962 | Time 0.15\n",
      "Epoch 0049: Loss 124.2671 | AUC 0.3096 | Recall 0.1258 | Precision 0.1258 | AP 0.1649 | F1 0.1266 | Time 0.15\n",
      "Epoch 0050: Loss 1268.6766 | AUC 0.8234 | Recall 0.3208 | Precision 0.3208 | AP 0.3453 | F1 0.3208 | Time 0.17\n",
      "Epoch 0051: Loss 1483.2684 | AUC 0.8271 | Recall 0.3208 | Precision 0.3208 | AP 0.3464 | F1 0.3208 | Time 0.15\n",
      "Epoch 0052: Loss 807.9559 | AUC 0.8281 | Recall 0.3208 | Precision 0.3208 | AP 0.3461 | F1 0.3208 | Time 0.17\n",
      "Epoch 0053: Loss 615.0027 | AUC 0.8759 | Recall 0.4151 | Precision 0.4151 | AP 0.4437 | F1 0.4151 | Time 0.16\n",
      "Epoch 0054: Loss 1013.2389 | AUC 0.8758 | Recall 0.3774 | Precision 0.3774 | AP 0.4371 | F1 0.3785 | Time 0.16\n",
      "Epoch 0055: Loss 630.3630 | AUC 0.8772 | Recall 0.4151 | Precision 0.4151 | AP 0.4441 | F1 0.4151 | Time 0.16\n",
      "Epoch 0056: Loss 402.1296 | AUC 0.8420 | Recall 0.3522 | Precision 0.3522 | AP 0.3768 | F1 0.3522 | Time 0.17\n",
      "Epoch 0057: Loss 618.0408 | AUC 0.8373 | Recall 0.3459 | Precision 0.3459 | AP 0.3547 | F1 0.3459 | Time 0.18\n",
      "Epoch 0058: Loss 254.2941 | AUC 0.8535 | Recall 0.3459 | Precision 0.3459 | AP 0.3743 | F1 0.3459 | Time 0.16\n",
      "Epoch 0059: Loss 630.4792 | AUC 0.8778 | Recall 0.4088 | Precision 0.4088 | AP 0.4430 | F1 0.4088 | Time 0.16\n",
      "Epoch 0060: Loss 827.1326 | AUC 0.8764 | Recall 0.3836 | Precision 0.3836 | AP 0.4377 | F1 0.3836 | Time 0.16\n",
      "Epoch 0061: Loss 524.5093 | AUC 0.8762 | Recall 0.4151 | Precision 0.4151 | AP 0.4462 | F1 0.4151 | Time 0.17\n",
      "Epoch 0062: Loss 210.1845 | AUC 0.8503 | Recall 0.3396 | Precision 0.3396 | AP 0.3768 | F1 0.3396 | Time 0.17\n",
      "Epoch 0063: Loss 388.5898 | AUC 0.8381 | Recall 0.3459 | Precision 0.3459 | AP 0.3728 | F1 0.3459 | Time 0.16\n",
      "Epoch 0064: Loss 200.6938 | AUC 0.8517 | Recall 0.3333 | Precision 0.3333 | AP 0.3774 | F1 0.3333 | Time 0.16\n",
      "Epoch 0065: Loss 339.1600 | AUC 0.8617 | Recall 0.4214 | Precision 0.4214 | AP 0.4508 | F1 0.4214 | Time 0.19\n",
      "Epoch 0066: Loss 430.9744 | AUC 0.8764 | Recall 0.4151 | Precision 0.4151 | AP 0.4486 | F1 0.4151 | Time 0.19\n",
      "Epoch 0067: Loss 221.8940 | AUC 0.8000 | Recall 0.3333 | Precision 0.3333 | AP 0.3783 | F1 0.3333 | Time 0.21\n",
      "Epoch 0068: Loss 266.6322 | AUC 0.8486 | Recall 0.3396 | Precision 0.3396 | AP 0.3758 | F1 0.3396 | Time 0.19\n",
      "Epoch 0069: Loss 388.3065 | AUC 0.8361 | Recall 0.3396 | Precision 0.3396 | AP 0.3708 | F1 0.3396 | Time 0.18\n",
      "Epoch 0070: Loss 284.5073 | AUC 0.8400 | Recall 0.3396 | Precision 0.3396 | AP 0.3738 | F1 0.3396 | Time 0.16\n",
      "Epoch 0071: Loss 61.5350 | AUC 0.4942 | Recall 0.1258 | Precision 0.1258 | AP 0.1867 | F1 0.1262 | Time 0.46\n",
      "Epoch 0072: Loss 256.8817 | AUC 0.8396 | Recall 0.4277 | Precision 0.4277 | AP 0.4387 | F1 0.4277 | Time 0.19\n",
      "Epoch 0073: Loss 259.5043 | AUC 0.8428 | Recall 0.4277 | Precision 0.4277 | AP 0.4415 | F1 0.4277 | Time 0.21\n",
      "Epoch 0074: Loss 111.1463 | AUC 0.7167 | Recall 0.1509 | Precision 0.1509 | AP 0.2479 | F1 0.1514 | Time 0.19\n",
      "Epoch 0075: Loss 204.1862 | AUC 0.8501 | Recall 0.3333 | Precision 0.3333 | AP 0.3773 | F1 0.3333 | Time 0.16\n",
      "Epoch 0076: Loss 289.2469 | AUC 0.8377 | Recall 0.3396 | Precision 0.3396 | AP 0.3731 | F1 0.3396 | Time 0.18\n",
      "Epoch 0077: Loss 254.0622 | AUC 0.8462 | Recall 0.3333 | Precision 0.3333 | AP 0.3736 | F1 0.3333 | Time 0.17\n",
      "Epoch 0078: Loss 134.5975 | AUC 0.8303 | Recall 0.3333 | Precision 0.3333 | AP 0.3856 | F1 0.3333 | Time 0.17\n",
      "Epoch 0079: Loss 102.8984 | AUC 0.7528 | Recall 0.1761 | Precision 0.1761 | AP 0.2747 | F1 0.1761 | Time 0.17\n",
      "Epoch 0080: Loss 166.0146 | AUC 0.7982 | Recall 0.3270 | Precision 0.3270 | AP 0.3730 | F1 0.3281 | Time 0.17\n",
      "Epoch 0081: Loss 148.5460 | AUC 0.7896 | Recall 0.2704 | Precision 0.2704 | AP 0.3497 | F1 0.2783 | Time 0.17\n",
      "Epoch 0082: Loss 76.9847 | AUC 0.6473 | Recall 0.1447 | Precision 0.1447 | AP 0.2210 | F1 0.1451 | Time 0.18\n",
      "Epoch 0083: Loss 99.7730 | AUC 0.8115 | Recall 0.3396 | Precision 0.3396 | AP 0.3766 | F1 0.3344 | Time 0.19\n",
      "Epoch 0084: Loss 136.9651 | AUC 0.8286 | Recall 0.3333 | Precision 0.3333 | AP 0.3847 | F1 0.3333 | Time 0.17\n",
      "Epoch 0085: Loss 135.0649 | AUC 0.8277 | Recall 0.3333 | Precision 0.3333 | AP 0.3844 | F1 0.3333 | Time 0.16\n",
      "Epoch 0086: Loss 108.2298 | AUC 0.8175 | Recall 0.3333 | Precision 0.3333 | AP 0.3789 | F1 0.3333 | Time 0.17\n",
      "Epoch 0087: Loss 72.9211 | AUC 0.7484 | Recall 0.3396 | Precision 0.3396 | AP 0.3319 | F1 0.3344 | Time 0.18\n",
      "Epoch 0088: Loss 57.0535 | AUC 0.4238 | Recall 0.1258 | Precision 0.1258 | AP 0.1732 | F1 0.1262 | Time 0.19\n",
      "Epoch 0089: Loss 76.2732 | AUC 0.7087 | Recall 0.1509 | Precision 0.1509 | AP 0.2450 | F1 0.1514 | Time 0.16\n",
      "Epoch 0090: Loss 76.8691 | AUC 0.7239 | Recall 0.1572 | Precision 0.1572 | AP 0.2518 | F1 0.1572 | Time 0.20\n",
      "Epoch 0091: Loss 66.7581 | AUC 0.6473 | Recall 0.1447 | Precision 0.1447 | AP 0.2210 | F1 0.1451 | Time 0.18\n",
      "Epoch 0092: Loss 51.6778 | AUC 0.4051 | Recall 0.1258 | Precision 0.1258 | AP 0.1718 | F1 0.1262 | Time 0.18\n",
      "Epoch 0093: Loss 52.9383 | AUC 0.7081 | Recall 0.1195 | Precision 0.1195 | AP 0.2188 | F1 0.1199 | Time 0.18\n",
      "Epoch 0094: Loss 56.6534 | AUC 0.6996 | Recall 0.1258 | Precision 0.1258 | AP 0.2248 | F1 0.1258 | Time 0.17\n",
      "Epoch 0095: Loss 56.8010 | AUC 0.6994 | Recall 0.1258 | Precision 0.1258 | AP 0.2255 | F1 0.1258 | Time 0.17\n",
      "Epoch 0096: Loss 54.4294 | AUC 0.7021 | Recall 0.1132 | Precision 0.1132 | AP 0.2187 | F1 0.1139 | Time 0.18\n",
      "Epoch 0097: Loss 51.0980 | AUC 0.7155 | Recall 0.1195 | Precision 0.1195 | AP 0.2227 | F1 0.1199 | Time 0.16\n",
      "Epoch 0098: Loss 49.3689 | AUC 0.6976 | Recall 0.1195 | Precision 0.1195 | AP 0.2222 | F1 0.1199 | Time 0.17\n",
      "Epoch 0099: Loss 50.6588 | AUC 0.4258 | Recall 0.1258 | Precision 0.1258 | AP 0.1732 | F1 0.1262 | Time 0.18\n"
     ]
    }
   ],
   "source": [
    "anomalydae_compile = anomalydae_model.fit(pyG_train, label_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss 0.0306 | AUC 0.6676 | Recall 0.6420 | Precision 0.6420 | AP 0.5881 | F1 0.6420 | Time 0.33\n",
      "tensor([0, 1]) tensor([1344,  262])\n"
     ]
    }
   ],
   "source": [
    "anomalydae_ip_pred_res, anomalydae_ip_score_res, anomalydae_ip_prob_res, anomalydae_ip_conf_res = conda_compile.predict(data=pyG_test, label = label_test_tensor,return_pred=True, return_score=True, return_prob=True, prob_method='linear', return_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
